2024-05-27 17:32:32,128 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                           cfg.name : iten_transformer_bpe5000
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                     cfg.data.train : data/preprocessed/train.sampled
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                       cfg.data.dev : data/preprocessed/valid
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                      cfg.data.test : data/preprocessed/test
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                  cfg.data.src.lang : it
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/bpe/vocab.5000
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/bpe/codes.5000
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/bpe/vocab.5000
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/bpe/codes.5000
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-27 17:32:32,128 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/iten_transformer_bpe5000
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-27 17:32:32,129 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-27 17:32:32,131 - INFO - joeynmt.data - Building tokenizer...
2024-05-27 17:32:32,138 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-27 17:32:32,138 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-27 17:32:32,138 - INFO - joeynmt.data - Loading train set...
2024-05-27 17:32:32,245 - INFO - joeynmt.data - Building vocabulary...
2024-05-27 17:32:32,421 - INFO - joeynmt.data - Loading dev set...
2024-05-27 17:32:32,423 - INFO - joeynmt.data - Loading test set...
2024-05-27 17:32:32,425 - INFO - joeynmt.data - Data loaded.
2024-05-27 17:32:32,425 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-27 17:32:32,425 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=929, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-27 17:32:32,425 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1566, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-27 17:32:32,425 - INFO - joeynmt.data - First training example:
	[SRC] Al G@@ ore : ar@@ res@@ tiamo il ri@@ scal@@ d@@ amento globale
	[TRG] Al G@@ ore : A@@ ver@@ ting the climate c@@ ris@@ is
2024-05-27 17:32:32,425 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) a (8) di (9) in
2024-05-27 17:32:32,425 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) the (7) a (8) di (9) in
2024-05-27 17:32:32,425 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 4988
2024-05-27 17:32:32,425 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 4988
2024-05-27 17:32:32,426 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-27 17:32:32,498 - INFO - joeynmt.model - Enc-dec model built.
2024-05-27 17:32:32,500 - INFO - joeynmt.model - Total params: 4176128
2024-05-27 17:32:32,500 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2024-05-27 17:32:32,500 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=4988),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=4988),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-27 17:32:32,500 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-27 17:32:32,500 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-27 17:32:32,500 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-27 17:32:32,500 - INFO - joeynmt.training - EPOCH 1
2024-05-27 17:32:52,124 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     4.290765, Batch Acc: 0.069363, Tokens per Sec:     3593, Lr: 0.000300
2024-05-27 17:33:11,169 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     4.018094, Batch Acc: 0.099480, Tokens per Sec:     3556, Lr: 0.000300
2024-05-27 17:33:30,715 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.797384, Batch Acc: 0.116237, Tokens per Sec:     3644, Lr: 0.000300
2024-05-27 17:33:49,708 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.805808, Batch Acc: 0.125756, Tokens per Sec:     3519, Lr: 0.000300
2024-05-27 17:34:08,964 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.517704, Batch Acc: 0.138525, Tokens per Sec:     3793, Lr: 0.000300
2024-05-27 17:34:08,965 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:34:08,965 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:35:32,914 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.66, ppl:  38.97, acc:   0.13, generation: 83.9349[sec], evaluation: 0.0000[sec]
2024-05-27 17:35:32,915 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:35:33,033 - INFO - joeynmt.training - Example #0
2024-05-27 17:35:33,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:35:33,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:35:33,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', '&apos;re', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2024-05-27 17:35:33,033 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:35:33,033 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:35:33,033 - INFO - joeynmt.training - 	Hypothesis: And I &apos;re the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2024-05-27 17:35:33,033 - INFO - joeynmt.training - Example #1
2024-05-27 17:35:33,033 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:35:33,033 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:35:33,033 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'have', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2024-05-27 17:35:33,033 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Hypothesis: And I have the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2024-05-27 17:35:33,034 - INFO - joeynmt.training - Example #2
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'have', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Hypothesis: And I have the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2024-05-27 17:35:33,034 - INFO - joeynmt.training - Example #3
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'have', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Hypothesis: And I have the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2024-05-27 17:35:33,034 - INFO - joeynmt.training - Example #4
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:35:33,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', '&apos;s', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the']
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:35:33,034 - INFO - joeynmt.training - 	Hypothesis: And &apos;s the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the
2024-05-27 17:35:52,052 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.532923, Batch Acc: 0.141580, Tokens per Sec:     3647, Lr: 0.000300
2024-05-27 17:36:10,987 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.602222, Batch Acc: 0.150607, Tokens per Sec:     3691, Lr: 0.000300
2024-05-27 17:36:30,627 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.404631, Batch Acc: 0.155126, Tokens per Sec:     3652, Lr: 0.000300
2024-05-27 17:36:50,211 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.458468, Batch Acc: 0.165244, Tokens per Sec:     3613, Lr: 0.000300
2024-05-27 17:37:10,511 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     3.360723, Batch Acc: 0.174766, Tokens per Sec:     3431, Lr: 0.000300
2024-05-27 17:37:10,512 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:37:10,512 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:38:37,670 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.47, ppl:  31.99, acc:   0.16, generation: 87.1497[sec], evaluation: 0.0000[sec]
2024-05-27 17:38:37,671 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:38:37,790 - INFO - joeynmt.training - Example #0
2024-05-27 17:38:37,790 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:38:37,790 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:38:37,790 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'is', 'a', 'lot', 'of', 'the', 'world', ',', 'the', 'world', ',', 'and', 'I', '&apos;re', 'a', 'very', 'the', 'world', ',', 'and', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'the', 'world', ',', 'and', 'the', 'world', '.', '</s>']
2024-05-27 17:38:37,790 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:38:37,790 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:38:37,790 - INFO - joeynmt.training - 	Hypothesis: The first is a lot of the world , the world , and I &apos;re a very the world , and the world , the world , the world , the world , and the world , and the world , the world , and the world .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - Example #1
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not']
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Hypothesis: It &apos;s not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not
2024-05-27 17:38:37,791 - INFO - joeynmt.training - Example #2
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'is', 'a', 'very', 'a', 'very', 'a', 'very', 'very', 'very', 'very', 'very', '.', '</s>']
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Hypothesis: The first is a very a very a very very very very very .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - Example #3
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'it', '&apos;s', 'a', 'very', 'very', 'very', 'very', 'very', 'very', '.', '</s>']
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - 	Hypothesis: And it &apos;s a very very very very very very .
2024-05-27 17:38:37,791 - INFO - joeynmt.training - Example #4
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:38:37,791 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'is', 'a', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', '.', '</s>']
2024-05-27 17:38:37,792 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:38:37,792 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:38:37,792 - INFO - joeynmt.training - 	Hypothesis: The first is a very very very very very very very very very very .
2024-05-27 17:38:59,013 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.201912, Batch Acc: 0.180212, Tokens per Sec:     3295, Lr: 0.000300
2024-05-27 17:39:20,431 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     3.404212, Batch Acc: 0.188181, Tokens per Sec:     3299, Lr: 0.000300
2024-05-27 17:39:40,726 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     3.284603, Batch Acc: 0.196480, Tokens per Sec:     3491, Lr: 0.000300
2024-05-27 17:40:01,565 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     3.165791, Batch Acc: 0.204216, Tokens per Sec:     3470, Lr: 0.000300
2024-05-27 17:40:22,543 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     3.243088, Batch Acc: 0.210171, Tokens per Sec:     3316, Lr: 0.000300
2024-05-27 17:40:22,544 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:40:22,544 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:41:40,767 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.27, ppl:  26.41, acc:   0.21, generation: 78.2158[sec], evaluation: 0.0000[sec]
2024-05-27 17:41:40,767 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:41:40,886 - INFO - joeynmt.training - Example #0
2024-05-27 17:41:40,886 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'I', '&apos;m', 'going', 'to', 'be', 'to', 'be', 'the', 'world', 'that', 'that', 'the', 'world', 'that', 'the', 'world', 'of', 'the', 'world', ',', 'in', 'the', 'world', ',', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'of', 'the', 'world', 'is', 'the', 'world', '.', '</s>']
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Hypothesis: The first thing I &apos;m going to be to be the world that that the world that the world of the world , in the world , the world of the world of the world of the world of the world is the world .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - Example #1
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'is', 'this', 'is', 'this', 'of', 'the', 'first', 'thing', 'of', 'the', 'world', 'is', 'not', 'not', 'not', 'the', 'world', '.', '</s>']
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Hypothesis: The first thing is this is this of the first thing of the world is not not not the world .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - Example #2
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'is', 'the', 'first', 'years', ',', 'the', 'first', ',', 'a', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'very', 'much', '.', '</s>']
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - 	Hypothesis: The first is the first years , the first , a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very much .
2024-05-27 17:41:40,887 - INFO - joeynmt.training - Example #3
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:41:40,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', '&apos;re', 'going', 'to', 'be', 'the', 'world', 'and', 'the', 'world', 'and', 'the', 'world', '.', '</s>']
2024-05-27 17:41:40,888 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:41:40,888 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:41:40,888 - INFO - joeynmt.training - 	Hypothesis: They &apos;re going to be the world and the world and the world .
2024-05-27 17:41:40,888 - INFO - joeynmt.training - Example #4
2024-05-27 17:41:40,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:41:40,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:41:40,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'thing', 'of', 'the', 'first', 'years', 'of', 'a', 'little', 'bit', 'of', 'the', 'world', 'of', 'the', 'world', '.', '</s>']
2024-05-27 17:41:40,888 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:41:40,888 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:41:40,888 - INFO - joeynmt.training - 	Hypothesis: The first thing of the first years of a little bit of the world of the world .
2024-05-27 17:42:01,509 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     3.196885, Batch Acc: 0.218471, Tokens per Sec:     3403, Lr: 0.000300
2024-05-27 17:42:23,259 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     3.278616, Batch Acc: 0.230339, Tokens per Sec:     3252, Lr: 0.000300
2024-05-27 17:42:44,066 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     3.204206, Batch Acc: 0.239347, Tokens per Sec:     3409, Lr: 0.000300
2024-05-27 17:43:05,012 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     3.002523, Batch Acc: 0.246180, Tokens per Sec:     3434, Lr: 0.000300
2024-05-27 17:43:26,078 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.942959, Batch Acc: 0.258828, Tokens per Sec:     3341, Lr: 0.000300
2024-05-27 17:43:26,078 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:43:26,078 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:44:40,492 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.04, ppl:  20.80, acc:   0.25, generation: 74.4077[sec], evaluation: 0.0000[sec]
2024-05-27 17:44:40,494 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:44:40,619 - INFO - joeynmt.training - Example #0
2024-05-27 17:44:40,619 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:44:40,619 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:44:40,619 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'I', '&apos;m', 'going', 'to', 'the', 'same', 'thing', 'that', 'we', '&apos;re', 'going', 'to', 'be', 'the', 'last', 'years', ',', 'that', '&apos;s', 'the', 'last', 'years', ',', 'that', '&apos;s', 'the', 'last', 'years', ',', 'of', 'the', 'last', 'years', ',', 'the', 'last', 'percent', 'of', 'the', 'same', 'is', 'the', 'same', 'of', 'the', 'same', 'percent', 'of', 'the', 'same', 'percent', 'of', 'the', 'same', 'of', 'the', 'world', '.', '</s>']
2024-05-27 17:44:40,619 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:44:40,619 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:44:40,619 - INFO - joeynmt.training - 	Hypothesis: The first first I &apos;m going to the same thing that we &apos;re going to be the last years , that &apos;s the last years , that &apos;s the last years , of the last years , the last percent of the same is the same of the same percent of the same percent of the same of the world .
2024-05-27 17:44:40,619 - INFO - joeynmt.training - Example #1
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'same', 'thing', 'is', 'the', 'same', 'of', 'the', 'same', 'because', 'the', 'same', 'because', 'the', 'same', 'because', 'the', 'same', 'is', 'not', 'the', 'same', '.', '</s>']
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Hypothesis: And the same thing is the same of the same because the same because the same because the same is not the same .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - Example #2
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'the', 'same', 'of', 'the', 'same', 'is', ',', 'is', 'a', 'little', 'bit', ',', 'in', 'the', 'same', 'way', ',', 'the', 'same', 'way', 'of', 'the', 'same', '.', '</s>']
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Hypothesis: The first the same of the same is , is a little bit , in the same way , the same way of the same .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - Example #3
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'see', 'the', 'same', 'of', 'the', 'same', 'and', 'the', 'w@@', 'w@@', 'w@@', 'w@@', 'w@@', 'il@@', 's', '.', '</s>']
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - 	Hypothesis: You can see the same of the same and the wwwwwils .
2024-05-27 17:44:40,620 - INFO - joeynmt.training - Example #4
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:44:40,620 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'time', 'is', 'a', 'little', 'bit', 'is', 'a', 'little', 'bit', 'of', 'the', 'same', 'time', ',', 'they', '&apos;re', 'the', 'last', 'years', '.', '</s>']
2024-05-27 17:44:40,621 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:44:40,621 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:44:40,621 - INFO - joeynmt.training - 	Hypothesis: The first first time is a little bit is a little bit of the same time , they &apos;re the last years .
2024-05-27 17:45:01,879 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.874581, Batch Acc: 0.271360, Tokens per Sec:     3388, Lr: 0.000300
2024-05-27 17:45:23,544 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.836266, Batch Acc: 0.282195, Tokens per Sec:     3294, Lr: 0.000300
2024-05-27 17:45:45,013 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.815667, Batch Acc: 0.288662, Tokens per Sec:     3374, Lr: 0.000300
2024-05-27 17:46:06,274 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.663611, Batch Acc: 0.304534, Tokens per Sec:     3301, Lr: 0.000300
2024-05-27 17:46:28,162 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.751141, Batch Acc: 0.305375, Tokens per Sec:     3169, Lr: 0.000300
2024-05-27 17:46:28,163 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:46:28,163 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:47:51,280 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.79, ppl:  16.33, acc:   0.30, generation: 83.1106[sec], evaluation: 0.0000[sec]
2024-05-27 17:47:51,282 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:47:51,399 - INFO - joeynmt.training - Example #0
2024-05-27 17:47:51,399 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:47:51,399 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:47:51,399 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'the', 'last', 'year', 'I', 'was', 'going', 'to', 'get', 'to', 'get', 'to', 'the', 'first', 'first', 'of', 'the', 'first', 'first', 'of', 'the', 'three', 'years', ',', 'which', 'is', 'that', '&apos;s', 'the', 'three', 'years', 'of', 'the', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '19@@', '5@@', '5', 'percent', '.', '</s>']
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Hypothesis: And the last year I was going to get to get to the first first of the first first of the three years , which is that &apos;s the three years of the 191919191919191919191919191955 percent .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - Example #1
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', '&apos;m', 'going', 'to', 'do', 'this', 'is', 'the', 'problem', 'because', 'it', '&apos;s', 'because', 'it', 'doesn', '&apos;t', 'be', 'the', 'problem', '.', '</s>']
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Hypothesis: And I &apos;m going to do this is the problem because it &apos;s because it doesn &apos;t be the problem .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - Example #2
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'the', 'ex@@', 'pen@@', 'sive', 'of', 'the', 'same', 'thing', 'is', ',', 'in', 'a', 'kind', 'of', 'way', ',', 'the', 'most', 'of', 'the', 'world', '.', '</s>']
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Hypothesis: The the expensive of the same thing is , in a kind of way , the most of the world .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - Example #3
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:47:51,400 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'lot', 'of', 'the', 'h@@', 'ou@@', 'd', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'a', 'lot', 'of', 'the', 'p@@', 'ec@@', 'ec@@', 'k', '.', '</s>']
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a lot of the houd and you &apos;re going to be a lot of the pececk .
2024-05-27 17:47:51,400 - INFO - joeynmt.training - Example #4
2024-05-27 17:47:51,401 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:47:51,401 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:47:51,401 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'is', 'not', 'a', 'very', 'very', 'very', 'very', 'much', ',', 'I', '&apos;m', 'going', 'to', 'get', 'to', 'the', 'last', 'years', '.', '</s>']
2024-05-27 17:47:51,401 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:47:51,401 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:47:51,401 - INFO - joeynmt.training - 	Hypothesis: The first first is not a very very very very much , I &apos;m going to get to the last years .
2024-05-27 17:48:11,706 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.669973, Batch Acc: 0.317159, Tokens per Sec:     3325, Lr: 0.000300
2024-05-27 17:48:32,694 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.791618, Batch Acc: 0.329047, Tokens per Sec:     3342, Lr: 0.000300
2024-05-27 17:48:53,986 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.612392, Batch Acc: 0.331378, Tokens per Sec:     3186, Lr: 0.000300
2024-05-27 17:49:14,955 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.563765, Batch Acc: 0.341005, Tokens per Sec:     3345, Lr: 0.000300
2024-05-27 17:49:35,889 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.468598, Batch Acc: 0.344146, Tokens per Sec:     3252, Lr: 0.000300
2024-05-27 17:49:35,889 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:49:35,889 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:50:50,673 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.61, ppl:  13.56, acc:   0.33, generation: 74.7770[sec], evaluation: 0.0000[sec]
2024-05-27 17:50:50,676 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:50:50,798 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/500.ckpt
2024-05-27 17:50:50,802 - INFO - joeynmt.training - Example #0
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'he', 'was', 'a', 'little', 'bit', 'of', 'the', 're@@', 'duc@@', 'ed', 'that', 'the', 're@@', 'duc@@', 'ed', 'to', 'the', 're@@', 'mark@@', 'able', 'to', 'the', 'three', 'million', 'years', 'ago', ',', 'to', 'the', 'three', 'million', 'years', 'ago', ',', 'which', 'was', 'a', 'few', 'million', 'years', 'of', 'the', 'United', 'States', ',', 'it', '&apos;s', 'been', 'been', 'on', 'the', 'last', 'year', '.', '</s>']
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Hypothesis: And he was a little bit of the reduced that the reduced to the remarkable to the three million years ago , to the three million years ago , which was a few million years of the United States , it &apos;s been been on the last year .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - Example #1
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@', 'at@@']
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Hypothesis: Tatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatatat
2024-05-27 17:50:50,803 - INFO - joeynmt.training - Example #2
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 's@@', 'ell', 'in', 'the', 're@@', 're@@', 'mark@@', 'able', 'to', 'a', 'sense', ',', 'the', 'way', ',', 'the', 're@@', 'mark@@', 'able', 'system', 'system', 'system', '.', '</s>']
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - 	Hypothesis: The sell in the reremarkable to a sense , the way , the remarkable system system system .
2024-05-27 17:50:50,803 - INFO - joeynmt.training - Example #3
2024-05-27 17:50:50,803 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:50:50,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:50:50,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', '</s>']
2024-05-27 17:50:50,804 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:50:50,804 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:50:50,804 - INFO - joeynmt.training - 	Hypothesis: You know , you know , you know , you know , you know ,
2024-05-27 17:50:50,804 - INFO - joeynmt.training - Example #4
2024-05-27 17:50:50,804 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:50:50,804 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:50:50,804 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'second', 'second', ',', 'you', 'know', ',', 'it', '&apos;s', 'a', 're@@', 're@@', 're@@', 're@@', 're@@', 'duc@@', 'ed', 'the', 'last', 'year', '.', '</s>']
2024-05-27 17:50:50,804 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:50:50,804 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:50:50,804 - INFO - joeynmt.training - 	Hypothesis: The second second , you know , it &apos;s a rerererereduced the last year .
2024-05-27 17:51:12,488 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.505029, Batch Acc: 0.357927, Tokens per Sec:     3214, Lr: 0.000300
2024-05-27 17:51:34,773 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.263022, Batch Acc: 0.362661, Tokens per Sec:     3171, Lr: 0.000300
2024-05-27 17:51:56,410 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.558877, Batch Acc: 0.374690, Tokens per Sec:     3242, Lr: 0.000300
2024-05-27 17:52:18,178 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.712244, Batch Acc: 0.372177, Tokens per Sec:     3261, Lr: 0.000300
2024-05-27 17:52:41,231 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.436763, Batch Acc: 0.384222, Tokens per Sec:     3054, Lr: 0.000300
2024-05-27 17:52:41,233 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:52:41,233 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:53:43,014 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.45, ppl:  11.58, acc:   0.37, generation: 61.7744[sec], evaluation: 0.0000[sec]
2024-05-27 17:53:43,018 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:53:43,140 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/1000.ckpt
2024-05-27 17:53:43,144 - INFO - joeynmt.training - Example #0
2024-05-27 17:53:43,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:53:43,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:53:43,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', '&apos;ve', 'got', 'these', 'things', 'to', 'show', 'that', 'the', 'little', 'bit', 'of', 'the', 'me@@', 'ant', 'that', 'the', 's@@', 'ou@@', 'l@@', 'ic', 'country', 'has', 'been', 'been', 'three', 'million', 'years', 'of', 'the', 'United', 'States', ',', 'it', '&apos;s', 'the', 'United', 'States', ',', 'is', 're@@', 'duc@@', 'ed', 'by', 'the', 'United', 'States', '.', '</s>']
2024-05-27 17:53:43,144 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:53:43,144 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:53:43,144 - INFO - joeynmt.training - 	Hypothesis: The year I &apos;ve got these things to show that the little bit of the meant that the soulic country has been been three million years of the United States , it &apos;s the United States , is reduced by the United States .
2024-05-27 17:53:43,144 - INFO - joeynmt.training - Example #1
2024-05-27 17:53:43,144 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:53:43,144 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:53:43,144 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'have', 'the', 'process', 'of', 'the', 'process', 'of', 'the', 'problem', 'because', 'you', 'don', '&apos;t', 'see', 'it', '&apos;s', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:53:43,144 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:53:43,144 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Hypothesis: I have the process of the process of the problem because you don &apos;t see it &apos;s the ice of the ice .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - Example #2
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'ich', 'to', 'the', 'in@@', 'in@@', 'in@@', 'iti@@', 'al', 'is', ',', 'the', 'heart', 'of', 'the', 'm@@', 'el@@', 'el@@', 'el@@', 'low', 'system', '.', '</s>']
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Hypothesis: The rich to the inininitial is , the heart of the melelellow system .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - Example #3
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'have', 'to', 'be', 'in@@', 'in@@', 'in@@', 'in@@', 'iti@@', 'onal', 'and', 'you', 'get', 'the', 'in@@', 'in@@', 'iti@@', 'onal', '.', '</s>']
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Hypothesis: You have to be ininininitional and you get the ininitional .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - Example #4
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:53:43,145 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'next', 'next', ',', 'it', '&apos;s', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'to', 'be', 'a', 'little', 'years', '.', '</s>']
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:53:43,145 - INFO - joeynmt.training - 	Hypothesis: The next next next next , it &apos;s going to be a remarkable to be a little years .
2024-05-27 17:54:05,426 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.392686, Batch Acc: 0.391318, Tokens per Sec:     3142, Lr: 0.000300
2024-05-27 17:54:29,066 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.395279, Batch Acc: 0.402623, Tokens per Sec:     2952, Lr: 0.000300
2024-05-27 17:54:51,891 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.465401, Batch Acc: 0.406971, Tokens per Sec:     3150, Lr: 0.000300
2024-05-27 17:55:10,249 - INFO - joeynmt.training - Epoch   1: total training loss 11759.55
2024-05-27 17:55:10,250 - INFO - joeynmt.training - EPOCH 2
2024-05-27 17:55:14,648 - INFO - joeynmt.training - Epoch   2, Step:     3900, Batch Loss:     2.300283, Batch Acc: 0.430702, Tokens per Sec:     2806, Lr: 0.000300
2024-05-27 17:55:38,411 - INFO - joeynmt.training - Epoch   2, Step:     4000, Batch Loss:     2.201891, Batch Acc: 0.428242, Tokens per Sec:     3032, Lr: 0.000300
2024-05-27 17:55:38,412 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:55:38,412 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:56:33,573 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.31, ppl:  10.12, acc:   0.40, generation: 55.1537[sec], evaluation: 0.0000[sec]
2024-05-27 17:56:33,575 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:56:33,776 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/1500.ckpt
2024-05-27 17:56:33,780 - INFO - joeynmt.training - Example #0
2024-05-27 17:56:33,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:56:33,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:56:33,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', '&apos;ve', 'got', 'to', 'show', 'these', 'two', 'two', 'million', 'years', ',', 'which', 'the', 'h@@', 'ang@@', 'er', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'ago', ',', 'that', '&apos;s', 'the', 'United', 'States', ',', 'which', 'has', 'been', 'the', 'United', 'States', ',', 'it', '&apos;s', 're@@', 'qui@@', 'et', 'of', 'the', '20@@', '8', 'percent', '.', '</s>']
2024-05-27 17:56:33,780 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:56:33,780 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:56:33,780 - INFO - joeynmt.training - 	Hypothesis: The last year I &apos;ve got to show these two two million years , which the hanger , which for almost three million years ago , that &apos;s the United States , which has been the United States , it &apos;s requiet of the 208 percent .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - Example #1
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', '&apos;m', 'going', 'to', 'be', 'the', 'K@@', 'or@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'see', 'it', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Hypothesis: And I &apos;m going to be the Kority of the problem because it doesn &apos;t see it the ice of the ice .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - Example #2
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'ich', 'r@@', 'ati@@', 'on@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'heart', 'system', ',', 'the', 'heart', 'of', 'the', 'power', 'system', '.', '</s>']
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Hypothesis: The rich rational is , in a sense , the heart of the heart system , the heart of the power system .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - Example #3
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 're@@', 'fl@@', 'ying', 'and', 'you', 'get', 'it', '.', '</s>']
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - 	Hypothesis: It &apos;s reflying and you get it .
2024-05-27 17:56:33,781 - INFO - joeynmt.training - Example #4
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:56:33,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'thing', 'will', 'be', 'a', 're@@', 'qui@@', 'et', 'to', 'be', 'a', 're@@', 'qui@@', 'et', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 17:56:33,782 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:56:33,782 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:56:33,782 - INFO - joeynmt.training - 	Hypothesis: The next next thing will be a requiet to be a requiet of the last 25 years .
2024-05-27 17:56:57,891 - INFO - joeynmt.training - Epoch   2, Step:     4100, Batch Loss:     2.235467, Batch Acc: 0.434200, Tokens per Sec:     2882, Lr: 0.000300
2024-05-27 17:57:23,061 - INFO - joeynmt.training - Epoch   2, Step:     4200, Batch Loss:     2.388479, Batch Acc: 0.437796, Tokens per Sec:     2839, Lr: 0.000300
2024-05-27 17:57:47,325 - INFO - joeynmt.training - Epoch   2, Step:     4300, Batch Loss:     2.041759, Batch Acc: 0.438841, Tokens per Sec:     2947, Lr: 0.000300
2024-05-27 17:58:11,443 - INFO - joeynmt.training - Epoch   2, Step:     4400, Batch Loss:     2.097773, Batch Acc: 0.446638, Tokens per Sec:     2926, Lr: 0.000300
2024-05-27 17:58:35,299 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.128023, Batch Acc: 0.449451, Tokens per Sec:     2934, Lr: 0.000300
2024-05-27 17:58:35,300 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:58:35,301 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:59:30,403 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.23, ppl:   9.27, acc:   0.43, generation: 55.0954[sec], evaluation: 0.0000[sec]
2024-05-27 17:59:30,406 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:59:30,545 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/2000.ckpt
2024-05-27 17:59:30,549 - INFO - joeynmt.training - Example #0
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'showed', 'these', 'two', 'two', 'to', 'show', 'these', 'two', 'two', 'two', 'two', 'two', 'million', 'years', '.', '</s>']
2024-05-27 17:59:30,550 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:59:30,550 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:59:30,550 - INFO - joeynmt.training - 	Hypothesis: I showed these two two to show these two two two two two million years .
2024-05-27 17:59:30,550 - INFO - joeynmt.training - Example #1
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;m', 'going', 'to', 'be', 'able', 'to', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'see', 'it', 'is', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 17:59:30,550 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:59:30,550 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:59:30,550 - INFO - joeynmt.training - 	Hypothesis: I &apos;m going to be able to the gravity of the problem because it doesn &apos;t see it is the ice of ice .
2024-05-27 17:59:30,550 - INFO - joeynmt.training - Example #2
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 17:59:30,550 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 's@@', 'we@@', 'et', 'of', 'the', 'c@@', 'ris@@', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'heart', 'system', 'of', 'climate', 'change', '.', '</s>']
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Hypothesis: The sweet of the crisis , in a sense , the heart of the heart system of climate change .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - Example #3
2024-05-27 17:59:30,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:59:30,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 17:59:30,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'going', 'to', 'be', 'in@@', 'ver@@', 'su@@', 's', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'a', 'g@@', 'las@@', 's', '.', '</s>']
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Hypothesis: It &apos;s going to be inversus and you &apos;re going to be a glass .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - Example #4
2024-05-27 17:59:30,551 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 17:59:30,551 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 17:59:30,551 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'to', 'be', 'a', 're@@', 'duce', 'a', 'car@@', 'ri@@', 'ri@@', 'ri@@', 'st', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:59:30,551 - INFO - joeynmt.training - 	Hypothesis: The next next to be a reduce a carriririst to the last 25 years .
2024-05-27 17:59:54,913 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.933453, Batch Acc: 0.450707, Tokens per Sec:     2866, Lr: 0.000300
2024-05-27 18:00:20,169 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.096066, Batch Acc: 0.459608, Tokens per Sec:     2797, Lr: 0.000300
2024-05-27 18:00:45,548 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     2.043733, Batch Acc: 0.456175, Tokens per Sec:     2756, Lr: 0.000300
2024-05-27 18:01:09,564 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     2.085935, Batch Acc: 0.460776, Tokens per Sec:     2850, Lr: 0.000300
2024-05-27 18:01:33,498 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.091363, Batch Acc: 0.468241, Tokens per Sec:     2938, Lr: 0.000300
2024-05-27 18:01:33,499 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:01:33,500 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:02:32,554 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.14, ppl:   8.51, acc:   0.44, generation: 59.0477[sec], evaluation: 0.0000[sec]
2024-05-27 18:02:32,558 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:02:32,694 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/2500.ckpt
2024-05-27 18:02:32,699 - INFO - joeynmt.training - Example #0
2024-05-27 18:02:32,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:02:32,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:02:32,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;ve', 'got', 'to', 'show', 'these', 'two', 'two', 'two', ',', 'which', 'is', 'the', 'ab@@', 'ab@@', 'ab@@', 'ab@@', 'les', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'of', 'the', '4@@', '8', ',', 'which', 'has', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', ',', 'it', '&apos;s', 're@@', 'qui@@', 'res', ',', 'is', 're@@', 'qui@@', 'res', ',', 'it', '&apos;s', 're@@', 'qui@@', 'res', ',', 'which', 'is', 're@@', 'qui@@', 'res', 'to', 'be', 're@@', 'qui@@', 'res', '.', '</s>']
2024-05-27 18:02:32,699 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:02:32,699 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:02:32,699 - INFO - joeynmt.training - 	Hypothesis: I &apos;ve got to show these two two two , which is the abababables , which is almost three million years of the 48 , which has had the size of 48 , the United States , it &apos;s requires , is requires , it &apos;s requires , which is requires to be requires .
2024-05-27 18:02:32,699 - INFO - joeynmt.training - Example #1
2024-05-27 18:02:32,699 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:02:32,699 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:02:32,699 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'that', '&apos;s', 'the', 'dang@@', 'al@@', 'y', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'see', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Hypothesis: And that &apos;s the dangaly of the problem because it doesn &apos;t see the ice of the ice .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - Example #2
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'we@@', 'we@@', 'ight', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'change', ',', 'the', 'heart', 'of', 'the', 'climate', 'change', '.', '</s>']
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Hypothesis: The weweight is , in a sense , the heart of the change , the heart of the climate change .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - Example #3
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'going', 'to', 'be', 're@@', 'ver@@', 'se', 'and', 'you', 'get', 'a', 't@@', 'esting', '.', '</s>']
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Hypothesis: It &apos;s going to be reverse and you get a testing .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - Example #4
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:02:32,700 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'present@@', 'ed', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:02:32,700 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable represented to the last 25 years .
2024-05-27 18:02:56,259 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     1.993593, Batch Acc: 0.469205, Tokens per Sec:     2958, Lr: 0.000300
2024-05-27 18:03:20,305 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.973475, Batch Acc: 0.468947, Tokens per Sec:     2943, Lr: 0.000300
2024-05-27 18:03:47,649 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.983774, Batch Acc: 0.469359, Tokens per Sec:     2586, Lr: 0.000300
2024-05-27 18:04:11,609 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.714281, Batch Acc: 0.479999, Tokens per Sec:     2990, Lr: 0.000300
2024-05-27 18:04:35,740 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.178111, Batch Acc: 0.480125, Tokens per Sec:     3031, Lr: 0.000300
2024-05-27 18:04:35,741 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:04:35,741 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:05:34,963 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.00, acc:   0.46, generation: 59.2152[sec], evaluation: 0.0000[sec]
2024-05-27 18:05:34,965 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:05:35,090 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/3000.ckpt
2024-05-27 18:05:35,093 - INFO - joeynmt.training - Example #0
2024-05-27 18:05:35,093 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:05:35,093 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'showed', 'these', 'slide', 'to', 'the', 'slide', 'that', 'the', 'calc@@', 'ul@@', 'ate', 's@@', 'ev@@', 'al', 'w@@', 'ild', ',', 'which', 'for', 'three', 'million', 'years', 'of', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', ',', 'is', 're@@', 'qui@@', 'et', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these slide to the slide that the calculate seval wild , which for three million years of years has had the size of 48 , the size of 48 , is requiet of 40 percent .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - Example #1
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', ',', 'in', 'the', 'way', 'that', 'we', 'have', 'the', 'grav@@', 'ity', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Hypothesis: But , in the way that we have the gravity of the ice of the ice .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - Example #2
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'calc@@', 'ul@@', 'f', 'w@@', 'ild', 'w@@', 'ild', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'climate', 'system', '.', '</s>']
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - 	Hypothesis: The calculf wild wild is , in a sense , the heart of the climate system .
2024-05-27 18:05:35,094 - INFO - joeynmt.training - Example #3
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:05:35,094 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'in', 'in@@', 'ver@@', 'n', 'and', 'you', '&apos;re', 'r@@', 'iti@@', 'er', '.', '</s>']
2024-05-27 18:05:35,095 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:05:35,095 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:05:35,095 - INFO - joeynmt.training - 	Hypothesis: It expanded up in invern and you &apos;re ritier .
2024-05-27 18:05:35,095 - INFO - joeynmt.training - Example #4
2024-05-27 18:05:35,095 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:05:35,095 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:05:35,095 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'slide', 'here', 'is', 'going', 'to', 'be', 'a', 're@@', '-@@', 're@@', '-@@', 're@@', '-@@', 's@@', 'ev@@', 'entu@@', 'ally', 're@@', 'ven@@', 'ven@@', 'ue', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:05:35,095 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:05:35,095 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:05:35,095 - INFO - joeynmt.training - 	Hypothesis: The next slide slide here is going to be a re-re-re-seventually revenvenue of the last 25 years .
2024-05-27 18:05:59,762 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.960853, Batch Acc: 0.484641, Tokens per Sec:     2816, Lr: 0.000300
2024-05-27 18:06:23,903 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.789927, Batch Acc: 0.478080, Tokens per Sec:     2891, Lr: 0.000300
2024-05-27 18:06:48,033 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.833455, Batch Acc: 0.484789, Tokens per Sec:     2952, Lr: 0.000300
2024-05-27 18:07:12,163 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     2.093164, Batch Acc: 0.489794, Tokens per Sec:     2924, Lr: 0.000300
2024-05-27 18:07:36,797 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.835325, Batch Acc: 0.488464, Tokens per Sec:     2866, Lr: 0.000300
2024-05-27 18:07:36,798 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:07:36,798 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:08:32,558 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.05, ppl:   7.75, acc:   0.46, generation: 55.7537[sec], evaluation: 0.0000[sec]
2024-05-27 18:08:32,560 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:08:32,674 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/3500.ckpt
2024-05-27 18:08:32,678 - INFO - joeynmt.training - Example #0
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'showed', 'these', 'slide', 'to', 'show', 'that', 'the', 'calc@@', 'ul@@', 'ate', 'se@@', 'ar@@', 'ch', 'that', 'the', 'calc@@', 'ul@@', 'ar@@', 't@@', 'ics', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'you', '&apos;re', 'going', 'to', 'be', 'a', '40', 'percent', '.', '</s>']
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these slide to show that the calculate search that the calculartics , which for almost three million years had the size of 48 United States , you &apos;re going to be a 40 percent .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - Example #1
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'in', 'the', 'end', 'of', 'the', 'world', ',', 'because', 'it', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Hypothesis: But in the end of the world , because it &apos;s the gravity of the ice .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - Example #2
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'calc@@', 'ul@@', 'ul@@', 'ul@@', 'ar@@', 't@@', 'ics', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'climate', 'climate', 'change', '.', '</s>']
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - 	Hypothesis: The calculululartics is , in a sense , the heart of the climate climate change .
2024-05-27 18:08:32,679 - INFO - joeynmt.training - Example #3
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:08:32,679 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:08:32,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'ex@@', 'pan@@', 'ded', 'in', 'in@@', 'ver@@', 's', 'and', 'you', '&apos;re', 'r@@', 'iti@@', 'on@@', 'ing', '.', '</s>']
2024-05-27 18:08:32,680 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:08:32,680 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:08:32,680 - INFO - joeynmt.training - 	Hypothesis: You &apos;re expanded in invers and you &apos;re ritioning .
2024-05-27 18:08:32,680 - INFO - joeynmt.training - Example #4
2024-05-27 18:08:32,680 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:08:32,680 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:08:32,680 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 's@@', 'ev@@', 'en@@', 'en@@', 'se', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:08:32,680 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:08:32,680 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:08:32,680 - INFO - joeynmt.training - 	Hypothesis: The next slide to be a carrying to be a carrying sevenense the last 25 years .
2024-05-27 18:08:55,545 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.794499, Batch Acc: 0.490808, Tokens per Sec:     3060, Lr: 0.000300
2024-05-27 18:09:19,335 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.852985, Batch Acc: 0.493366, Tokens per Sec:     2966, Lr: 0.000300
2024-05-27 18:09:43,023 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.868476, Batch Acc: 0.493546, Tokens per Sec:     2989, Lr: 0.000300
2024-05-27 18:10:06,617 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.776114, Batch Acc: 0.499375, Tokens per Sec:     3020, Lr: 0.000300
2024-05-27 18:10:29,848 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     2.030073, Batch Acc: 0.487941, Tokens per Sec:     3066, Lr: 0.000300
2024-05-27 18:10:29,849 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:10:29,849 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:11:30,216 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.99, ppl:   7.34, acc:   0.48, generation: 60.3599[sec], evaluation: 0.0000[sec]
2024-05-27 18:11:30,218 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:11:30,337 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/4000.ckpt
2024-05-27 18:11:30,344 - INFO - joeynmt.training - Example #0
2024-05-27 18:11:30,344 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:11:30,344 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:11:30,344 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'last', 'year', 'I', 'showed', 'these', 'two', 'two', 'two', 'two', 'two', 'two', 'million', 'years', 'of', 'the', 'U.S.', ',', 'which', 'is', 'that', 'for', 'almost', 'three', 'million', 'years', 'of', 'the', 'United', 'States', ',', 'that', '&apos;s', 'going', 'to', 'be', 'the', 'size', 'of', '4@@', '8', ',', 'you', '&apos;ve', 'got', 'the', 'size', 'of', 'the', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Hypothesis: So last year I showed these two two two two two two million years of the U.S. , which is that for almost three million years of the United States , that &apos;s going to be the size of 48 , you &apos;ve got the size of the 48 percent .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - Example #1
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', '&apos;s', 'the', 'very', 'very', 'far', 'as', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'ex@@', 'tra', 'the', 'ice', '.', '</s>']
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Hypothesis: But that &apos;s the very very far as the gravity of the problem because it doesn &apos;t exextra the ice .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - Example #2
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'calc@@', 'ul@@', 'ate', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', ',', 'is', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'global', 'system', '.', '</s>']
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial glacial , is in a sense , the heart of the global global system .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - Example #3
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:11:30,345 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;ve', 'got', 'to', 'in@@', 'ver@@', 'su@@', 's', 'and', 'you', 'get', 'to', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - 	Hypothesis: You &apos;ve got to inversus and you get to the summer .
2024-05-27 18:11:30,345 - INFO - joeynmt.training - Example #4
2024-05-27 18:11:30,346 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:11:30,346 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:11:30,346 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'a', 're@@', 'mark@@', 'able', 're@@', 'duc@@', 'ed', 'to', 'be', 'a', 're@@', 'duc@@', 'ed', 're@@', 'duc@@', 'ed', 'by', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:11:30,346 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:11:30,346 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:11:30,346 - INFO - joeynmt.training - 	Hypothesis: The next slide is a remarkable reduced to be a reduced reduced by the last 25 years .
2024-05-27 18:11:53,059 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.836450, Batch Acc: 0.494826, Tokens per Sec:     3097, Lr: 0.000300
2024-05-27 18:12:16,598 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     2.178180, Batch Acc: 0.495648, Tokens per Sec:     2982, Lr: 0.000300
2024-05-27 18:12:39,487 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.794446, Batch Acc: 0.504529, Tokens per Sec:     3126, Lr: 0.000300
2024-05-27 18:13:02,726 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.718333, Batch Acc: 0.506152, Tokens per Sec:     3029, Lr: 0.000300
2024-05-27 18:13:25,922 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.721853, Batch Acc: 0.499747, Tokens per Sec:     3062, Lr: 0.000300
2024-05-27 18:13:25,924 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:13:25,924 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:14:20,706 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.97, ppl:   7.19, acc:   0.48, generation: 54.7759[sec], evaluation: 0.0000[sec]
2024-05-27 18:14:20,707 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:14:20,818 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/4500.ckpt
2024-05-27 18:14:20,826 - INFO - joeynmt.training - Example #0
2024-05-27 18:14:20,826 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:14:20,826 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:14:20,826 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'showed', 'these', 'slide', 'to', 'show', 'that', 'the', 'calc@@', 'ul@@', 'ate', 'that', 'the', 'calc@@', 'ul@@', 'ating', 'of', 'the', '4@@', '8', 'million', 'years', 'of', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 'a', '40', 'percent', 'of', 'the', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 'a', '40', 'percent', '.', '</s>']
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these slide to show that the calculate that the calculating of the 48 million years of the size of the 48 continental , it &apos;s a 40 percent of the continental , it &apos;s a 40 percent .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - Example #1
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', ',', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'the', 'end', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', '.', '</s>']
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Hypothesis: But that &apos;s the gravity of the problem , because it doesn &apos;t show the the end of the problem because it doesn &apos;t show it .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - Example #2
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'al', 'gl@@', 'aci@@', 'al', ',', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'system', '.', '</s>']
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Hypothesis: The artal glacial , is , in a sense , the heart of the global system .
2024-05-27 18:14:20,827 - INFO - joeynmt.training - Example #3
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:14:20,827 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'got', 'to', 'in@@', 'ver@@', 'se', 'and', 'you', 'get', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 18:14:20,827 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:14:20,828 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:14:20,828 - INFO - joeynmt.training - 	Hypothesis: It &apos;s got to inverse and you get the summer .
2024-05-27 18:14:20,828 - INFO - joeynmt.training - Example #4
2024-05-27 18:14:20,828 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:14:20,828 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:14:20,828 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'to', 'be', 'a', 're@@', 'duc@@', 'ed', 're@@', 'duc@@', 'ed', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:14:20,828 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:14:20,828 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:14:20,828 - INFO - joeynmt.training - 	Hypothesis: The next slide to be a reduced reduced the last 25 years .
2024-05-27 18:14:42,838 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.793634, Batch Acc: 0.505363, Tokens per Sec:     3100, Lr: 0.000300
2024-05-27 18:15:06,080 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.844608, Batch Acc: 0.501038, Tokens per Sec:     2964, Lr: 0.000300
2024-05-27 18:15:29,139 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.765043, Batch Acc: 0.507671, Tokens per Sec:     3093, Lr: 0.000300
2024-05-27 18:15:52,770 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.679969, Batch Acc: 0.509750, Tokens per Sec:     2971, Lr: 0.000300
2024-05-27 18:16:15,525 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.832381, Batch Acc: 0.505351, Tokens per Sec:     2989, Lr: 0.000300
2024-05-27 18:16:15,525 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:16:15,525 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:17:08,981 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.94, ppl:   6.94, acc:   0.49, generation: 53.4500[sec], evaluation: 0.0000[sec]
2024-05-27 18:17:08,983 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:17:09,102 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/5000.ckpt
2024-05-27 18:17:09,108 - INFO - joeynmt.training - Example #0
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'showed', 'these', 'slide', 'slide', 'slide', 'to', 'show', 'that', 'the', 'cal@@', 'm', 'of', 'the', 'ar@@', 't@@', 'ics', 'of', 'the', 'ar@@', 't@@', 'ics', 'of', 'the', '4@@', '8', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'the', 'size', 'of', 'the', '4@@', '8', ',', 'the', 'size', 'of', 'the', '4@@', '8', '.', '</s>']
2024-05-27 18:17:09,108 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:17:09,108 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:17:09,108 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slide slide slide to show that the calm of the artics of the artics of the 48 , which for almost three million years , the size of the 48 , the size of the 48 .
2024-05-27 18:17:09,108 - INFO - joeynmt.training - Example #1
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'in', 'the', 'way', ',', 'you', 'have', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'ice', '.', '</s>']
2024-05-27 18:17:09,108 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:17:09,108 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:17:09,108 - INFO - joeynmt.training - 	Hypothesis: But in the way , you have the gravity of the problem because it doesn &apos;t show the spessor of ice .
2024-05-27 18:17:09,108 - INFO - joeynmt.training - Example #2
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:17:09,108 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ics', 'of', 'the', 'ar@@', 't@@', 'ics', 'of', 'the', 'global', 'global', 'global', 'global', '.', '</s>']
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Hypothesis: The artics of the artics of the global global global global .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - Example #3
2024-05-27 18:17:09,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:17:09,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:17:09,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ds', '.', '</s>']
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expands .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - Example #4
2024-05-27 18:17:09,109 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:17:09,109 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:17:09,109 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'will', 'be', 'a', 're@@', 'qui@@', 'res', 'to', 'be', 'a', 're@@', 'ven@@', 'ue', 're@@', 'ven@@', 'ue', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:17:09,109 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a requires to be a revenue revenue of the last 25 years .
2024-05-27 18:17:31,860 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     2.102947, Batch Acc: 0.506278, Tokens per Sec:     3109, Lr: 0.000300
2024-05-27 18:17:54,636 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.865749, Batch Acc: 0.502745, Tokens per Sec:     3008, Lr: 0.000300
2024-05-27 18:18:07,326 - INFO - joeynmt.training - Epoch   2: total training loss 7666.97
2024-05-27 18:18:07,327 - INFO - joeynmt.training - EPOCH 3
2024-05-27 18:18:17,405 - INFO - joeynmt.training - Epoch   3, Step:     7800, Batch Loss:     1.623690, Batch Acc: 0.532750, Tokens per Sec:     3006, Lr: 0.000300
2024-05-27 18:18:40,625 - INFO - joeynmt.training - Epoch   3, Step:     7900, Batch Loss:     1.703181, Batch Acc: 0.535585, Tokens per Sec:     3012, Lr: 0.000300
2024-05-27 18:19:03,501 - INFO - joeynmt.training - Epoch   3, Step:     8000, Batch Loss:     1.969967, Batch Acc: 0.534362, Tokens per Sec:     3067, Lr: 0.000300
2024-05-27 18:19:03,502 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:19:03,502 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:19:53,803 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.91, ppl:   6.75, acc:   0.49, generation: 50.2940[sec], evaluation: 0.0000[sec]
2024-05-27 18:19:53,805 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:19:53,925 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/5500.ckpt
2024-05-27 18:19:53,930 - INFO - joeynmt.training - Example #0
2024-05-27 18:19:53,930 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:19:53,930 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:19:53,930 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'showed', 'these', 'very', 'few', 'few', 'few', 'few', 'few', 'years', ',', 'which', 'the', 'ar@@', 't@@', 't@@', 'al', 'of', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'of', 'the', 'United', 'States', ',', 'it', '&apos;s', 're@@', 'mot@@', 'e', 'the', 'United', 'States', ',', 'it', '&apos;s', 're@@', 'mark@@', 'able', '.', '</s>']
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these very few few few few few years , which the arttal of the artica , which is almost three million years of the United States , it &apos;s remote the United States , it &apos;s remarkable .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - Example #1
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', 'would', 'be', 'the', 'ast@@', 'est', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'p', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Hypothesis: But it would be the astest gravity of the problem because it doesn &apos;t exhip the ice of the ice .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - Example #2
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'he@@', 'at', 'of', 'the', 'ar@@', 't@@', 'ic', 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Hypothesis: The heat of the artic glacial is , in a sense , the heart of global climate system .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - Example #3
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:19:53,931 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'see', 'the', 'in@@', 'ver@@', 'se', 'of', 'the', 'in@@', 'ver@@', 'se', 'and', 'you', '&apos;re', 'r@@', 'iti@@', 'ra', '.', '</s>']
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - 	Hypothesis: You see the inverse of the inverse and you &apos;re ritira .
2024-05-27 18:19:53,931 - INFO - joeynmt.training - Example #4
2024-05-27 18:19:53,932 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:19:53,932 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:19:53,932 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'slide', 'is', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 're@@', 'mot@@', 'e', 's@@', 'av@@', 'o@@', 'id', 're@@', 'ven@@', 'ess', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:19:53,932 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:19:53,932 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:19:53,932 - INFO - joeynmt.training - 	Hypothesis: The next next slide is to be a carrelated remote savoid reveness of the last 25 years .
2024-05-27 18:20:17,046 - INFO - joeynmt.training - Epoch   3, Step:     8100, Batch Loss:     1.884470, Batch Acc: 0.531771, Tokens per Sec:     3057, Lr: 0.000300
2024-05-27 18:20:39,600 - INFO - joeynmt.training - Epoch   3, Step:     8200, Batch Loss:     1.795207, Batch Acc: 0.527857, Tokens per Sec:     3145, Lr: 0.000300
2024-05-27 18:21:03,676 - INFO - joeynmt.training - Epoch   3, Step:     8300, Batch Loss:     1.549996, Batch Acc: 0.526077, Tokens per Sec:     2890, Lr: 0.000300
2024-05-27 18:21:26,239 - INFO - joeynmt.training - Epoch   3, Step:     8400, Batch Loss:     1.766568, Batch Acc: 0.532650, Tokens per Sec:     3057, Lr: 0.000300
2024-05-27 18:21:49,201 - INFO - joeynmt.training - Epoch   3, Step:     8500, Batch Loss:     1.664082, Batch Acc: 0.532934, Tokens per Sec:     3050, Lr: 0.000300
2024-05-27 18:21:49,202 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:21:49,202 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:22:34,759 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.89, ppl:   6.65, acc:   0.50, generation: 45.5507[sec], evaluation: 0.0000[sec]
2024-05-27 18:22:34,762 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:22:34,877 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/6000.ckpt
2024-05-27 18:22:34,881 - INFO - joeynmt.training - Example #0
2024-05-27 18:22:34,881 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'showed', 'these', 'slide', 'slide', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'calc@@', 'ul@@', 'us', ',', 'which', 'was', 'about', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', 'the', '4@@', '8', ',', 'the', 'United', 'States', 'of', 'the', 'contin@@', 'ent', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slide slide to demonstrate that the calculus , which was about three million years has had the size of the 48 , the United States of the continent , it &apos;s restrip , it &apos;s restrip of 40 percent .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - Example #1
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', '&apos;s', 'the', 'way', 'that', 'it', '&apos;s', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Hypothesis: But that &apos;s the way that it &apos;s gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - Example #2
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'calc@@', 'ul@@', 'ate', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'ate', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial calculate is , in a sense , the heart heart of global climate system .
2024-05-27 18:22:34,882 - INFO - joeynmt.training - Example #3
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:22:34,882 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', 'get', 'away', 'from', 'sum@@', 'mer', '.', '</s>']
2024-05-27 18:22:34,883 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:22:34,883 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:22:34,883 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and you get away from summer .
2024-05-27 18:22:34,883 - INFO - joeynmt.training - Example #4
2024-05-27 18:22:34,883 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:22:34,883 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:22:34,883 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 'slide', 'will', 'be', 'a', 'car@@', 'rel@@', 'ated', 're@@', 'ven@@', 'ue', 'to', 's@@', 'ev@@', 'entu@@', 'ally', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:22:34,883 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:22:34,883 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:22:34,883 - INFO - joeynmt.training - 	Hypothesis: The next next slide will be a carrelated revenue to seventually the last 25 years .
2024-05-27 18:22:57,811 - INFO - joeynmt.training - Epoch   3, Step:     8600, Batch Loss:     2.010540, Batch Acc: 0.529522, Tokens per Sec:     3137, Lr: 0.000300
2024-05-27 18:23:21,373 - INFO - joeynmt.training - Epoch   3, Step:     8700, Batch Loss:     1.532461, Batch Acc: 0.530211, Tokens per Sec:     3041, Lr: 0.000300
2024-05-27 18:23:44,682 - INFO - joeynmt.training - Epoch   3, Step:     8800, Batch Loss:     1.754444, Batch Acc: 0.531429, Tokens per Sec:     3067, Lr: 0.000300
2024-05-27 18:24:07,643 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.619716, Batch Acc: 0.530541, Tokens per Sec:     3071, Lr: 0.000300
2024-05-27 18:24:30,104 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.783748, Batch Acc: 0.532159, Tokens per Sec:     3085, Lr: 0.000300
2024-05-27 18:24:30,105 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:24:30,105 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:25:20,166 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.53, acc:   0.50, generation: 50.0542[sec], evaluation: 0.0000[sec]
2024-05-27 18:25:20,168 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:25:20,287 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/6500.ckpt
2024-05-27 18:25:20,291 - INFO - joeynmt.training - Example #0
2024-05-27 18:25:20,291 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:25:20,291 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:25:20,291 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'slide', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 't@@', 'ica', 'calc@@', 'ul@@', 'al', 'calc@@', 'ul@@', 'al', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'of', 'the', 'United', 'States', 'contin@@', 'ent', ',', 'you', 'know', ',', '40', 'percent', 'of', 'the', 'United', 'States', 'contin@@', 'ent', ',', 'you', 'know', ',', '40', 'percent', '.', '</s>']
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide to demonstrate that the artica calculal calculal , which for almost three million years of the United States continent , you know , 40 percent of the United States continent , you know , 40 percent .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - Example #1
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'there', 'is', 'the', 'grav@@', 'ity', 'of', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', ',', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'p', 'in', 'the', 'ice', '.', '</s>']
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Hypothesis: But there is the gravity of the gravity of the problem , because it &apos;s not exhip in the ice .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - Example #2
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ab@@', 'les', 'gl@@', 'aci@@', 'al', ',', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'global', 'global', 'global', 'global', 'global', 'system', '.', '</s>']
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - 	Hypothesis: The artables glacial , is , in a sense , the heart of global global global global global global system .
2024-05-27 18:25:20,292 - INFO - joeynmt.training - Example #3
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:25:20,292 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'trem@@', 'ely', 'in@@', 'ver@@', 'se', 'and', 'you', 'get', 'sum@@', 'm@@', 'it', '.', '</s>']
2024-05-27 18:25:20,293 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:25:20,293 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:25:20,293 - INFO - joeynmt.training - 	Hypothesis: It &apos;s extremely inverse and you get summit .
2024-05-27 18:25:20,293 - INFO - joeynmt.training - Example #4
2024-05-27 18:25:20,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:25:20,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:25:20,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'will', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'ven@@', 'ue', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:25:20,293 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:25:20,293 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:25:20,293 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a remarkable remarkable to be a remarkable revenue of the last 25 years .
2024-05-27 18:25:42,648 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.718663, Batch Acc: 0.534248, Tokens per Sec:     3193, Lr: 0.000300
2024-05-27 18:26:05,367 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.729292, Batch Acc: 0.529941, Tokens per Sec:     3059, Lr: 0.000300
2024-05-27 18:26:27,770 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.650414, Batch Acc: 0.532506, Tokens per Sec:     3075, Lr: 0.000300
2024-05-27 18:26:51,974 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.475745, Batch Acc: 0.530611, Tokens per Sec:     2902, Lr: 0.000300
2024-05-27 18:27:16,339 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.626953, Batch Acc: 0.540294, Tokens per Sec:     2950, Lr: 0.000300
2024-05-27 18:27:16,340 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:27:16,340 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:28:00,801 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.87, ppl:   6.52, acc:   0.50, generation: 44.4548[sec], evaluation: 0.0000[sec]
2024-05-27 18:28:00,804 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:28:00,933 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/7000.ckpt
2024-05-27 18:28:00,936 - INFO - joeynmt.training - Example #0
2024-05-27 18:28:00,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:28:00,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:28:00,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'tic', 'gl@@', 'aci@@', 'al', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'of', 'the', 'United', 'States', ',', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', 'the', 'contin@@', 'ent', ',', 'you', 'know', ',', 'it', '&apos;s', 're@@', 'duc@@', 'ed', '40', 'percent', '.', '</s>']
2024-05-27 18:28:00,936 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:28:00,936 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:28:00,936 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arttic glacial , which is almost three million years of the United States , the size of 48 , the United States of the continent , you know , it &apos;s reduced 40 percent .
2024-05-27 18:28:00,936 - INFO - joeynmt.training - Example #1
2024-05-27 18:28:00,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:28:00,936 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:28:00,936 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'if', 'you', 'have', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'p', 'the', 'ice', '.', '</s>']
2024-05-27 18:28:00,936 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:28:00,936 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:28:00,936 - INFO - joeynmt.training - 	Hypothesis: But if you have this underneath the gravity of the problem because it doesn &apos;t exhip the ice .
2024-05-27 18:28:00,936 - INFO - joeynmt.training - Example #2
2024-05-27 18:28:00,936 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'he@@', 'at', 'gl@@', 'aci@@', 'al', 'aci@@', 'al', ',', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'climate', 'climate', 'system', '.', '</s>']
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Hypothesis: The heat glacial acial , is , in a certain sense , the heart of global climate climate climate system .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - Example #3
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'and', 'you', 'get', 'a', 'w@@', 'it@@', 'er', '.', '</s>']
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded and you get a witer .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - Example #4
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:28:00,937 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'ven@@', 'ue', 'to', 's@@', 'ell', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:28:00,937 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable revenue to sell the last 25 years .
2024-05-27 18:28:23,377 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.610713, Batch Acc: 0.538266, Tokens per Sec:     3214, Lr: 0.000300
2024-05-27 18:28:47,687 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.640144, Batch Acc: 0.538190, Tokens per Sec:     2971, Lr: 0.000300
2024-05-27 18:29:17,430 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.665142, Batch Acc: 0.540692, Tokens per Sec:     2477, Lr: 0.000300
2024-05-27 18:29:41,449 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.531097, Batch Acc: 0.534427, Tokens per Sec:     2988, Lr: 0.000300
2024-05-27 18:30:04,253 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.757107, Batch Acc: 0.541072, Tokens per Sec:     3004, Lr: 0.000300
2024-05-27 18:30:04,253 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:30:04,253 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:30:56,304 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.36, acc:   0.51, generation: 52.0447[sec], evaluation: 0.0000[sec]
2024-05-27 18:30:56,306 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:30:56,424 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/7500.ckpt
2024-05-27 18:30:56,430 - INFO - joeynmt.training - Example #0
2024-05-27 18:30:56,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:30:56,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:30:56,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'slide', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'cal@@', 'ving', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'of', 'the', 'United', 'States', 'contin@@', 'ent', ',', 'the', 'U.S.', 'U.S.', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent', ',', 'and', 'it', '&apos;s', 're@@', 'str@@', 'ing', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:30:56,430 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:30:56,430 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:30:56,430 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide to show that the artica calving the artica , which is almost three million years of the United States continent , the U.S. U.S. continental continent , and it &apos;s restring of 40 percent .
2024-05-27 18:30:56,430 - INFO - joeynmt.training - Example #1
2024-05-27 18:30:56,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:30:56,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:30:56,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'in', 'the', 'way', 'that', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'in', 'the', 'ice', '.', '</s>']
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Hypothesis: But in the way that underlying the gravity of the problem because it doesn &apos;t show it in the ice .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - Example #2
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'climate', 'climate', 'system', '.', '</s>']
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Hypothesis: The artica glacial calculus is , in a certain sense , the heart of global climate climate climate system .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - Example #3
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', '&apos;re', 'r@@', 'iti@@', 'ra', 'in', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and you &apos;re ritira in the summer .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - Example #4
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:30:56,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'will', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'qui@@', 'red', 'up', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:30:56,431 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:30:56,432 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a remarkable required up to the last 25 years .
2024-05-27 18:31:18,724 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.855348, Batch Acc: 0.537819, Tokens per Sec:     3231, Lr: 0.000300
2024-05-27 18:31:42,060 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.744914, Batch Acc: 0.537663, Tokens per Sec:     2980, Lr: 0.000300
2024-05-27 18:32:07,795 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.648758, Batch Acc: 0.537805, Tokens per Sec:     2723, Lr: 0.000300
2024-05-27 18:32:32,211 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.620298, Batch Acc: 0.537594, Tokens per Sec:     2861, Lr: 0.000300
2024-05-27 18:32:58,264 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.942522, Batch Acc: 0.539520, Tokens per Sec:     2744, Lr: 0.000300
2024-05-27 18:32:58,265 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:32:58,265 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:33:43,394 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.83, ppl:   6.23, acc:   0.51, generation: 45.1230[sec], evaluation: 0.0000[sec]
2024-05-27 18:33:43,397 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:33:43,524 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/8000.ckpt
2024-05-27 18:33:43,528 - INFO - joeynmt.training - Example #0
2024-05-27 18:33:43,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:33:43,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:33:43,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'last', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'calc@@', 'ul@@', 'us', 'that', 'the', 'calc@@', 'ul@@', 'us', ',', 'which', 'is', 'a', 'three', 'million', 'years', 'of', 'the', 'United', 'States', 'contin@@', 'ent', ',', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', 'contin@@', 'ent', ',', 'is', 're@@', 'str@@', 'ugg@@', 'le', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:33:43,528 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:33:43,528 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:33:43,528 - INFO - joeynmt.training - 	Hypothesis: So last year I showed these slides to show that the calculus that the calculus , which is a three million years of the United States continent , the size of the 48 United States continent , is restruggle of 40 percent .
2024-05-27 18:33:43,528 - INFO - joeynmt.training - Example #1
2024-05-27 18:33:43,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:33:43,528 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:33:43,528 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'p', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'p', 'of', 'ice', '.', '</s>']
2024-05-27 18:33:43,528 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:33:43,528 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:33:43,528 - INFO - joeynmt.training - 	Hypothesis: But that &apos;s the gravity of the problem because it &apos;s not exhip the problem because it &apos;s not exhip of ice .
2024-05-27 18:33:43,528 - INFO - joeynmt.training - Example #2
2024-05-27 18:33:43,528 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'calc@@', 'ul@@', 'us', 'of', 'the', 'ar@@', 't@@', 'ics', 'of', 'the', 'climate', 'system', '.', '</s>']
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Hypothesis: The calculus of the artics of the climate system .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - Example #3
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', 'get', 'sum@@', 'm@@', 'it', '.', '</s>']
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and you get summit .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - Example #4
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:33:43,529 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'will', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', '-@@', 'up', ',', 'the', 'next', 'time', 'is', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:33:43,529 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a remarkable re-up , the next time is the last 25 years .
2024-05-27 18:34:06,523 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.685541, Batch Acc: 0.542402, Tokens per Sec:     2973, Lr: 0.000300
2024-05-27 18:34:30,309 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.910601, Batch Acc: 0.543269, Tokens per Sec:     2932, Lr: 0.000300
2024-05-27 18:34:53,743 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.774746, Batch Acc: 0.542168, Tokens per Sec:     2974, Lr: 0.000300
2024-05-27 18:35:17,544 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.652818, Batch Acc: 0.549060, Tokens per Sec:     2911, Lr: 0.000300
2024-05-27 18:35:42,205 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.646676, Batch Acc: 0.543725, Tokens per Sec:     2836, Lr: 0.000300
2024-05-27 18:35:42,206 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:35:42,206 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:36:37,343 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.12, acc:   0.52, generation: 55.1309[sec], evaluation: 0.0000[sec]
2024-05-27 18:36:37,344 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:36:37,477 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/8500.ckpt
2024-05-27 18:36:37,482 - INFO - joeynmt.training - Example #0
2024-05-27 18:36:37,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:36:37,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:36:37,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 't@@', 'ic', 'cal@@', 'm', 'of', 'the', 'ar@@', 't@@', 'ic', 'gl@@', 'aci@@', 'al', 'of', 'the', '4@@', '8', 'United', 'States', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ents', ',', 'it', '&apos;s', 're@@', 'str@@', 'et', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:36:37,482 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:36:37,482 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:36:37,482 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slides to demonstrate that the artic calm of the artic glacial of the 48 United States had the size of 48 United States continents , it &apos;s restret of 40 percent .
2024-05-27 18:36:37,482 - INFO - joeynmt.training - Example #1
2024-05-27 18:36:37,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:36:37,482 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:36:37,482 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'going', 'to', 'be', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:36:37,482 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:36:37,482 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:36:37,482 - INFO - joeynmt.training - 	Hypothesis: But it &apos;s the gravity of the problem because it &apos;s not going to be spessor of the ice .
2024-05-27 18:36:37,482 - INFO - joeynmt.training - Example #2
2024-05-27 18:36:37,482 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Hypothesis: The artica glacial glacial is , in a sense , the heart of global climate system .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - Example #3
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'a', 'sum@@', 'mer', '.', '</s>']
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded and you &apos;re going to be a summer .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - Example #4
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:36:37,483 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 's@@', 'ell', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:36:37,483 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable to sell the last 25 years .
2024-05-27 18:37:01,719 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.576779, Batch Acc: 0.541963, Tokens per Sec:     2874, Lr: 0.000300
2024-05-27 18:37:26,488 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.812841, Batch Acc: 0.538829, Tokens per Sec:     2880, Lr: 0.000300
2024-05-27 18:37:51,052 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.525928, Batch Acc: 0.550224, Tokens per Sec:     2896, Lr: 0.000300
2024-05-27 18:38:17,665 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.635628, Batch Acc: 0.540797, Tokens per Sec:     2653, Lr: 0.000300
2024-05-27 18:38:42,237 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.759399, Batch Acc: 0.545141, Tokens per Sec:     2918, Lr: 0.000300
2024-05-27 18:38:42,237 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:38:42,237 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:39:33,423 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.06, acc:   0.52, generation: 51.1796[sec], evaluation: 0.0000[sec]
2024-05-27 18:39:33,425 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:39:33,551 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/9000.ckpt
2024-05-27 18:39:33,556 - INFO - joeynmt.training - Example #0
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', 'the', 'United', 'States', 'contin@@', 'ents', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:39:33,556 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:39:33,556 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:39:33,556 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slides to show that the glacial calculus , which for almost three million years had the size of 48 , the size of the United States continents , it &apos;s restrip of 40 percent .
2024-05-27 18:39:33,556 - INFO - joeynmt.training - Example #1
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'going', 'to', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:39:33,556 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:39:33,556 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:39:33,556 - INFO - joeynmt.training - 	Hypothesis: But that &apos;s the gravity of the problem because it &apos;s not going to show the ice of the ice .
2024-05-27 18:39:33,556 - INFO - joeynmt.training - Example #2
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:39:33,556 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'system', '.', '</s>']
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Hypothesis: The artica glacial glacial is , in a sense , the heart of global system .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - Example #3
2024-05-27 18:39:33,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:39:33,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:39:33,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', '&apos;re', 'r@@', 'iti@@', 'on@@', 'ed', 'in', 'sum@@', 'mer', '.', '</s>']
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Hypothesis: It expanded up and you &apos;re ritioned in summer .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - Example #4
2024-05-27 18:39:33,557 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:39:33,557 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:39:33,557 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 's@@', 'ell', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:39:33,557 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable to sell the last 25 years .
2024-05-27 18:39:58,095 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.740391, Batch Acc: 0.545179, Tokens per Sec:     2850, Lr: 0.000300
2024-05-27 18:40:03,991 - INFO - joeynmt.training - Epoch   3: total training loss 6652.70
2024-05-27 18:40:03,991 - INFO - joeynmt.training - EPOCH 4
2024-05-27 18:40:22,289 - INFO - joeynmt.training - Epoch   4, Step:    11700, Batch Loss:     1.658918, Batch Acc: 0.565776, Tokens per Sec:     2939, Lr: 0.000300
2024-05-27 18:40:45,917 - INFO - joeynmt.training - Epoch   4, Step:    11800, Batch Loss:     1.600730, Batch Acc: 0.557632, Tokens per Sec:     2951, Lr: 0.000300
2024-05-27 18:41:13,677 - INFO - joeynmt.training - Epoch   4, Step:    11900, Batch Loss:     1.547043, Batch Acc: 0.570202, Tokens per Sec:     2572, Lr: 0.000300
2024-05-27 18:41:37,351 - INFO - joeynmt.training - Epoch   4, Step:    12000, Batch Loss:     1.487878, Batch Acc: 0.567652, Tokens per Sec:     3000, Lr: 0.000300
2024-05-27 18:41:37,352 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:41:37,352 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:42:29,587 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.80, ppl:   6.03, acc:   0.52, generation: 52.2279[sec], evaluation: 0.0000[sec]
2024-05-27 18:42:29,589 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:42:29,708 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/9500.ckpt
2024-05-27 18:42:29,712 - INFO - joeynmt.training - Example #0
2024-05-27 18:42:29,712 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:42:29,712 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:42:29,712 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'gl@@', 'aci@@', 'al', 'aci@@', 'al', 'we@@', 'ar', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', ',', 'the', 'size', 'of', 'the', 'United', 'States', 'contin@@', 'ent', ',', 'it', '&apos;s', 're@@', 'ach@@', 'ing', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slides to demonstrate that the arglacial acial wear , which for almost three million years had the size of the 48 , the size of the United States continent , it &apos;s reaching of 40 percent .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - Example #1
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'in', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'p', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Hypothesis: But in this underneath the gravity of the problem because it &apos;s not exhip the ice of the ice of the ice .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - Example #2
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'aci@@', 'al', ',', 'is', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'climate', 'system', '.', '</s>']
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Hypothesis: The artica glacial acial , is in a sense , the heart of the climate system .
2024-05-27 18:42:29,713 - INFO - joeynmt.training - Example #3
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:42:29,713 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 18:42:29,713 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:42:29,714 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:42:29,714 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded .
2024-05-27 18:42:29,714 - INFO - joeynmt.training - Example #4
2024-05-27 18:42:29,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:42:29,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:42:29,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'relationship', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:42:29,714 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:42:29,714 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:42:29,714 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable relationship to the last 25 years .
2024-05-27 18:42:54,296 - INFO - joeynmt.training - Epoch   4, Step:    12100, Batch Loss:     1.676703, Batch Acc: 0.562628, Tokens per Sec:     2861, Lr: 0.000300
2024-05-27 18:43:18,571 - INFO - joeynmt.training - Epoch   4, Step:    12200, Batch Loss:     1.569103, Batch Acc: 0.566441, Tokens per Sec:     2944, Lr: 0.000300
2024-05-27 18:43:41,680 - INFO - joeynmt.training - Epoch   4, Step:    12300, Batch Loss:     1.889999, Batch Acc: 0.564205, Tokens per Sec:     2947, Lr: 0.000300
2024-05-27 18:44:05,697 - INFO - joeynmt.training - Epoch   4, Step:    12400, Batch Loss:     1.587842, Batch Acc: 0.565312, Tokens per Sec:     2929, Lr: 0.000300
2024-05-27 18:44:29,952 - INFO - joeynmt.training - Epoch   4, Step:    12500, Batch Loss:     1.689495, Batch Acc: 0.561149, Tokens per Sec:     2969, Lr: 0.000300
2024-05-27 18:44:29,953 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:44:29,953 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:45:28,441 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   5.99, acc:   0.52, generation: 58.4810[sec], evaluation: 0.0000[sec]
2024-05-27 18:45:28,443 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:45:28,566 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/10000.ckpt
2024-05-27 18:45:28,571 - INFO - joeynmt.training - Example #0
2024-05-27 18:45:28,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:45:28,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:45:28,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'cal@@', 'ving', 'gl@@', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', ',', 'the', 'size', 'of', 'the', 'contin@@', 'ent', ',', 'the', 'world', '&apos;s', '40', 'percent', '.', '</s>']
2024-05-27 18:45:28,571 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:45:28,571 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:45:28,571 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to show that the artica calving glacial acial acial acial acial acial acial acial acial acial , the size of the continent , the world &apos;s 40 percent .
2024-05-27 18:45:28,571 - INFO - joeynmt.training - Example #1
2024-05-27 18:45:28,571 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:45:28,571 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:45:28,571 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'if', 'you', 'have', 'this', 'under@@', 'ne@@', 'ath', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'from', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 18:45:28,571 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:45:28,571 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Hypothesis: But if you have this underneath gravity of the problem because it doesn &apos;t show it from the ice of ice .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - Example #2
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'aci@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Hypothesis: The artal acial acial acial is , in a sense , the heart of global climate system .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - Example #3
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'sum@@', 'mer', 'r@@', 'iti@@', 'er', '.', '</s>']
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Hypothesis: You &apos;re expanded up and summer ritier .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - Example #4
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:45:28,572 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 's@@', 'ell', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:45:28,572 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable to sell the last 25 years .
2024-05-27 18:45:51,841 - INFO - joeynmt.training - Epoch   4, Step:    12600, Batch Loss:     1.698412, Batch Acc: 0.559253, Tokens per Sec:     3068, Lr: 0.000300
2024-05-27 18:46:15,982 - INFO - joeynmt.training - Epoch   4, Step:    12700, Batch Loss:     1.661382, Batch Acc: 0.559241, Tokens per Sec:     2959, Lr: 0.000300
2024-05-27 18:46:41,967 - INFO - joeynmt.training - Epoch   4, Step:    12800, Batch Loss:     1.717284, Batch Acc: 0.563418, Tokens per Sec:     2708, Lr: 0.000300
2024-05-27 18:47:07,341 - INFO - joeynmt.training - Epoch   4, Step:    12900, Batch Loss:     1.543743, Batch Acc: 0.563454, Tokens per Sec:     2770, Lr: 0.000300
2024-05-27 18:47:30,682 - INFO - joeynmt.training - Epoch   4, Step:    13000, Batch Loss:     1.671230, Batch Acc: 0.563984, Tokens per Sec:     3023, Lr: 0.000300
2024-05-27 18:47:30,683 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:47:30,683 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:48:22,479 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.78, ppl:   5.92, acc:   0.52, generation: 51.7893[sec], evaluation: 0.0000[sec]
2024-05-27 18:48:22,481 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:48:22,595 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/10500.ckpt
2024-05-27 18:48:22,600 - INFO - joeynmt.training - Example #0
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'm', 'calc@@', 'ul@@', 'us', 'that', 'the', 'ar@@', 't@@', 'ica', 'of', 'ar@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ents', ',', 'it', '&apos;s', 're@@', 'com@@', 'fort@@', 'able', 'to', '40', 'percent', '.', '</s>']
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arm calculus that the artica of artica , which for almost three million years had the size of 48 United States continents , it &apos;s recomfortable to 40 percent .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - Example #1
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'sub@@', 'ject', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Hypothesis: However this subject the gravity of the problem because it doesn &apos;t show the ice of ice .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - Example #2
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'ate', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'global', 'global', 'system', '.', '</s>']
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - 	Hypothesis: The artica glacial calculate is , in a sense , the heart of the global global global system .
2024-05-27 18:48:22,601 - INFO - joeynmt.training - Example #3
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:48:22,601 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'sion', 'ex@@', 'pan@@', 'sion', '.', '</s>']
2024-05-27 18:48:22,602 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:48:22,602 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:48:22,602 - INFO - joeynmt.training - 	Hypothesis: It expansion expansion .
2024-05-27 18:48:22,602 - INFO - joeynmt.training - Example #4
2024-05-27 18:48:22,602 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:48:22,602 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:48:22,602 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 'r@@', 'ying', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:48:22,602 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:48:22,602 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:48:22,602 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelated rying to the last 25 years .
2024-05-27 18:48:46,152 - INFO - joeynmt.training - Epoch   4, Step:    13100, Batch Loss:     1.616728, Batch Acc: 0.562414, Tokens per Sec:     2976, Lr: 0.000300
2024-05-27 18:49:10,342 - INFO - joeynmt.training - Epoch   4, Step:    13200, Batch Loss:     1.634330, Batch Acc: 0.560504, Tokens per Sec:     2999, Lr: 0.000300
2024-05-27 18:49:33,120 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.503222, Batch Acc: 0.561903, Tokens per Sec:     3050, Lr: 0.000300
2024-05-27 18:49:56,655 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.581416, Batch Acc: 0.567168, Tokens per Sec:     3066, Lr: 0.000300
2024-05-27 18:50:20,034 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.902166, Batch Acc: 0.560378, Tokens per Sec:     2963, Lr: 0.000300
2024-05-27 18:50:20,035 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:50:20,035 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:51:09,617 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.77, ppl:   5.88, acc:   0.53, generation: 49.5745[sec], evaluation: 0.0000[sec]
2024-05-27 18:51:09,619 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:51:09,745 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/11000.ckpt
2024-05-27 18:51:09,750 - INFO - joeynmt.training - Example #0
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ugg@@', 'le', 'that', 'gl@@', 'aci@@', 'al', 'cal@@', 'm', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', ',', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'fl@@', 'ected', 'for', '40', 'percent', '.', '</s>']
2024-05-27 18:51:09,750 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:51:09,750 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:51:09,750 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstruggle that glacial calm , which for almost three million years had the size of the 48 , the size of the 48 United States continental , it &apos;s reflected for 40 percent .
2024-05-27 18:51:09,750 - INFO - joeynmt.training - Example #1
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', ',', 'you', 'have', 'this', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'b@@', 'ition', 'of', 'ice', '.', '</s>']
2024-05-27 18:51:09,750 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:51:09,750 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:51:09,750 - INFO - joeynmt.training - 	Hypothesis: But , you have this underlying the gravity of the problem because it doesn &apos;t exhibition of ice .
2024-05-27 18:51:09,750 - INFO - joeynmt.training - Example #2
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:51:09,750 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'ar@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Hypothesis: The artica glacial artica is , in a sense , the heart of global climate system .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - Example #3
2024-05-27 18:51:09,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:51:09,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:51:09,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', 'have', 'a', 't@@', 'esting', '.', '</s>']
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and you have a testing .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - Example #4
2024-05-27 18:51:09,751 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:51:09,751 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:51:09,751 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'few', 'weeks', 'will', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', ',', 'the', 'next', '25', 'years', '.', '</s>']
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:51:09,751 - INFO - joeynmt.training - 	Hypothesis: The next few weeks will be a remarkable remarkable , the next 25 years .
2024-05-27 18:51:32,885 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.641047, Batch Acc: 0.560541, Tokens per Sec:     3060, Lr: 0.000300
2024-05-27 18:51:56,699 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.797413, Batch Acc: 0.559588, Tokens per Sec:     3011, Lr: 0.000300
2024-05-27 18:52:19,372 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.552413, Batch Acc: 0.560676, Tokens per Sec:     3046, Lr: 0.000300
2024-05-27 18:52:42,894 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.613812, Batch Acc: 0.565874, Tokens per Sec:     3101, Lr: 0.000300
2024-05-27 18:53:06,007 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.559931, Batch Acc: 0.564520, Tokens per Sec:     3115, Lr: 0.000300
2024-05-27 18:53:06,008 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:53:06,008 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:54:02,219 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.79, acc:   0.53, generation: 56.2041[sec], evaluation: 0.0000[sec]
2024-05-27 18:54:02,220 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:54:02,333 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/11500.ckpt
2024-05-27 18:54:02,338 - INFO - joeynmt.training - Example #0
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'last', 'year', ',', 'I', 'showed', 'these', 'slide', 'to', 'show', 'that', 'the', 'gl@@', 'al', 'aci@@', 'al', 'gl@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', 'contin@@', 'ents', ',', 'the', 'size', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:54:02,338 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:54:02,338 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:54:02,338 - INFO - joeynmt.training - 	Hypothesis: So last year , I showed these slide to show that the glal acial glal calculus , which for almost three million years had the size of 48 , the United States of 48 continents , the size of 40 percent .
2024-05-27 18:54:02,338 - INFO - joeynmt.training - Example #1
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'ice', '.', '</s>']
2024-05-27 18:54:02,338 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:54:02,338 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:54:02,338 - INFO - joeynmt.training - 	Hypothesis: But that &apos;s the gravity of the problem because it doesn &apos;t show the spessor of ice .
2024-05-27 18:54:02,338 - INFO - joeynmt.training - Example #2
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:54:02,338 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial calculus is , in a sense , the heart of global climate system .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - Example #3
2024-05-27 18:54:02,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:54:02,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:54:02,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'and', 'you', 'get', 'in@@', 'ver@@', 'se', '.', '</s>']
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded and you get inverse .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - Example #4
2024-05-27 18:54:02,339 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:54:02,339 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:54:02,339 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 're@@', 'f@@', 'li@@', 'ghts', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:54:02,339 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable reflights on the last 25 years .
2024-05-27 18:54:25,540 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.662937, Batch Acc: 0.567220, Tokens per Sec:     3082, Lr: 0.000300
2024-05-27 18:54:49,484 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.540142, Batch Acc: 0.563937, Tokens per Sec:     2901, Lr: 0.000300
2024-05-27 18:55:15,242 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.534063, Batch Acc: 0.562665, Tokens per Sec:     2751, Lr: 0.000300
2024-05-27 18:55:39,943 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.723871, Batch Acc: 0.561764, Tokens per Sec:     2786, Lr: 0.000300
2024-05-27 18:56:02,447 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.826710, Batch Acc: 0.556270, Tokens per Sec:     3082, Lr: 0.000300
2024-05-27 18:56:02,447 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:56:02,447 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:56:59,844 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.53, generation: 57.3899[sec], evaluation: 0.0000[sec]
2024-05-27 18:56:59,972 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/12000.ckpt
2024-05-27 18:56:59,978 - INFO - joeynmt.training - Example #0
2024-05-27 18:56:59,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:56:59,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:56:59,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', 'that', 'for', 'almost', 'three', 'million', 'years', 'of', 'the', 'United', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', '.', '</s>']
2024-05-27 18:56:59,978 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:56:59,978 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:56:59,978 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial calculus that for almost three million years of the United 48 , the United States of 48 , the United States of 48 , the United States of 48 .
2024-05-27 18:56:59,978 - INFO - joeynmt.training - Example #1
2024-05-27 18:56:59,978 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:56:59,978 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:56:59,978 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'p', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 18:56:59,978 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:56:59,978 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:56:59,978 - INFO - joeynmt.training - 	Hypothesis: But it &apos;s the gravity of the problem because it &apos;s not exhip the problem because it doesn &apos;t show the ice ice of ice .
2024-05-27 18:56:59,978 - INFO - joeynmt.training - Example #2
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'h@@', 'ot', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Hypothesis: The artica glacial hot is , in a sense , the clean of global climate system .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - Example #3
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'win@@', 'ter', 'and', 're@@', 'ver@@', 'se', 'of', 'sum@@', 'm@@', 'it', '.', '</s>']
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a winter and reverse of summit .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - Example #4
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:56:59,979 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'will', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'ach', ',', 'the', 'next', 'few', 'years', 'old', '.', '</s>']
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:56:59,979 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a carrying reach , the next few years old .
2024-05-27 18:57:23,285 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.325839, Batch Acc: 0.568271, Tokens per Sec:     3022, Lr: 0.000300
2024-05-27 18:57:46,574 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.512627, Batch Acc: 0.565349, Tokens per Sec:     2933, Lr: 0.000300
2024-05-27 18:58:10,331 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.523464, Batch Acc: 0.567652, Tokens per Sec:     2914, Lr: 0.000300
2024-05-27 18:58:34,015 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.651857, Batch Acc: 0.562861, Tokens per Sec:     2947, Lr: 0.000300
2024-05-27 18:58:57,378 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.602299, Batch Acc: 0.563510, Tokens per Sec:     3022, Lr: 0.000300
2024-05-27 18:58:57,379 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 18:58:57,379 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 18:59:52,957 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.72, acc:   0.53, generation: 55.5721[sec], evaluation: 0.0000[sec]
2024-05-27 18:59:52,960 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 18:59:53,080 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/12500.ckpt
2024-05-27 18:59:53,084 - INFO - joeynmt.training - Example #0
2024-05-27 18:59:53,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'hy@@', 'th@@', 'ic', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', 'the', 'contin@@', 'ent', ',', 'the', 'United', 'States', 'of', '40', 'percent', '.', '</s>']
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial hythic calculus , which for almost three million years had the size of 48 , the United States of the continent , the United States of 40 percent .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - Example #1
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'ath', 'this', 'under@@', 'ne@@', 'ath', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'p', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'p', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Hypothesis: But this underneath this underneath the problem because it doesn &apos;t exhip the problem because it doesn &apos;t exhip the ice of the ice .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - Example #2
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial calculus is , in a sense , the clean of global climate system .
2024-05-27 18:59:53,085 - INFO - joeynmt.training - Example #3
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 18:59:53,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'in', 'the', 'sum@@', 'mer', 'and', 'the', 'sum@@', 'mer', 'of', 'sum@@', 'mer', '.', '</s>']
2024-05-27 18:59:53,086 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 18:59:53,086 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 18:59:53,086 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up in the summer and the summer of summer .
2024-05-27 18:59:53,086 - INFO - joeynmt.training - Example #4
2024-05-27 18:59:53,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 18:59:53,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 18:59:53,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 18:59:53,086 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 18:59:53,086 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 18:59:53,086 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelated carrelated to the last 25 years .
2024-05-27 19:00:16,898 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.631771, Batch Acc: 0.568179, Tokens per Sec:     3043, Lr: 0.000300
2024-05-27 19:00:40,807 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.657122, Batch Acc: 0.565751, Tokens per Sec:     3068, Lr: 0.000300
2024-05-27 19:01:04,361 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.657758, Batch Acc: 0.568360, Tokens per Sec:     2913, Lr: 0.000300
2024-05-27 19:01:31,357 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.650405, Batch Acc: 0.563454, Tokens per Sec:     2575, Lr: 0.000300
2024-05-27 19:01:53,485 - INFO - joeynmt.training - Epoch   4: total training loss 6180.99
2024-05-27 19:01:53,486 - INFO - joeynmt.training - EPOCH 5
2024-05-27 19:01:55,482 - INFO - joeynmt.training - Epoch   5, Step:    15500, Batch Loss:     1.452077, Batch Acc: 0.588799, Tokens per Sec:     3087, Lr: 0.000300
2024-05-27 19:01:55,482 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:01:55,482 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:02:55,327 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.66, acc:   0.53, generation: 59.8367[sec], evaluation: 0.0000[sec]
2024-05-27 19:02:55,330 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:02:55,471 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/13000.ckpt
2024-05-27 19:02:55,476 - INFO - joeynmt.training - Example #0
2024-05-27 19:02:55,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:02:55,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:02:55,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'al', 'calc@@', 'ul@@', 'us', 'that', '&apos;s', 'gl@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'of', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ents', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', 'of', '40', 'percent', '.', '</s>']
2024-05-27 19:02:55,477 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:02:55,477 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:02:55,477 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glal calculus that &apos;s glal calculus , which for almost three million years of years had the size of 48 United States continents , it &apos;s restrip of 40 percent .
2024-05-27 19:02:55,477 - INFO - joeynmt.training - Example #1
2024-05-27 19:02:55,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:02:55,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:02:55,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'b@@', 'ition', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 19:02:55,477 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:02:55,477 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:02:55,477 - INFO - joeynmt.training - 	Hypothesis: But this underneath the gravity of the problem because it &apos;s not exhibition the ice of ice .
2024-05-27 19:02:55,477 - INFO - joeynmt.training - Example #2
2024-05-27 19:02:55,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:02:55,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:02:55,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'global', 'system', '.', '</s>']
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Hypothesis: The artica calculus is , in a sense , the heart of the global global global global global global global global global global system .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - Example #3
2024-05-27 19:02:55,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:02:55,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:02:55,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'the', 'sum@@', 'mer', 're@@', 'tre@@', 'ating', '.', '</s>']
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and the summer retreating .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - Example #4
2024-05-27 19:02:55,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:02:55,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:02:55,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:02:55,478 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelated carrelated to the last 25 years .
2024-05-27 19:03:20,173 - INFO - joeynmt.training - Epoch   5, Step:    15600, Batch Loss:     1.469421, Batch Acc: 0.589926, Tokens per Sec:     2806, Lr: 0.000300
2024-05-27 19:03:45,792 - INFO - joeynmt.training - Epoch   5, Step:    15700, Batch Loss:     1.339900, Batch Acc: 0.590168, Tokens per Sec:     2814, Lr: 0.000300
2024-05-27 19:04:09,577 - INFO - joeynmt.training - Epoch   5, Step:    15800, Batch Loss:     1.458207, Batch Acc: 0.586906, Tokens per Sec:     2884, Lr: 0.000300
2024-05-27 19:04:40,314 - INFO - joeynmt.training - Epoch   5, Step:    15900, Batch Loss:     1.538842, Batch Acc: 0.592745, Tokens per Sec:     2364, Lr: 0.000300
2024-05-27 19:05:05,593 - INFO - joeynmt.training - Epoch   5, Step:    16000, Batch Loss:     1.417204, Batch Acc: 0.590581, Tokens per Sec:     2790, Lr: 0.000300
2024-05-27 19:05:05,594 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:05:05,594 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:06:00,015 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.65, acc:   0.54, generation: 54.4124[sec], evaluation: 0.0000[sec]
2024-05-27 19:06:00,018 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:06:00,159 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/13500.ckpt
2024-05-27 19:06:00,164 - INFO - joeynmt.training - Example #0
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', 'contin@@', 'ent@@', 'al', '4@@', '8', 'of', 'the', 'contin@@', 'ent@@', 'al', '4@@', '8', 'of', 'the', 'contin@@', 'ent', ',', 'it', 'has', 'been', 're@@', 'str@@', 'et@@', 'ch', 'of', '40', 'percent', '.', '</s>']
2024-05-27 19:06:00,165 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:06:00,165 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:06:00,165 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the glacial calculus , which for almost three million years had the size of the 48 of the continental 48 of the continental 48 of the continent , it has been restretch of 40 percent .
2024-05-27 19:06:00,165 - INFO - joeynmt.training - Example #1
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', '&apos;s', 'going', 'to', 'under@@', 'ne@@', 'ath', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'the', 'sp@@', 'ess@@', 'or', 'of', 'ice', '.', '</s>']
2024-05-27 19:06:00,165 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:06:00,165 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:06:00,165 - INFO - joeynmt.training - 	Hypothesis: But it &apos;s going to underneath this underneath the gravity of the problem because it doesn &apos;t show it the spessor of ice .
2024-05-27 19:06:00,165 - INFO - joeynmt.training - Example #2
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:06:00,165 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Hypothesis: The artica glacial calculus is , in a sense , the clean of global climate system .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - Example #3
2024-05-27 19:06:00,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:06:00,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:06:00,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'in', 'the', 'world', 'and', 'sum@@', 'mer', 'r@@', 'iti@@', 'er', '.', '</s>']
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up in the world and summer ritier .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - Example #4
2024-05-27 19:06:00,166 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:06:00,166 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:06:00,166 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'i@@', 'ed', 'car@@', 'r@@', 'ying', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:06:00,166 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelied carrying the last 25 years .
2024-05-27 19:06:26,024 - INFO - joeynmt.training - Epoch   5, Step:    16100, Batch Loss:     1.504367, Batch Acc: 0.584694, Tokens per Sec:     2691, Lr: 0.000300
2024-05-27 19:06:48,272 - INFO - joeynmt.training - Epoch   5, Step:    16200, Batch Loss:     1.382325, Batch Acc: 0.590436, Tokens per Sec:     3205, Lr: 0.000300
2024-05-27 19:07:10,551 - INFO - joeynmt.training - Epoch   5, Step:    16300, Batch Loss:     1.550825, Batch Acc: 0.585134, Tokens per Sec:     3103, Lr: 0.000300
2024-05-27 19:07:35,220 - INFO - joeynmt.training - Epoch   5, Step:    16400, Batch Loss:     1.523723, Batch Acc: 0.579626, Tokens per Sec:     2798, Lr: 0.000300
2024-05-27 19:07:56,737 - INFO - joeynmt.training - Epoch   5, Step:    16500, Batch Loss:     1.515927, Batch Acc: 0.583641, Tokens per Sec:     3311, Lr: 0.000300
2024-05-27 19:07:56,737 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:07:56,737 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:08:42,756 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.73, ppl:   5.63, acc:   0.54, generation: 46.0123[sec], evaluation: 0.0000[sec]
2024-05-27 19:08:42,757 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:08:42,877 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/14500.ckpt
2024-05-27 19:08:42,887 - INFO - joeynmt.training - Example #0
2024-05-27 19:08:42,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:08:42,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:08:42,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'ass@@', 'es', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'contin@@', 'ent@@', 'al', 'ex@@', 'pen@@', 'sive', ',', 'it', '&apos;s', 're@@', 'str@@', 'et@@', 'ch', 'of', '40', 'percent', '.', '</s>']
2024-05-27 19:08:42,887 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:08:42,887 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:08:42,887 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glasses to demonstrate that glacial calculus , which is almost three million years had the size of 48 , the continental expensive , it &apos;s restretch of 40 percent .
2024-05-27 19:08:42,887 - INFO - joeynmt.training - Example #1
2024-05-27 19:08:42,887 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:08:42,887 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:08:42,887 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'going', 'to', 'be', 'sp@@', 'ex@@', 't', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:08:42,887 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:08:42,887 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:08:42,887 - INFO - joeynmt.training - 	Hypothesis: But it &apos;s the gravity of the problem because it &apos;s not going to be spext of the ice .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - Example #2
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'al', 'gl@@', 'aci@@', 'al', 'hy@@', 'th@@', 'ic', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Hypothesis: The artal glacial hythic is , in a sense , the heart of the global climate system .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - Example #3
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'sion', 'of', 'in@@', 'ver@@', 'n', 'and', 're@@', 'tre@@', 'ated', 'of', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Hypothesis: It expansion of invern and retreated of summer .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - Example #4
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:08:42,888 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 're@@', 'ven@@', 'ess', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:08:42,888 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelated reveness of the last 25 years .
2024-05-27 19:09:04,648 - INFO - joeynmt.training - Epoch   5, Step:    16600, Batch Loss:     1.262185, Batch Acc: 0.581167, Tokens per Sec:     3095, Lr: 0.000300
2024-05-27 19:09:27,630 - INFO - joeynmt.training - Epoch   5, Step:    16700, Batch Loss:     1.502400, Batch Acc: 0.582382, Tokens per Sec:     3136, Lr: 0.000300
2024-05-27 19:09:51,199 - INFO - joeynmt.training - Epoch   5, Step:    16800, Batch Loss:     1.516380, Batch Acc: 0.580977, Tokens per Sec:     2961, Lr: 0.000300
2024-05-27 19:10:12,916 - INFO - joeynmt.training - Epoch   5, Step:    16900, Batch Loss:     1.320962, Batch Acc: 0.580179, Tokens per Sec:     3230, Lr: 0.000300
2024-05-27 19:10:35,065 - INFO - joeynmt.training - Epoch   5, Step:    17000, Batch Loss:     1.526603, Batch Acc: 0.583892, Tokens per Sec:     3245, Lr: 0.000300
2024-05-27 19:10:35,066 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:10:35,066 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:11:20,666 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.57, acc:   0.54, generation: 45.5938[sec], evaluation: 0.0000[sec]
2024-05-27 19:11:20,668 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:11:20,794 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/14000.ckpt
2024-05-27 19:11:20,798 - INFO - joeynmt.training - Example #0
2024-05-27 19:11:20,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:11:20,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:11:20,798 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'al', 'aci@@', 'al', 'calc@@', 'ul@@', 'al', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'is', 're@@', 'str@@', 'i@@', 'p', 'of', '40', 'percent', '.', '</s>']
2024-05-27 19:11:20,798 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:11:20,798 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:11:20,798 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the artica glacial calculal acial calculal acial calculus , which is restrip of 40 percent .
2024-05-27 19:11:20,798 - INFO - joeynmt.training - Example #1
2024-05-27 19:11:20,798 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:11:20,798 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'sub@@', '-@@', 'up', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Hypothesis: However this sub-up the gravity of the problem because it doesn &apos;t show the ice of the ice of the ice of the ice .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - Example #2
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'gl@@', 'aci@@', 'al', 'aci@@', 'al', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'system', '.', '</s>']
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Hypothesis: The artica glacial acial ice is , in a sense , the heart of global system .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - Example #3
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'of', 'the', 'sum@@', 'mer', 'and', 'you', 'get', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up of the summer and you get summer .
2024-05-27 19:11:20,799 - INFO - joeynmt.training - Example #4
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:11:20,799 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', ',', 'the', 'next', 'few', '25', 'years', '.', '</s>']
2024-05-27 19:11:20,800 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:11:20,800 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:11:20,800 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelated , the next few 25 years .
2024-05-27 19:11:42,483 - INFO - joeynmt.training - Epoch   5, Step:    17100, Batch Loss:     1.425376, Batch Acc: 0.582204, Tokens per Sec:     3266, Lr: 0.000300
2024-05-27 19:12:04,380 - INFO - joeynmt.training - Epoch   5, Step:    17200, Batch Loss:     1.496565, Batch Acc: 0.586494, Tokens per Sec:     3209, Lr: 0.000300
2024-05-27 19:12:26,141 - INFO - joeynmt.training - Epoch   5, Step:    17300, Batch Loss:     1.476888, Batch Acc: 0.579118, Tokens per Sec:     3215, Lr: 0.000300
2024-05-27 19:12:48,533 - INFO - joeynmt.training - Epoch   5, Step:    17400, Batch Loss:     1.390572, Batch Acc: 0.585723, Tokens per Sec:     3236, Lr: 0.000300
2024-05-27 19:13:10,446 - INFO - joeynmt.training - Epoch   5, Step:    17500, Batch Loss:     1.397732, Batch Acc: 0.577979, Tokens per Sec:     3216, Lr: 0.000300
2024-05-27 19:13:10,447 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:13:10,447 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:14:01,058 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.60, acc:   0.54, generation: 50.6055[sec], evaluation: 0.0000[sec]
2024-05-27 19:14:01,180 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/15000.ckpt
2024-05-27 19:14:01,184 - INFO - joeynmt.training - Example #0
2024-05-27 19:14:01,184 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:14:01,184 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:14:01,184 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'of', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'the', 'size', 'of', 'the', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', 'of', '40', 'percent', '.', '</s>']
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the artica of the artica , which is almost three million years had the size of the 48 continental , the size of the United States continental , it &apos;s restrip of 40 percent .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - Example #1
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Hypothesis: However this underlying gravity of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - Example #2
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'cal@@', 'ght', 'gl@@', 'aci@@', 'al', 'cal@@', 'm', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'an', 'of', 'global', 'system', '.', '</s>']
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Hypothesis: The artica calght glacial calm is , in a way , the clean of global system .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - Example #3
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:14:01,185 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'pan@@', 'ded', 'up', 'of', 'in@@', 'ver@@', 'se', 'and', 're@@', 'ver@@', 'se', 'of', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:14:01,185 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:14:01,186 - INFO - joeynmt.training - 	Hypothesis: You expanded up of inverse and reverse of summer .
2024-05-27 19:14:01,186 - INFO - joeynmt.training - Example #4
2024-05-27 19:14:01,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:14:01,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:14:01,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'car@@', 'r@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:14:01,186 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:14:01,186 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:14:01,186 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable carrying on the last 25 years .
2024-05-27 19:14:24,366 - INFO - joeynmt.training - Epoch   5, Step:    17600, Batch Loss:     1.633565, Batch Acc: 0.579316, Tokens per Sec:     2955, Lr: 0.000300
2024-05-27 19:14:47,629 - INFO - joeynmt.training - Epoch   5, Step:    17700, Batch Loss:     1.219641, Batch Acc: 0.583421, Tokens per Sec:     3075, Lr: 0.000300
2024-05-27 19:15:09,569 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.297703, Batch Acc: 0.583931, Tokens per Sec:     3166, Lr: 0.000300
2024-05-27 19:15:31,395 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.505720, Batch Acc: 0.582946, Tokens per Sec:     3260, Lr: 0.000300
2024-05-27 19:15:53,141 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.694737, Batch Acc: 0.581411, Tokens per Sec:     3228, Lr: 0.000300
2024-05-27 19:15:53,141 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:15:53,141 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:16:42,298 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.56, acc:   0.54, generation: 49.1500[sec], evaluation: 0.0000[sec]
2024-05-27 19:16:42,300 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:16:42,421 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/15500.ckpt
2024-05-27 19:16:42,425 - INFO - joeynmt.training - Example #0
2024-05-27 19:16:42,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:16:42,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:16:42,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'slide', 'slide', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ents', ',', 'the', 'size', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 19:16:42,425 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:16:42,425 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:16:42,425 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide slide to demonstrate that the arglacial calculus , which is about three million years has had the size of 48 United States continents , the size of 48 percent .
2024-05-27 19:16:42,425 - INFO - joeynmt.training - Example #1
2024-05-27 19:16:42,425 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:16:42,425 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:16:42,425 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ground', 'under@@', 'ground', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'in', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Hypothesis: But this underground underground gravity of the problem because it doesn &apos;t show it in the ice of the ice of ice .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - Example #2
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Hypothesis: The artica is , in a sense , the heart of global climate system .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - Example #3
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'in@@', 'ver@@', 'se', 'and', 're@@', 'tre@@', 'at', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Hypothesis: It &apos;s inverse and retreat the summer .
2024-05-27 19:16:42,426 - INFO - joeynmt.training - Example #4
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:16:42,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'rel@@', 'ated', 'car@@', 'r@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:16:42,426 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:16:42,427 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:16:42,427 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a related carrying on the last 25 years .
2024-05-27 19:17:03,424 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.443918, Batch Acc: 0.572458, Tokens per Sec:     3264, Lr: 0.000300
2024-05-27 19:17:25,282 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.556622, Batch Acc: 0.575654, Tokens per Sec:     3207, Lr: 0.000300
2024-05-27 19:17:47,266 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.695184, Batch Acc: 0.577316, Tokens per Sec:     3222, Lr: 0.000300
2024-05-27 19:18:11,232 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.395737, Batch Acc: 0.578490, Tokens per Sec:     2972, Lr: 0.000300
2024-05-27 19:18:32,660 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.575702, Batch Acc: 0.578998, Tokens per Sec:     3258, Lr: 0.000300
2024-05-27 19:18:32,661 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:18:32,661 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:19:19,760 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.51, acc:   0.54, generation: 47.0929[sec], evaluation: 0.0000[sec]
2024-05-27 19:19:19,761 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:19:19,884 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/16000.ckpt
2024-05-27 19:19:19,889 - INFO - joeynmt.training - Example #0
2024-05-27 19:19:19,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:19:19,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:19:19,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'ate', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'U.S.', 'U.S.', 'U.S.', 'contin@@', 'ents', ',', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2024-05-27 19:19:19,889 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:19:19,889 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:19:19,889 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the glacial calculate , which is about three million years had the size of 48 , the U.S. U.S. U.S. continents , the size of 48 .
2024-05-27 19:19:19,889 - INFO - joeynmt.training - Example #1
2024-05-27 19:19:19,889 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:19:19,889 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:19:19,889 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', '&apos;s', 'going', 'to', 'put', 'this', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'p', 'of', 'ice', '.', '</s>']
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Hypothesis: But it &apos;s going to put this underlying the gravity of the problem because it &apos;s not exhip of ice .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - Example #2
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ving', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'climate', 'system', '.', '</s>']
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Hypothesis: The glacial calving is , in a sense , the heart of climate system .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - Example #3
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'been', 'ex@@', 'pan@@', 'ded', 'and', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Hypothesis: It &apos;s been expanded and retreat .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - Example #4
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:19:19,890 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'few', 'sli@@', 'des', 'will', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'ven@@', 'ue', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:19:19,890 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:19:19,891 - INFO - joeynmt.training - 	Hypothesis: The next few slides will be a remarkable revenue to the last 25 years .
2024-05-27 19:19:42,011 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.582486, Batch Acc: 0.579117, Tokens per Sec:     3105, Lr: 0.000300
2024-05-27 19:20:03,157 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.557174, Batch Acc: 0.578755, Tokens per Sec:     3330, Lr: 0.000300
2024-05-27 19:20:26,466 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.548507, Batch Acc: 0.580711, Tokens per Sec:     3093, Lr: 0.000300
2024-05-27 19:20:49,997 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.633464, Batch Acc: 0.581961, Tokens per Sec:     2961, Lr: 0.000300
2024-05-27 19:21:13,580 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.660336, Batch Acc: 0.576700, Tokens per Sec:     2949, Lr: 0.000300
2024-05-27 19:21:13,581 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:21:13,581 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:22:04,912 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.49, acc:   0.54, generation: 51.3248[sec], evaluation: 0.0000[sec]
2024-05-27 19:22:04,914 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:22:05,034 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/16500.ckpt
2024-05-27 19:22:05,039 - INFO - joeynmt.training - Example #0
2024-05-27 19:22:05,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:22:05,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:22:05,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'last', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'ated', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', '.', '</s>']
2024-05-27 19:22:05,039 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:22:05,039 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:22:05,039 - INFO - joeynmt.training - 	Hypothesis: So last year I showed these slides to show that the glacial calculated , which for almost three million years has had the size of 48 million years had the size of the 48 continent , it &apos;s restrip .
2024-05-27 19:22:05,039 - INFO - joeynmt.training - Example #1
2024-05-27 19:22:05,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:22:05,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:22:05,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ground', ',', 'this', 'under@@', 'ground', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Hypothesis: But this underground , this underground gravity of the problem because it doesn &apos;t show the ice ice of ice .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - Example #2
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'calc@@', 'ul@@', 'ated', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'climate', 'system', '.', '</s>']
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Hypothesis: The artica calculated is , in a certain sense , the heart of climate system .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - Example #3
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'about', 'in@@', 'ver@@', 'n', 'and', 'sum@@', 'mer', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - 	Hypothesis: It &apos;s about invern and summer the summer .
2024-05-27 19:22:05,040 - INFO - joeynmt.training - Example #4
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:22:05,040 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', '25', 'years', ',', 'it', '&apos;s', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ated', 'car@@', 'l@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:22:05,041 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:22:05,041 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:22:05,041 - INFO - joeynmt.training - 	Hypothesis: The next next 25 years , it &apos;s going to be a carlated carlying on the last 25 years .
2024-05-27 19:22:27,040 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.375635, Batch Acc: 0.577939, Tokens per Sec:     3267, Lr: 0.000300
2024-05-27 19:22:49,937 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.678335, Batch Acc: 0.582357, Tokens per Sec:     3113, Lr: 0.000300
2024-05-27 19:23:14,354 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.556416, Batch Acc: 0.578501, Tokens per Sec:     2882, Lr: 0.000300
2024-05-27 19:23:29,240 - INFO - joeynmt.training - Epoch   5: total training loss 5890.91
2024-05-27 19:23:29,241 - INFO - joeynmt.training - EPOCH 6
2024-05-27 19:23:36,107 - INFO - joeynmt.training - Epoch   6, Step:    19400, Batch Loss:     1.471948, Batch Acc: 0.601448, Tokens per Sec:     3178, Lr: 0.000300
2024-05-27 19:23:59,383 - INFO - joeynmt.training - Epoch   6, Step:    19500, Batch Loss:     1.662382, Batch Acc: 0.605435, Tokens per Sec:     3056, Lr: 0.000300
2024-05-27 19:23:59,384 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:23:59,384 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:24:48,881 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.49, acc:   0.54, generation: 49.4904[sec], evaluation: 0.0000[sec]
2024-05-27 19:24:49,007 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/17500.ckpt
2024-05-27 19:24:49,013 - INFO - joeynmt.training - Example #0
2024-05-27 19:24:49,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:24:49,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:24:49,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'showed', 'these', 'slide', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'gl@@', 'al', 'calc@@', 'ul@@', 'ate', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'has', 'been', 'the', 'size', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', '.', '</s>']
2024-05-27 19:24:49,013 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:24:49,013 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:24:49,013 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slide to demonstrate that the arglal calculate ice , which for almost three million years had the size of 48 , the United States has been the size of 48 continental , it &apos;s restrip .
2024-05-27 19:24:49,013 - INFO - joeynmt.training - Example #1
2024-05-27 19:24:49,013 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:24:49,013 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:24:49,013 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', '&apos;s', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'p', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Hypothesis: But it &apos;s the gravity of the problem because it doesn &apos;t exhip the ice of the ice .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - Example #2
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'calc@@', 'ul@@', 'ate', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'cle@@', 'an', 'of', 'global', 'global', 'global', 'system', '.', '</s>']
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Hypothesis: The artica calculate is , in a sense , the heart clean of global global global system .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - Example #3
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'in', 'the', 'win@@', 'ter', 'and', 'you', 're@@', 'ver@@', 'n', '.', '</s>']
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Hypothesis: It expands in the winter and you revern .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - Example #4
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:24:49,014 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ed', 'car@@', 'l@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:24:49,014 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:24:49,015 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carled carled on the last 25 years .
2024-05-27 19:25:13,086 - INFO - joeynmt.training - Epoch   6, Step:    19600, Batch Loss:     1.530073, Batch Acc: 0.610631, Tokens per Sec:     3045, Lr: 0.000300
2024-05-27 19:25:39,165 - INFO - joeynmt.training - Epoch   6, Step:    19700, Batch Loss:     1.585162, Batch Acc: 0.606245, Tokens per Sec:     2729, Lr: 0.000300
2024-05-27 19:26:02,691 - INFO - joeynmt.training - Epoch   6, Step:    19800, Batch Loss:     1.172162, Batch Acc: 0.601497, Tokens per Sec:     3033, Lr: 0.000300
2024-05-27 19:26:25,407 - INFO - joeynmt.training - Epoch   6, Step:    19900, Batch Loss:     1.257636, Batch Acc: 0.607926, Tokens per Sec:     3074, Lr: 0.000300
2024-05-27 19:26:54,771 - INFO - joeynmt.training - Epoch   6, Step:    20000, Batch Loss:     1.392706, Batch Acc: 0.596105, Tokens per Sec:     2368, Lr: 0.000300
2024-05-27 19:26:54,772 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:26:54,772 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:27:48,514 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.46, acc:   0.54, generation: 53.7348[sec], evaluation: 0.0000[sec]
2024-05-27 19:27:48,517 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:27:48,642 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/17000.ckpt
2024-05-27 19:27:48,647 - INFO - joeynmt.training - Example #0
2024-05-27 19:27:48,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:27:48,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:27:48,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'last', 'year', 'I', 'showed', 'these', 'slide', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'he@@', 'at', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'of', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', 'United', 'States', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'United', 'States', '.', '</s>']
2024-05-27 19:27:48,647 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:27:48,647 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:27:48,647 - INFO - joeynmt.training - 	Hypothesis: So last year I showed these slide to show that the artica heat , which for almost three million years of the size of the 48 of the United States of the 48 continental United States .
2024-05-27 19:27:48,647 - INFO - joeynmt.training - Example #1
2024-05-27 19:27:48,647 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:27:48,647 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:27:48,647 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'p', 'of', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 19:27:48,647 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:27:48,647 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:27:48,647 - INFO - joeynmt.training - 	Hypothesis: However this underneath the gravity of the problem because it &apos;s not exhip of the ice of ice .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - Example #2
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'climate', 'climate', 'climate', 'climate', 'system', '.', '</s>']
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Hypothesis: The artica ice ice is , in a sense , the heart of the global climate climate climate climate climate system .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - Example #3
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 's@@', 'at', 'the', 'win@@', 'ter', 'and', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Hypothesis: It &apos;s sat the winter and retreat .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - Example #4
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:27:48,648 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 're@@', 'turn', 'for', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:27:48,648 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable return for the last 25 years .
2024-05-27 19:28:10,908 - INFO - joeynmt.training - Epoch   6, Step:    20100, Batch Loss:     1.410982, Batch Acc: 0.600708, Tokens per Sec:     3141, Lr: 0.000300
2024-05-27 19:28:35,369 - INFO - joeynmt.training - Epoch   6, Step:    20200, Batch Loss:     1.475017, Batch Acc: 0.594275, Tokens per Sec:     2916, Lr: 0.000300
2024-05-27 19:29:00,802 - INFO - joeynmt.training - Epoch   6, Step:    20300, Batch Loss:     1.397514, Batch Acc: 0.592711, Tokens per Sec:     2756, Lr: 0.000300
2024-05-27 19:29:27,803 - INFO - joeynmt.training - Epoch   6, Step:    20400, Batch Loss:     1.425523, Batch Acc: 0.598124, Tokens per Sec:     2653, Lr: 0.000300
2024-05-27 19:29:53,860 - INFO - joeynmt.training - Epoch   6, Step:    20500, Batch Loss:     1.438146, Batch Acc: 0.599158, Tokens per Sec:     2708, Lr: 0.000300
2024-05-27 19:29:53,860 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:29:53,860 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:30:48,630 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.70, ppl:   5.45, acc:   0.55, generation: 54.7623[sec], evaluation: 0.0000[sec]
2024-05-27 19:30:48,633 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:30:48,760 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/18000.ckpt
2024-05-27 19:30:48,764 - INFO - joeynmt.training - Example #0
2024-05-27 19:30:48,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:30:48,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:30:48,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'last', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'row', 'gl@@', 'al', 'aci@@', 'al', 'ice', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'U.S.', 'U.S.', 'contin@@', 'ent@@', 'al', '4@@', '8', 'United', 'States', ',', 'the', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 19:30:48,764 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:30:48,764 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:30:48,764 - INFO - joeynmt.training - 	Hypothesis: So last year I showed these slides to show that the arrow glal acial ice , which is almost three million years had the size of the 48 U.S. U.S. continental 48 United States , the 48 percent .
2024-05-27 19:30:48,764 - INFO - joeynmt.training - Example #1
2024-05-27 19:30:48,764 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:30:48,764 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:30:48,764 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'sub@@', '-@@', 'up', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Hypothesis: However this sub-up the gravity of the problem because it doesn &apos;t show the ice of the ice of ice .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - Example #2
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'same', 'gl@@', 'ori@@', 'ous', 'ice', 'war@@', 's', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Hypothesis: The same glorious ice wars is , in a sense , the heart of the global climate system .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - Example #3
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'de', 'and', 're@@', 'tre@@', 'at', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expande and retreat the summer .
2024-05-27 19:30:48,765 - INFO - joeynmt.training - Example #4
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:30:48,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:30:48,766 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:30:48,766 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:30:48,766 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable to the last 25 years .
2024-05-27 19:31:11,938 - INFO - joeynmt.training - Epoch   6, Step:    20600, Batch Loss:     1.440508, Batch Acc: 0.599961, Tokens per Sec:     3055, Lr: 0.000300
2024-05-27 19:31:32,922 - INFO - joeynmt.training - Epoch   6, Step:    20700, Batch Loss:     1.498142, Batch Acc: 0.596355, Tokens per Sec:     3277, Lr: 0.000300
2024-05-27 19:31:54,573 - INFO - joeynmt.training - Epoch   6, Step:    20800, Batch Loss:     1.475968, Batch Acc: 0.592095, Tokens per Sec:     3212, Lr: 0.000300
2024-05-27 19:32:14,925 - INFO - joeynmt.training - Epoch   6, Step:    20900, Batch Loss:     1.569239, Batch Acc: 0.592794, Tokens per Sec:     3442, Lr: 0.000300
2024-05-27 19:32:41,536 - INFO - joeynmt.training - Epoch   6, Step:    21000, Batch Loss:     1.642634, Batch Acc: 0.591662, Tokens per Sec:     2708, Lr: 0.000300
2024-05-27 19:32:41,538 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:32:41,538 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:33:33,056 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.41, acc:   0.55, generation: 51.5118[sec], evaluation: 0.0000[sec]
2024-05-27 19:33:33,060 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:33:33,188 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/18500.ckpt
2024-05-27 19:33:33,192 - INFO - joeynmt.training - Example #0
2024-05-27 19:33:33,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:33:33,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:33:33,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', '40', 'percent', '.', '</s>']
2024-05-27 19:33:33,192 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:33:33,192 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:33:33,192 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides slides to show that the glacial calculus , which is almost three million years had the size of 48 million years had the size of 48 , the United States continental , it &apos;s restrip 40 percent .
2024-05-27 19:33:33,192 - INFO - joeynmt.training - Example #1
2024-05-27 19:33:33,192 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:33:33,192 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:33:33,192 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'ground', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:33:33,192 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Hypothesis: However this underground the gravity of the problem because it doesn &apos;t show the ice of the ice of the ice of the ice of the ice .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - Example #2
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'ving', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Hypothesis: The glacial calving is , in a sense , the sense , the clean of global climate system .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - Example #3
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'w@@', 'oo@@', 'ds', 'and', 'you', '&apos;re', 'w@@', 'oo@@', 'den', ',', 'and', 'it', '&apos;s', 'w@@', 'oo@@', 'ds', '.', '</s>']
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - 	Hypothesis: It &apos;s woods and you &apos;re wooden , and it &apos;s woods .
2024-05-27 19:33:33,193 - INFO - joeynmt.training - Example #4
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:33:33,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'relationship', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:33:33,194 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:33:33,194 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:33:33,194 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable relationship to the last 25 years .
2024-05-27 19:33:55,086 - INFO - joeynmt.training - Epoch   6, Step:    21100, Batch Loss:     1.359016, Batch Acc: 0.599161, Tokens per Sec:     3183, Lr: 0.000300
2024-05-27 19:34:20,126 - INFO - joeynmt.training - Epoch   6, Step:    21200, Batch Loss:     1.490447, Batch Acc: 0.594025, Tokens per Sec:     2793, Lr: 0.000300
2024-05-27 19:34:43,402 - INFO - joeynmt.training - Epoch   6, Step:    21300, Batch Loss:     1.412226, Batch Acc: 0.593787, Tokens per Sec:     2989, Lr: 0.000300
2024-05-27 19:35:06,726 - INFO - joeynmt.training - Epoch   6, Step:    21400, Batch Loss:     1.468637, Batch Acc: 0.592409, Tokens per Sec:     2944, Lr: 0.000300
2024-05-27 19:35:31,942 - INFO - joeynmt.training - Epoch   6, Step:    21500, Batch Loss:     1.570323, Batch Acc: 0.596860, Tokens per Sec:     2898, Lr: 0.000300
2024-05-27 19:35:31,943 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:35:31,943 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:36:22,301 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.41, acc:   0.55, generation: 50.3510[sec], evaluation: 0.0000[sec]
2024-05-27 19:36:22,434 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/19500.ckpt
2024-05-27 19:36:22,439 - INFO - joeynmt.training - Example #0
2024-05-27 19:36:22,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:36:22,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:36:22,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'calc@@', 'ul@@', 'us', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'contin@@', 'ent@@', 'al', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'tro@@', 'ying', '40', 'percent', '.', '</s>']
2024-05-27 19:36:22,439 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:36:22,439 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:36:22,439 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the artica calculus , which is almost three million years had the size of 48 , the United States continental 48 United States continental , it &apos;s retroying 40 percent .
2024-05-27 19:36:22,439 - INFO - joeynmt.training - Example #1
2024-05-27 19:36:22,439 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:36:22,439 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:36:22,439 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ground', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'ex@@', 'ten@@', 'sion', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Hypothesis: But this underground the gravity of the problem because it &apos;s not exextension of the ice .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - Example #2
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'way', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Hypothesis: The artica ice ice ice is , in a way , the heart of global climate system .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - Example #3
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'and', 're@@', 'tre@@', 'at', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded and retreat the summer .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - Example #4
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:36:22,440 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'rap@@', 'id', 're@@', 'ven@@', 'ess', 'about', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:36:22,440 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable rapid reveness about the last 25 years .
2024-05-27 19:36:48,143 - INFO - joeynmt.training - Epoch   6, Step:    21600, Batch Loss:     1.623007, Batch Acc: 0.589432, Tokens per Sec:     2732, Lr: 0.000300
2024-05-27 19:37:11,007 - INFO - joeynmt.training - Epoch   6, Step:    21700, Batch Loss:     1.416472, Batch Acc: 0.587539, Tokens per Sec:     3090, Lr: 0.000300
2024-05-27 19:37:36,397 - INFO - joeynmt.training - Epoch   6, Step:    21800, Batch Loss:     1.458016, Batch Acc: 0.595096, Tokens per Sec:     2808, Lr: 0.000300
2024-05-27 19:37:59,034 - INFO - joeynmt.training - Epoch   6, Step:    21900, Batch Loss:     1.463210, Batch Acc: 0.597381, Tokens per Sec:     3067, Lr: 0.000300
2024-05-27 19:38:21,206 - INFO - joeynmt.training - Epoch   6, Step:    22000, Batch Loss:     1.602202, Batch Acc: 0.590350, Tokens per Sec:     3175, Lr: 0.000300
2024-05-27 19:38:21,207 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:38:21,207 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:39:16,161 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.36, acc:   0.55, generation: 54.9473[sec], evaluation: 0.0000[sec]
2024-05-27 19:39:16,162 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:39:16,278 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/19000.ckpt
2024-05-27 19:39:16,282 - INFO - joeynmt.training - Example #0
2024-05-27 19:39:16,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:39:16,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:39:16,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'ice', 'ice', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', '40', 'percent', '.', '</s>']
2024-05-27 19:39:16,282 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:39:16,282 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:39:16,282 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial ice ice to show that the artica , which for almost three million years has had the size of 48 , the United States continental , it &apos;s restrip 40 percent .
2024-05-27 19:39:16,282 - INFO - joeynmt.training - Example #1
2024-05-27 19:39:16,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:39:16,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:39:16,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'sub@@', 'j@@', 'ected', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:39:16,282 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:39:16,282 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:39:16,282 - INFO - joeynmt.training - 	Hypothesis: However this subjected gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 19:39:16,282 - INFO - joeynmt.training - Example #2
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'aci@@', 'ous', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Hypothesis: The acious ice ice ice is , in a sense , the clean of global climate system .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - Example #3
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 're@@', 'ver@@', 'se', 'and', 're@@', 'ver@@', 'n', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Hypothesis: It &apos;s reverse and revern expanded .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - Example #4
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:39:16,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ying', 're@@', '-@@', 'rel@@', 'i@@', 'ef', ',', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:39:16,283 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carlying re-relief , the last 25 years .
2024-05-27 19:39:37,858 - INFO - joeynmt.training - Epoch   6, Step:    22100, Batch Loss:     1.325458, Batch Acc: 0.592785, Tokens per Sec:     3242, Lr: 0.000300
2024-05-27 19:40:04,043 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.421446, Batch Acc: 0.593963, Tokens per Sec:     2762, Lr: 0.000300
2024-05-27 19:40:26,370 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.518454, Batch Acc: 0.597855, Tokens per Sec:     3224, Lr: 0.000300
2024-05-27 19:40:48,463 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.510443, Batch Acc: 0.594586, Tokens per Sec:     3212, Lr: 0.000300
2024-05-27 19:41:10,276 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.358670, Batch Acc: 0.594744, Tokens per Sec:     3151, Lr: 0.000300
2024-05-27 19:41:10,277 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:41:10,277 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:42:02,163 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.55, generation: 51.8796[sec], evaluation: 0.0000[sec]
2024-05-27 19:42:02,292 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/20000.ckpt
2024-05-27 19:42:02,298 - INFO - joeynmt.training - Example #0
2024-05-27 19:42:02,298 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:42:02,298 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'U.S.', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', '40', 'percent', '.', '</s>']
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial calculus , which is almost three million years had the size of the 48 U.S. continental dimensions , it &apos;s restrip 40 percent .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - Example #1
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ur@@', 'g@@', 'y', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Hypothesis: But this suburgy of the problem because it &apos;s not showing the ice of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - Example #2
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - 	Hypothesis: The glacial ice ice ice is , in a way , the clean of global climate system .
2024-05-27 19:42:02,299 - INFO - joeynmt.training - Example #3
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:42:02,299 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'in', 'the', 'win@@', 'ter', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'in', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:42:02,300 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:42:02,300 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:42:02,300 - INFO - joeynmt.training - 	Hypothesis: It expanded in the winter and you &apos;re going to be in the summer .
2024-05-27 19:42:02,300 - INFO - joeynmt.training - Example #4
2024-05-27 19:42:02,300 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:42:02,300 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:42:02,300 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 'car@@', 'l@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:42:02,300 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:42:02,300 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:42:02,300 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying carlying on the last 25 years .
2024-05-27 19:42:25,628 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.406691, Batch Acc: 0.600238, Tokens per Sec:     3083, Lr: 0.000300
2024-05-27 19:42:52,984 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.498252, Batch Acc: 0.590697, Tokens per Sec:     2553, Lr: 0.000300
2024-05-27 19:43:15,344 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.455161, Batch Acc: 0.592676, Tokens per Sec:     3216, Lr: 0.000300
2024-05-27 19:43:37,260 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.373133, Batch Acc: 0.600316, Tokens per Sec:     3172, Lr: 0.000300
2024-05-27 19:43:58,931 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.564350, Batch Acc: 0.597587, Tokens per Sec:     3270, Lr: 0.000300
2024-05-27 19:43:58,931 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:43:58,931 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:44:55,630 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.55, generation: 56.6925[sec], evaluation: 0.0000[sec]
2024-05-27 19:44:55,631 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:44:55,744 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/20500.ckpt
2024-05-27 19:44:55,753 - INFO - joeynmt.training - Example #0
2024-05-27 19:44:55,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:44:55,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:44:55,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 't@@', 'ica', 'of', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', 'size', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'ed', 'the', '40', 'percent', '.', '</s>']
2024-05-27 19:44:55,753 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:44:55,753 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:44:55,753 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the artica of the artica , which for almost three million years had the size of 48 United States continental size , it &apos;s retrofed the 40 percent .
2024-05-27 19:44:55,753 - INFO - joeynmt.training - Example #1
2024-05-27 19:44:55,753 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:44:55,753 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:44:55,753 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', '&apos;s', 'this', 'sub@@', 'j@@', 'ec@@', 'ti@@', 'vely', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'a', 'sp@@', 'ac@@', 'es', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:44:55,753 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Hypothesis: But that &apos;s this subjectively gravity of the problem because it &apos;s not a spaces of the ice .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - Example #2
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'of', 'the', 'ar@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Hypothesis: The artica of the artica is , in a sense , the heart of global climate system .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - Example #3
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'on', 'the', 'win@@', 'ter', 'and', 'you', '&apos;re', 're@@', 'tre@@', 'ating', '.', '</s>']
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Hypothesis: It expanded on the winter and you &apos;re retreating .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - Example #4
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:44:55,754 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'ven@@', 'ue', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:44:55,754 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying revenue of the last 25 years .
2024-05-27 19:45:16,259 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.654343, Batch Acc: 0.593864, Tokens per Sec:     3350, Lr: 0.000300
2024-05-27 19:45:37,867 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.415326, Batch Acc: 0.589702, Tokens per Sec:     3206, Lr: 0.000300
2024-05-27 19:45:46,270 - INFO - joeynmt.training - Epoch   6: total training loss 5647.73
2024-05-27 19:45:46,271 - INFO - joeynmt.training - EPOCH 7
2024-05-27 19:46:01,679 - INFO - joeynmt.training - Epoch   7, Step:    23300, Batch Loss:     1.341947, Batch Acc: 0.616011, Tokens per Sec:     2887, Lr: 0.000300
2024-05-27 19:46:25,001 - INFO - joeynmt.training - Epoch   7, Step:    23400, Batch Loss:     1.267121, Batch Acc: 0.625533, Tokens per Sec:     3077, Lr: 0.000300
2024-05-27 19:46:48,204 - INFO - joeynmt.training - Epoch   7, Step:    23500, Batch Loss:     1.462304, Batch Acc: 0.613699, Tokens per Sec:     3106, Lr: 0.000300
2024-05-27 19:46:48,205 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:46:48,205 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:47:44,922 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.35, acc:   0.55, generation: 56.7098[sec], evaluation: 0.0000[sec]
2024-05-27 19:47:45,061 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/21500.ckpt
2024-05-27 19:47:45,066 - INFO - joeynmt.training - Example #0
2024-05-27 19:47:45,066 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:47:45,066 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:47:45,066 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'e@@', 'ar', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', ',', 'it', '&apos;s', 're@@', 'tro@@', 'ying', '40', 'percent', '.', '</s>']
2024-05-27 19:47:45,066 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:47:45,066 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:47:45,066 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the glacial calear , which for almost three million years had the size of 48 , the United States continental dimensions , it &apos;s retroying 40 percent .
2024-05-27 19:47:45,066 - INFO - joeynmt.training - Example #1
2024-05-27 19:47:45,066 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:47:45,066 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:47:45,066 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'b@@', 'ition', 'of', 'ice', '.', '</s>']
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Hypothesis: But this underneath the gravity of the problem because it &apos;s not exhibition of ice .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - Example #2
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'ice', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'climate', 'system', '.', '</s>']
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Hypothesis: The glacial ice ice ice ice is , in a sense , the clean of global climate climate system .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - Example #3
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'of', 'win@@', 'ter', 'and', 're@@', 'tre@@', 'ated', 'in', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Hypothesis: It expands of winter and retreated in summer .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - Example #4
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:47:45,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'ven@@', 'ess', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:47:45,067 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying reveness of the last 25 years .
2024-05-27 19:48:07,280 - INFO - joeynmt.training - Epoch   7, Step:    23600, Batch Loss:     1.415245, Batch Acc: 0.619187, Tokens per Sec:     3151, Lr: 0.000300
2024-05-27 19:48:32,740 - INFO - joeynmt.training - Epoch   7, Step:    23700, Batch Loss:     1.597340, Batch Acc: 0.613539, Tokens per Sec:     2747, Lr: 0.000300
2024-05-27 19:48:57,054 - INFO - joeynmt.training - Epoch   7, Step:    23800, Batch Loss:     1.576721, Batch Acc: 0.611096, Tokens per Sec:     2928, Lr: 0.000300
2024-05-27 19:49:20,135 - INFO - joeynmt.training - Epoch   7, Step:    23900, Batch Loss:     1.205565, Batch Acc: 0.612526, Tokens per Sec:     2934, Lr: 0.000300
2024-05-27 19:49:43,020 - INFO - joeynmt.training - Epoch   7, Step:    24000, Batch Loss:     1.455404, Batch Acc: 0.611567, Tokens per Sec:     3107, Lr: 0.000300
2024-05-27 19:49:43,021 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:49:43,021 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:50:31,220 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.35, acc:   0.55, generation: 48.1922[sec], evaluation: 0.0000[sec]
2024-05-27 19:50:31,341 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/21000.ckpt
2024-05-27 19:50:31,347 - INFO - joeynmt.training - Example #0
2024-05-27 19:50:31,347 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:50:31,347 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:50:31,347 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', 'contin@@', 'ents', ',', 'the', 'United', 'States', 'contin@@', 'ents', ',', 'you', 're@@', 'tro@@', 'f@@', 'ed', '40', 'percent', '.', '</s>']
2024-05-27 19:50:31,347 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to demonstrate that the glacial calculus , which for almost three million years had the size of the 48 United States continents , the United States continents , you retrofed 40 percent .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - Example #1
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', '-@@', 'up', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'about', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Hypothesis: But this sub-up the gravity of the problem because it &apos;s not about the ice of the ice .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - Example #2
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Hypothesis: The artica ice ice ice is , in a sense , the clean of global climate system .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - Example #3
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 're@@', 'tre@@', 'at', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and retreat the summer .
2024-05-27 19:50:31,348 - INFO - joeynmt.training - Example #4
2024-05-27 19:50:31,348 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:50:31,349 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:50:31,349 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', '-@@', 'rel@@', 'ated', 're@@', 'mark@@', 'able', 're@@', 'ven@@', 'ue', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:50:31,349 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:50:31,349 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:50:31,349 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying re-related remarkable revenue of the last 25 years .
2024-05-27 19:50:56,174 - INFO - joeynmt.training - Epoch   7, Step:    24100, Batch Loss:     1.340857, Batch Acc: 0.605037, Tokens per Sec:     2817, Lr: 0.000300
2024-05-27 19:51:20,621 - INFO - joeynmt.training - Epoch   7, Step:    24200, Batch Loss:     1.381221, Batch Acc: 0.609732, Tokens per Sec:     2849, Lr: 0.000300
2024-05-27 19:51:43,360 - INFO - joeynmt.training - Epoch   7, Step:    24300, Batch Loss:     1.460327, Batch Acc: 0.608285, Tokens per Sec:     3167, Lr: 0.000300
2024-05-27 19:52:06,924 - INFO - joeynmt.training - Epoch   7, Step:    24400, Batch Loss:     1.401267, Batch Acc: 0.613271, Tokens per Sec:     2990, Lr: 0.000300
2024-05-27 19:52:30,239 - INFO - joeynmt.training - Epoch   7, Step:    24500, Batch Loss:     1.391494, Batch Acc: 0.613794, Tokens per Sec:     2940, Lr: 0.000300
2024-05-27 19:52:30,239 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:52:30,239 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:53:23,918 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.55, generation: 53.6706[sec], evaluation: 0.0000[sec]
2024-05-27 19:53:23,920 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:53:24,072 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/22500.ckpt
2024-05-27 19:53:24,075 - INFO - joeynmt.training - Example #0
2024-05-27 19:53:24,075 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:53:24,075 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:53:24,075 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'slide', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 't@@', 'work', 'of', 'the', 'ar@@', 't@@', 'work', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'U.S.', 'contin@@', 'ents', ',', 'the', 'size', 'of', 'the', '4@@', '4@@', '8', 'U.S.', 'contin@@', 'ents', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'its', 'of', '40', 'percent', '.', '</s>']
2024-05-27 19:53:24,075 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide to demonstrate that the artwork of the artwork , which for almost three million years had the size of the 48 U.S. continents , the size of the 448 U.S. continents , it &apos;s retrofits of 40 percent .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - Example #1
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Hypothesis: But this subject gravity of the problem because it &apos;s not showing the ice of the ice of the ice of the ice .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - Example #2
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'ice', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'climate', 'system', '.', '</s>']
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Hypothesis: The glacial ice ice ice ice is , in a sense , the heart of the climate system .
2024-05-27 19:53:24,076 - INFO - joeynmt.training - Example #3
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:53:24,076 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'the', 'win@@', 'ter', 'and', 'the', 'sum@@', 'mer', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:53:24,076 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:53:24,077 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:53:24,077 - INFO - joeynmt.training - 	Hypothesis: It expanded up the winter and the summer summer .
2024-05-27 19:53:24,077 - INFO - joeynmt.training - Example #4
2024-05-27 19:53:24,077 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:53:24,077 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:53:24,077 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ying', 'of', 'the', 'next', '25', 'years', '.', '</s>']
2024-05-27 19:53:24,077 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:53:24,077 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:53:24,077 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carlying of the next 25 years .
2024-05-27 19:53:53,562 - INFO - joeynmt.training - Epoch   7, Step:    24600, Batch Loss:     1.214110, Batch Acc: 0.614162, Tokens per Sec:     2385, Lr: 0.000300
2024-05-27 19:54:19,625 - INFO - joeynmt.training - Epoch   7, Step:    24700, Batch Loss:     1.369449, Batch Acc: 0.612707, Tokens per Sec:     2694, Lr: 0.000300
2024-05-27 19:54:44,482 - INFO - joeynmt.training - Epoch   7, Step:    24800, Batch Loss:     1.453649, Batch Acc: 0.602564, Tokens per Sec:     2824, Lr: 0.000300
2024-05-27 19:55:08,743 - INFO - joeynmt.training - Epoch   7, Step:    24900, Batch Loss:     1.435458, Batch Acc: 0.607277, Tokens per Sec:     2866, Lr: 0.000300
2024-05-27 19:55:33,541 - INFO - joeynmt.training - Epoch   7, Step:    25000, Batch Loss:     1.507322, Batch Acc: 0.605628, Tokens per Sec:     2936, Lr: 0.000300
2024-05-27 19:55:33,541 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:55:33,541 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:56:25,307 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.35, acc:   0.55, generation: 51.7569[sec], evaluation: 0.0000[sec]
2024-05-27 19:56:25,462 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/22000.ckpt
2024-05-27 19:56:25,467 - INFO - joeynmt.training - Example #0
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'up', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'ate', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', 'dimen@@', 'sions', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p', '40', 'percent', '.', '</s>']
2024-05-27 19:56:25,467 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:56:25,467 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:56:25,467 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide up to show that the glacial calculate , which for almost three million years had the size of the 48 United States continental dimensions , it &apos;s restrip 40 percent .
2024-05-27 19:56:25,467 - INFO - joeynmt.training - Example #1
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'ten@@', 'ding', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 19:56:25,467 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:56:25,467 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:56:25,467 - INFO - joeynmt.training - 	Hypothesis: However this underlying gravity of the problem because it &apos;s not extending of the ice of the ice of the ice .
2024-05-27 19:56:25,467 - INFO - joeynmt.training - Example #2
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:56:25,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'cal@@', 'm', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'heart', 'of', 'the', 'gl@@', 'aci@@', 'al', 'climate', 'system', '.', '</s>']
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Hypothesis: The glacial calm is , in a certain sense , the heart of the glacial climate system .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - Example #3
2024-05-27 19:56:25,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:56:25,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:56:25,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'on', 'the', 'win@@', 'ter', 'and', 'you', '&apos;re', 'going', 'to', 'be', 're@@', 'tre@@', 'ated', '.', '</s>']
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Hypothesis: It expands on the winter and you &apos;re going to be retreated .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - Example #4
2024-05-27 19:56:25,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:56:25,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:56:25,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'qu@@', 'ick', 's@@', 'at', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:56:25,468 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick quick sat the last 25 years .
2024-05-27 19:56:55,205 - INFO - joeynmt.training - Epoch   7, Step:    25100, Batch Loss:     1.284772, Batch Acc: 0.604963, Tokens per Sec:     2351, Lr: 0.000300
2024-05-27 19:57:19,414 - INFO - joeynmt.training - Epoch   7, Step:    25200, Batch Loss:     1.507279, Batch Acc: 0.607397, Tokens per Sec:     2866, Lr: 0.000300
2024-05-27 19:57:44,696 - INFO - joeynmt.training - Epoch   7, Step:    25300, Batch Loss:     1.460402, Batch Acc: 0.606305, Tokens per Sec:     2806, Lr: 0.000300
2024-05-27 19:58:12,457 - INFO - joeynmt.training - Epoch   7, Step:    25400, Batch Loss:     1.610619, Batch Acc: 0.606950, Tokens per Sec:     2566, Lr: 0.000300
2024-05-27 19:58:37,478 - INFO - joeynmt.training - Epoch   7, Step:    25500, Batch Loss:     1.497503, Batch Acc: 0.602283, Tokens per Sec:     2851, Lr: 0.000300
2024-05-27 19:58:37,479 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 19:58:37,479 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 19:59:33,162 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.67, ppl:   5.29, acc:   0.55, generation: 55.6766[sec], evaluation: 0.0000[sec]
2024-05-27 19:59:33,164 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 19:59:33,291 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/24000.ckpt
2024-05-27 19:59:33,293 - INFO - joeynmt.training - Example #0
2024-05-27 19:59:33,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 19:59:33,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 19:59:33,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'slide', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'ice', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'contin@@', 'ent@@', 'al', '4@@', '8', ',', 'the', 'United', 'States', 'has', 'been', 're@@', 'str@@', 'i@@', 'p', 'of', '40', 'percent', '.', '</s>']
2024-05-27 19:59:33,293 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 19:59:33,293 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 19:59:33,293 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide to show that the glacial ice to demonstrate that for almost three million years had the size of 48 , the United States continental 48 , the United States has been restrip of 40 percent .
2024-05-27 19:59:33,293 - INFO - joeynmt.training - Example #1
2024-05-27 19:59:33,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 19:59:33,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'b@@', 'ition', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Hypothesis: However this underneath the gravity of the problem because it doesn &apos;t exhibition the ice of ice .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - Example #2
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Hypothesis: The artica ice ice is , in a sense , the heart of global climate system .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - Example #3
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'the', 'in@@', 'ver@@', 'n', 'and', 're@@', 'tre@@', 'at', 'sum@@', 'mer', '.', '</s>']
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - 	Hypothesis: It expanded up the invern and retreat summer .
2024-05-27 19:59:33,294 - INFO - joeynmt.training - Example #4
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 19:59:33,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 'car@@', 'r@@', 'ying', 'on', 'the', 's@@', 'ell', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 19:59:33,295 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 19:59:33,295 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 19:59:33,295 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying carrying on the sell of the last 25 years .
2024-05-27 19:59:59,140 - INFO - joeynmt.training - Epoch   7, Step:    25600, Batch Loss:     1.440919, Batch Acc: 0.604107, Tokens per Sec:     2741, Lr: 0.000300
2024-05-27 20:00:25,400 - INFO - joeynmt.training - Epoch   7, Step:    25700, Batch Loss:     1.304672, Batch Acc: 0.608314, Tokens per Sec:     2738, Lr: 0.000300
2024-05-27 20:00:52,879 - INFO - joeynmt.training - Epoch   7, Step:    25800, Batch Loss:     1.459963, Batch Acc: 0.606357, Tokens per Sec:     2560, Lr: 0.000300
2024-05-27 20:01:18,595 - INFO - joeynmt.training - Epoch   7, Step:    25900, Batch Loss:     1.442524, Batch Acc: 0.599787, Tokens per Sec:     2737, Lr: 0.000300
2024-05-27 20:01:43,800 - INFO - joeynmt.training - Epoch   7, Step:    26000, Batch Loss:     1.445522, Batch Acc: 0.605906, Tokens per Sec:     2727, Lr: 0.000300
2024-05-27 20:01:43,801 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:01:43,802 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:02:38,782 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.55, generation: 54.9735[sec], evaluation: 0.0000[sec]
2024-05-27 20:02:38,784 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:02:38,911 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/25000.ckpt
2024-05-27 20:02:38,915 - INFO - joeynmt.training - Example #0
2024-05-27 20:02:38,915 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:02:38,915 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:02:38,915 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'the', 'size', 'of', 'the', '4@@', '8', '.', '</s>']
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the glacial calculus , which for almost three million years had the size of the 48 United States continental , the size of the 48 continental , the size of the 48 .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - Example #1
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Hypothesis: However this underlying gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - Example #2
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', ',', 'the', 'heart', 'of', 'climate', 'system', '.', '</s>']
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - 	Hypothesis: The artica ice is , in a sense , the clean , the heart of climate system .
2024-05-27 20:02:38,916 - INFO - joeynmt.training - Example #3
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:02:38,916 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'comes', 'from', 'win@@', 'ter', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'sum@@', 'mer', '.', '</s>']
2024-05-27 20:02:38,917 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:02:38,917 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:02:38,917 - INFO - joeynmt.training - 	Hypothesis: It comes from winter and you &apos;re going to be summer .
2024-05-27 20:02:38,917 - INFO - joeynmt.training - Example #4
2024-05-27 20:02:38,917 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:02:38,917 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:02:38,917 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'ach@@', 'ing', 'car@@', 'r@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:02:38,917 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:02:38,917 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:02:38,917 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a reaching carrying on the last 25 years .
2024-05-27 20:03:04,564 - INFO - joeynmt.training - Epoch   7, Step:    26100, Batch Loss:     1.521230, Batch Acc: 0.602789, Tokens per Sec:     2684, Lr: 0.000300
2024-05-27 20:03:29,264 - INFO - joeynmt.training - Epoch   7, Step:    26200, Batch Loss:     1.265423, Batch Acc: 0.606779, Tokens per Sec:     2800, Lr: 0.000300
2024-05-27 20:03:56,016 - INFO - joeynmt.training - Epoch   7, Step:    26300, Batch Loss:     1.420341, Batch Acc: 0.600297, Tokens per Sec:     2716, Lr: 0.000300
2024-05-27 20:04:23,511 - INFO - joeynmt.training - Epoch   7, Step:    26400, Batch Loss:     1.353108, Batch Acc: 0.606083, Tokens per Sec:     2519, Lr: 0.000300
2024-05-27 20:04:48,854 - INFO - joeynmt.training - Epoch   7, Step:    26500, Batch Loss:     1.510549, Batch Acc: 0.602789, Tokens per Sec:     2787, Lr: 0.000300
2024-05-27 20:04:48,854 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:04:48,855 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:05:48,516 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.55, generation: 59.6550[sec], evaluation: 0.0000[sec]
2024-05-27 20:05:48,518 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:05:48,638 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/23500.ckpt
2024-05-27 20:05:48,642 - INFO - joeynmt.training - Example #0
2024-05-27 20:05:48,642 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:05:48,642 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:05:48,642 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'of', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'United', 'States', '.', '</s>']
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the artica of the artica , which for almost three million years had the size of 48 , the size of the 48 continental United States .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - Example #1
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', 'sub@@', 't@@', 'le', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Hypothesis: But that subtle the gravity of the problem because it &apos;s not the ice of the ice of the ice .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - Example #2
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'ice', 'is', ',', 'in', 'a', 'way', ',', 'the', 'f@@', 'ear@@', 'th', 'heart', 'of', 'global', 'climate', '.', '</s>']
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Hypothesis: The artica ice ice is , in a way , the fearth heart of global climate .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - Example #3
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:05:48,643 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'in', 'the', 'win@@', 'ter', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'sum@@', 'mer', '.', '</s>']
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:05:48,643 - INFO - joeynmt.training - 	Hypothesis: It expanded up in the winter and you &apos;re going to be summer .
2024-05-27 20:05:48,644 - INFO - joeynmt.training - Example #4
2024-05-27 20:05:48,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:05:48,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:05:48,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'car@@', 'l@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:05:48,644 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:05:48,644 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:05:48,644 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable carlying on the last 25 years .
2024-05-27 20:06:15,375 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.346958, Batch Acc: 0.600976, Tokens per Sec:     2649, Lr: 0.000300
2024-05-27 20:06:41,378 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.367667, Batch Acc: 0.603835, Tokens per Sec:     2692, Lr: 0.000300
2024-05-27 20:07:07,079 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.410128, Batch Acc: 0.602341, Tokens per Sec:     2776, Lr: 0.000300
2024-05-27 20:07:32,601 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.508671, Batch Acc: 0.595774, Tokens per Sec:     2763, Lr: 0.000300
2024-05-27 20:07:58,817 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.683195, Batch Acc: 0.607780, Tokens per Sec:     2703, Lr: 0.000300
2024-05-27 20:07:58,818 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:07:58,818 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:08:53,615 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.55, generation: 54.7906[sec], evaluation: 0.0000[sec]
2024-05-27 20:08:53,617 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:08:53,743 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/23000.ckpt
2024-05-27 20:08:53,747 - INFO - joeynmt.training - Example #0
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'th@@', 'ic', 'gl@@', 'aci@@', 'al', 'cal@@', 'f', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'U.S.', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the arthic glacial calf , which is almost three million years had the size of the 48 U.S. continental , it &apos;s retrofit of 40 percent .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - Example #1
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'ice', '.', '</s>']
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Hypothesis: However this underlying the gravity of the problem because it doesn &apos;t show the spessor of ice .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - Example #2
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:08:53,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ave', 'gl@@', 'aci@@', 'al', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - 	Hypothesis: The arcave glacial ice is , in a sense , the heart of global climate system .
2024-05-27 20:08:53,748 - INFO - joeynmt.training - Example #3
2024-05-27 20:08:53,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:08:53,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:08:53,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'in', 'the', 'sum@@', 'mer', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 20:08:53,749 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:08:53,749 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:08:53,749 - INFO - joeynmt.training - 	Hypothesis: It expanded up in the summer and retreatment .
2024-05-27 20:08:53,749 - INFO - joeynmt.training - Example #4
2024-05-27 20:08:53,749 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:08:53,749 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:08:53,749 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'p@@', 'ast@@', 'ing', 'r@@', 'r@@', 'ing', 'about', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:08:53,749 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:08:53,749 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:08:53,749 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable pasting rring about the last 25 years .
2024-05-27 20:09:21,007 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.423759, Batch Acc: 0.608394, Tokens per Sec:     2639, Lr: 0.000300
2024-05-27 20:09:22,830 - INFO - joeynmt.training - Epoch   7: total training loss 5471.22
2024-05-27 20:09:22,831 - INFO - joeynmt.training - EPOCH 8
2024-05-27 20:09:48,253 - INFO - joeynmt.training - Epoch   8, Step:    27200, Batch Loss:     1.412120, Batch Acc: 0.622682, Tokens per Sec:     2656, Lr: 0.000300
2024-05-27 20:10:14,494 - INFO - joeynmt.training - Epoch   8, Step:    27300, Batch Loss:     1.312530, Batch Acc: 0.624305, Tokens per Sec:     2660, Lr: 0.000300
2024-05-27 20:10:40,614 - INFO - joeynmt.training - Epoch   8, Step:    27400, Batch Loss:     1.246112, Batch Acc: 0.626229, Tokens per Sec:     2667, Lr: 0.000300
2024-05-27 20:11:06,132 - INFO - joeynmt.training - Epoch   8, Step:    27500, Batch Loss:     1.432757, Batch Acc: 0.626524, Tokens per Sec:     2836, Lr: 0.000300
2024-05-27 20:11:06,132 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:11:06,132 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:12:03,732 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.25, acc:   0.56, generation: 57.5929[sec], evaluation: 0.0000[sec]
2024-05-27 20:12:03,857 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/24500.ckpt
2024-05-27 20:12:03,862 - INFO - joeynmt.training - Example #0
2024-05-27 20:12:03,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:12:03,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:12:03,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'of', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'has', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'U.S.', 'contin@@', 'ent@@', 'al', 'size', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:12:03,862 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:12:03,862 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:12:03,862 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the artica of the artica , which is almost three million years has had the size of the 48 U.S. continental size , it &apos;s retrofit of 40 percent .
2024-05-27 20:12:03,862 - INFO - joeynmt.training - Example #1
2024-05-27 20:12:03,862 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:12:03,862 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:12:03,862 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 't@@', 'le', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:12:03,862 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:12:03,862 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:12:03,862 - INFO - joeynmt.training - 	Hypothesis: But this subtle the gravity of the problem because it doesn &apos;t show the ice ice of the ice .
2024-05-27 20:12:03,862 - INFO - joeynmt.training - Example #2
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Hypothesis: The artica ice ice ice is , in a sense , the heart of the global climate system .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - Example #3
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'sum@@', 'mer', 're@@', 'ver@@', 'se', '.', '</s>']
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Hypothesis: It expanded up and summer reverse .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - Example #4
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:12:03,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 'car@@', 'l@@', 'on@@', 'ed', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:12:03,863 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying carloned on the last 25 years .
2024-05-27 20:12:30,189 - INFO - joeynmt.training - Epoch   8, Step:    27600, Batch Loss:     1.480795, Batch Acc: 0.626512, Tokens per Sec:     2641, Lr: 0.000300
2024-05-27 20:12:56,076 - INFO - joeynmt.training - Epoch   8, Step:    27700, Batch Loss:     1.306397, Batch Acc: 0.625348, Tokens per Sec:     2733, Lr: 0.000300
2024-05-27 20:13:21,646 - INFO - joeynmt.training - Epoch   8, Step:    27800, Batch Loss:     1.304534, Batch Acc: 0.622804, Tokens per Sec:     2798, Lr: 0.000300
2024-05-27 20:13:46,596 - INFO - joeynmt.training - Epoch   8, Step:    27900, Batch Loss:     1.533486, Batch Acc: 0.625018, Tokens per Sec:     2794, Lr: 0.000300
2024-05-27 20:14:14,074 - INFO - joeynmt.training - Epoch   8, Step:    28000, Batch Loss:     1.337014, Batch Acc: 0.621560, Tokens per Sec:     2555, Lr: 0.000300
2024-05-27 20:14:14,074 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:14:14,074 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:15:09,961 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.26, acc:   0.55, generation: 55.8780[sec], evaluation: 0.0000[sec]
2024-05-27 20:15:10,098 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/25500.ckpt
2024-05-27 20:15:10,102 - INFO - joeynmt.training - Example #0
2024-05-27 20:15:10,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:15:10,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:15:10,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'ice', 'ice', 'ice', 'ice', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'tro@@', 'ops', '40', 'percent', '.', '</s>']
2024-05-27 20:15:10,102 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:15:10,102 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:15:10,102 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial ice ice ice ice , which is almost three million years had the size of 48 , the size of 48 United States continental , it &apos;s retroops 40 percent .
2024-05-27 20:15:10,102 - INFO - joeynmt.training - Example #1
2024-05-27 20:15:10,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:15:10,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:15:10,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', ',', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'b@@', 'ition', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 20:15:10,102 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:15:10,102 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:15:10,102 - INFO - joeynmt.training - 	Hypothesis: However , this underlying gravity of the problem because it doesn &apos;t exhibition the ice of ice .
2024-05-27 20:15:10,102 - INFO - joeynmt.training - Example #2
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Hypothesis: The artica ice ice is , in a sense , the clean heart of global climate system .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - Example #3
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', '&apos;re', 'de@@', 'al@@', 'ing', '.', '</s>']
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and you &apos;re dealing .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - Example #4
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:15:10,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 'b@@', 'ul@@', 'ed', 'by', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:15:10,103 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying buled by the last 25 years .
2024-05-27 20:15:36,047 - INFO - joeynmt.training - Epoch   8, Step:    28100, Batch Loss:     1.409965, Batch Acc: 0.620404, Tokens per Sec:     2746, Lr: 0.000300
2024-05-27 20:16:02,420 - INFO - joeynmt.training - Epoch   8, Step:    28200, Batch Loss:     1.108314, Batch Acc: 0.615040, Tokens per Sec:     2795, Lr: 0.000300
2024-05-27 20:16:28,068 - INFO - joeynmt.training - Epoch   8, Step:    28300, Batch Loss:     1.420699, Batch Acc: 0.619589, Tokens per Sec:     2841, Lr: 0.000300
2024-05-27 20:16:53,578 - INFO - joeynmt.training - Epoch   8, Step:    28400, Batch Loss:     1.382517, Batch Acc: 0.617645, Tokens per Sec:     2709, Lr: 0.000300
2024-05-27 20:17:18,619 - INFO - joeynmt.training - Epoch   8, Step:    28500, Batch Loss:     1.254256, Batch Acc: 0.617706, Tokens per Sec:     2806, Lr: 0.000300
2024-05-27 20:17:18,620 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:17:18,620 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:18:15,251 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.24, acc:   0.55, generation: 56.6237[sec], evaluation: 0.0000[sec]
2024-05-27 20:18:15,379 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/28000.ckpt
2024-05-27 20:18:15,380 - INFO - joeynmt.helpers - delete /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/28000.ckpt
2024-05-27 20:18:15,380 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/28000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/28000.ckpt')
2024-05-27 20:18:15,380 - INFO - joeynmt.training - Example #0
2024-05-27 20:18:15,380 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:18:15,380 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:18:15,380 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'showed', 'these', 'slide', 'slide', 'to', 'prove', 'that', 'the', 'gl@@', 'aci@@', 'al', 'ice', 'ice', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', ',', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slide slide to prove that the glacial ice ice , which is almost three million years had the size of the 48 United States , the size of 48 United States , it &apos;s retrofit of 40 percent .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - Example #1
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Hypothesis: But this underneath the gravity of the problem because it &apos;s not showing the ice ice of the ice .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - Example #2
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'cal@@', 'f', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - 	Hypothesis: The arctic calf is , in a sense , the heart of the global climate system .
2024-05-27 20:18:15,381 - INFO - joeynmt.training - Example #3
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:18:15,381 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 20:18:15,382 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:18:15,382 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:18:15,382 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and you &apos;re going to be expanded .
2024-05-27 20:18:15,382 - INFO - joeynmt.training - Example #4
2024-05-27 20:18:15,382 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:18:15,382 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:18:15,382 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ed', 'with', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:18:15,382 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:18:15,382 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:18:15,382 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carled with the last 25 years .
2024-05-27 20:18:40,304 - INFO - joeynmt.training - Epoch   8, Step:    28600, Batch Loss:     1.350690, Batch Acc: 0.618402, Tokens per Sec:     2828, Lr: 0.000300
2024-05-27 20:19:06,640 - INFO - joeynmt.training - Epoch   8, Step:    28700, Batch Loss:     1.447884, Batch Acc: 0.617338, Tokens per Sec:     2670, Lr: 0.000300
2024-05-27 20:19:32,272 - INFO - joeynmt.training - Epoch   8, Step:    28800, Batch Loss:     1.484233, Batch Acc: 0.617140, Tokens per Sec:     2773, Lr: 0.000300
2024-05-27 20:19:58,227 - INFO - joeynmt.training - Epoch   8, Step:    28900, Batch Loss:     1.528038, Batch Acc: 0.611177, Tokens per Sec:     2724, Lr: 0.000300
2024-05-27 20:20:26,160 - INFO - joeynmt.training - Epoch   8, Step:    29000, Batch Loss:     1.413502, Batch Acc: 0.617399, Tokens per Sec:     2540, Lr: 0.000300
2024-05-27 20:20:26,160 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:20:26,160 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:21:19,219 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.56, generation: 53.0522[sec], evaluation: 0.0000[sec]
2024-05-27 20:21:19,222 - INFO - joeynmt.training - Example #0
2024-05-27 20:21:19,222 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:21:19,222 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:21:19,222 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'slide', 'slide', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'cal@@', 'cal@@', 'f', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'has', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'ent@@', 'al', 'contin@@', 'ents', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide slide to demonstrate that the glacial calcalf , which for almost three million years , has the size of 48 , the size of 48 , the size of 48 , the ental continents , it &apos;s retrofit of 40 percent .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - Example #1
2024-05-27 20:21:19,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:21:19,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:21:19,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Hypothesis: However this underlying gravity of the problem because it &apos;s not showing the ice of the ice .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - Example #2
2024-05-27 20:21:19,223 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:21:19,223 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:21:19,223 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'cal@@', 'f', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - 	Hypothesis: The arctic calf is , in a sense , the clean heart of global climate system .
2024-05-27 20:21:19,223 - INFO - joeynmt.training - Example #3
2024-05-27 20:21:19,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:21:19,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:21:19,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'sum@@', 'mer', '.', '</s>']
2024-05-27 20:21:19,224 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:21:19,224 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:21:19,224 - INFO - joeynmt.training - 	Hypothesis: It expanded up and you &apos;re going to be summer .
2024-05-27 20:21:19,224 - INFO - joeynmt.training - Example #4
2024-05-27 20:21:19,224 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:21:19,224 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:21:19,224 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ying', 're@@', 'ven@@', 'ement', 'about', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:21:19,224 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:21:19,224 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:21:19,224 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carlying revenement about the last 25 years .
2024-05-27 20:21:42,944 - INFO - joeynmt.training - Epoch   8, Step:    29100, Batch Loss:     1.359982, Batch Acc: 0.619764, Tokens per Sec:     2992, Lr: 0.000300
2024-05-27 20:22:08,547 - INFO - joeynmt.training - Epoch   8, Step:    29200, Batch Loss:     1.385494, Batch Acc: 0.618049, Tokens per Sec:     2725, Lr: 0.000300
2024-05-27 20:22:33,985 - INFO - joeynmt.training - Epoch   8, Step:    29300, Batch Loss:     1.615452, Batch Acc: 0.610722, Tokens per Sec:     2750, Lr: 0.000300
2024-05-27 20:22:58,868 - INFO - joeynmt.training - Epoch   8, Step:    29400, Batch Loss:     1.345298, Batch Acc: 0.619492, Tokens per Sec:     2814, Lr: 0.000300
2024-05-27 20:23:23,413 - INFO - joeynmt.training - Epoch   8, Step:    29500, Batch Loss:     1.412177, Batch Acc: 0.614210, Tokens per Sec:     2799, Lr: 0.000300
2024-05-27 20:23:23,413 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:23:23,413 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:24:18,685 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.21, acc:   0.56, generation: 55.2610[sec], evaluation: 0.0000[sec]
2024-05-27 20:24:18,689 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:24:18,895 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/26000.ckpt
2024-05-27 20:24:18,898 - INFO - joeynmt.training - Example #0
2024-05-27 20:24:18,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:24:18,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:24:18,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'the', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent', ',', 'it', 're@@', 'str@@', 'i@@', 'p', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:24:18,898 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:24:18,898 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:24:18,898 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the artica calculus , which for almost three million years had the size of 48 , the size of 48 United States , the continental continent , it restrip of 40 percent .
2024-05-27 20:24:18,898 - INFO - joeynmt.training - Example #1
2024-05-27 20:24:18,898 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:24:18,898 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:24:18,898 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'ice', 'ice', 'ice', '.', '</s>']
2024-05-27 20:24:18,899 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:24:18,899 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:24:18,899 - INFO - joeynmt.training - 	Hypothesis: However this underneath the gravity of the problem because it doesn &apos;t show the ice ice ice ice .
2024-05-27 20:24:18,899 - INFO - joeynmt.training - Example #2
2024-05-27 20:24:18,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:24:18,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:24:18,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'climate', 'system', '.', '</s>']
2024-05-27 20:24:18,899 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:24:18,899 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:24:18,899 - INFO - joeynmt.training - 	Hypothesis: The arctic calculus is , in a way , the clean heart of climate system .
2024-05-27 20:24:18,899 - INFO - joeynmt.training - Example #3
2024-05-27 20:24:18,899 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:24:18,899 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:24:18,899 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'and', 're@@', 'ver@@', 'se', 're@@', 'tre@@', 'ated', '.', '</s>']
2024-05-27 20:24:18,900 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:24:18,900 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:24:18,900 - INFO - joeynmt.training - 	Hypothesis: It expanded up and reverse retreated .
2024-05-27 20:24:18,900 - INFO - joeynmt.training - Example #4
2024-05-27 20:24:18,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:24:18,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:24:18,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 'car@@', 'l@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:24:18,900 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:24:18,900 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:24:18,900 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying carlying on the last 25 years .
2024-05-27 20:24:45,988 - INFO - joeynmt.training - Epoch   8, Step:    29600, Batch Loss:     1.500974, Batch Acc: 0.613549, Tokens per Sec:     2542, Lr: 0.000300
2024-05-27 20:25:11,370 - INFO - joeynmt.training - Epoch   8, Step:    29700, Batch Loss:     1.726235, Batch Acc: 0.616163, Tokens per Sec:     2726, Lr: 0.000300
2024-05-27 20:25:37,074 - INFO - joeynmt.training - Epoch   8, Step:    29800, Batch Loss:     1.302082, Batch Acc: 0.611767, Tokens per Sec:     2663, Lr: 0.000300
2024-05-27 20:26:02,052 - INFO - joeynmt.training - Epoch   8, Step:    29900, Batch Loss:     1.211288, Batch Acc: 0.612462, Tokens per Sec:     2841, Lr: 0.000300
2024-05-27 20:26:26,778 - INFO - joeynmt.training - Epoch   8, Step:    30000, Batch Loss:     1.362561, Batch Acc: 0.614555, Tokens per Sec:     2838, Lr: 0.000300
2024-05-27 20:26:26,778 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:26:26,778 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:27:23,337 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.17, acc:   0.56, generation: 56.5527[sec], evaluation: 0.0000[sec]
2024-05-27 20:27:23,339 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:27:23,466 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/26500.ckpt
2024-05-27 20:27:23,471 - INFO - joeynmt.training - Example #0
2024-05-27 20:27:23,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:27:23,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:27:23,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'years', 'had', 'the', 'size', 'size', '.', '</s>']
2024-05-27 20:27:23,471 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:27:23,471 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:27:23,471 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arctic ice , which for almost three million years had the size of 48 years had the size of 48 years had the size of 48 years had the size size .
2024-05-27 20:27:23,471 - INFO - joeynmt.training - Example #1
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'trem@@', 'ely', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Hypothesis: But this underlying gravity of the problem because it &apos;s not extremely the ice of the ice .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - Example #2
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Hypothesis: The arctic ice is , in a sense , the sense , the clean heart of global climate system .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - Example #3
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 're@@', 'ver@@', 'n', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and revern expanded .
2024-05-27 20:27:23,472 - INFO - joeynmt.training - Example #4
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:27:23,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:27:23,473 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mot@@', 'e', 're@@', 'ach@@', 'ing', 'r@@', 'ich', 're@@', 'ven@@', 'ement', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:27:23,473 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:27:23,473 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:27:23,473 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remote reaching rich revenement last 25 years .
2024-05-27 20:27:48,980 - INFO - joeynmt.training - Epoch   8, Step:    30100, Batch Loss:     1.365373, Batch Acc: 0.614092, Tokens per Sec:     2702, Lr: 0.000300
2024-05-27 20:28:13,904 - INFO - joeynmt.training - Epoch   8, Step:    30200, Batch Loss:     1.274390, Batch Acc: 0.611148, Tokens per Sec:     2813, Lr: 0.000300
2024-05-27 20:28:40,893 - INFO - joeynmt.training - Epoch   8, Step:    30300, Batch Loss:     1.682589, Batch Acc: 0.615836, Tokens per Sec:     2610, Lr: 0.000300
2024-05-27 20:29:06,630 - INFO - joeynmt.training - Epoch   8, Step:    30400, Batch Loss:     1.271460, Batch Acc: 0.612934, Tokens per Sec:     2833, Lr: 0.000300
2024-05-27 20:29:31,200 - INFO - joeynmt.training - Epoch   8, Step:    30500, Batch Loss:     1.446658, Batch Acc: 0.611645, Tokens per Sec:     2944, Lr: 0.000300
2024-05-27 20:29:31,200 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:29:31,200 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:30:23,124 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.56, generation: 51.9172[sec], evaluation: 0.0000[sec]
2024-05-27 20:30:23,250 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/27500.ckpt
2024-05-27 20:30:23,254 - INFO - joeynmt.training - Example #0
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'tic', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'of', 'the', 'United', 'States', '.', '</s>']
2024-05-27 20:30:23,254 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:30:23,254 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:30:23,254 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arttic ice , which for almost three million years had the size of the 48 of the United States .
2024-05-27 20:30:23,254 - INFO - joeynmt.training - Example #1
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', ',', 'this', 'sub@@', 'j@@', 'ected', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 20:30:23,254 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:30:23,254 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:30:23,254 - INFO - joeynmt.training - 	Hypothesis: However , this subjected the gravity of the problem because it doesn &apos;t show the ice ice of ice .
2024-05-27 20:30:23,254 - INFO - joeynmt.training - Example #2
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:30:23,254 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:30:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'tic', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Hypothesis: The arttic ice is , in a sense , in a sense , the clean heart of global climate system .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - Example #3
2024-05-27 20:30:23,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:30:23,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:30:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'in', 'the', 'win@@', 'ter', 'and', 'you', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Hypothesis: It expands in the winter and you retreat .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - Example #4
2024-05-27 20:30:23,255 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:30:23,255 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:30:23,255 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'i@@', 'ed', 're@@', 'ven@@', 'ue', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:30:23,255 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a carrelied revenue of the last 25 years .
2024-05-27 20:30:49,397 - INFO - joeynmt.training - Epoch   8, Step:    30600, Batch Loss:     1.283657, Batch Acc: 0.614826, Tokens per Sec:     2640, Lr: 0.000300
2024-05-27 20:31:14,842 - INFO - joeynmt.training - Epoch   8, Step:    30700, Batch Loss:     1.426417, Batch Acc: 0.613876, Tokens per Sec:     2720, Lr: 0.000300
2024-05-27 20:31:39,435 - INFO - joeynmt.training - Epoch   8, Step:    30800, Batch Loss:     1.475009, Batch Acc: 0.605509, Tokens per Sec:     2728, Lr: 0.000300
2024-05-27 20:32:04,318 - INFO - joeynmt.training - Epoch   8, Step:    30900, Batch Loss:     1.508587, Batch Acc: 0.610199, Tokens per Sec:     2851, Lr: 0.000300
2024-05-27 20:32:25,022 - INFO - joeynmt.training - Epoch   8: total training loss 5324.47
2024-05-27 20:32:25,023 - INFO - joeynmt.training - EPOCH 9
2024-05-27 20:32:29,111 - INFO - joeynmt.training - Epoch   9, Step:    31000, Batch Loss:     1.307386, Batch Acc: 0.639591, Tokens per Sec:     2797, Lr: 0.000300
2024-05-27 20:32:29,112 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:32:29,112 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:33:26,152 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.56, generation: 57.0331[sec], evaluation: 0.0000[sec]
2024-05-27 20:33:26,278 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/28500.ckpt
2024-05-27 20:33:26,282 - INFO - joeynmt.training - Example #0
2024-05-27 20:33:26,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:33:26,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:33:26,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'showed', 'these', 'sli@@', 'des', 'sli@@', 'des', 'to', 'show', 'show', 'that', 'the', 'ar@@', 'tic', 'ice', 'ice', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'its', '40', 'percent', '.', '</s>']
2024-05-27 20:33:26,282 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:33:26,282 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:33:26,282 - INFO - joeynmt.training - 	Hypothesis: I showed these slides slides to show show that the artic ice ice , which is almost three million years had the size of 48 , the United States of 48 , the United States of 48 continental , it &apos;s retrofits 40 percent .
2024-05-27 20:33:26,282 - INFO - joeynmt.training - Example #1
2024-05-27 20:33:26,282 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:33:26,282 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:33:26,282 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'ice', 'of', 'the', 'ice', 'ice', '.', '</s>']
2024-05-27 20:33:26,282 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Hypothesis: But this underlying the gravity of the problem because it &apos;s not showing the ice ice of the ice ice .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - Example #2
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'climate', 'system', '.', '</s>']
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Hypothesis: The artica is , in a sense , the heart of the climate system .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - Example #3
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'w@@', 'oo@@', 'ds', 'of', 'win@@', 'ter', 'and', 'you', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - 	Hypothesis: It &apos;s woods of winter and you retreat .
2024-05-27 20:33:26,283 - INFO - joeynmt.training - Example #4
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:33:26,283 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 'car@@', 'r@@', 'ying', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:33:26,284 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:33:26,284 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:33:26,284 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying carrying on the last 25 years .
2024-05-27 20:33:51,670 - INFO - joeynmt.training - Epoch   9, Step:    31100, Batch Loss:     1.250627, Batch Acc: 0.638762, Tokens per Sec:     2728, Lr: 0.000300
2024-05-27 20:34:17,747 - INFO - joeynmt.training - Epoch   9, Step:    31200, Batch Loss:     1.136461, Batch Acc: 0.638117, Tokens per Sec:     2673, Lr: 0.000300
2024-05-27 20:34:42,531 - INFO - joeynmt.training - Epoch   9, Step:    31300, Batch Loss:     1.169520, Batch Acc: 0.639368, Tokens per Sec:     2777, Lr: 0.000300
2024-05-27 20:35:08,015 - INFO - joeynmt.training - Epoch   9, Step:    31400, Batch Loss:     1.328904, Batch Acc: 0.633154, Tokens per Sec:     2676, Lr: 0.000300
2024-05-27 20:35:36,609 - INFO - joeynmt.training - Epoch   9, Step:    31500, Batch Loss:     1.313942, Batch Acc: 0.638281, Tokens per Sec:     2543, Lr: 0.000300
2024-05-27 20:35:36,609 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:35:36,609 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:36:34,342 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.56, generation: 57.7258[sec], evaluation: 0.0000[sec]
2024-05-27 20:36:34,460 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/27000.ckpt
2024-05-27 20:36:34,465 - INFO - joeynmt.training - Example #0
2024-05-27 20:36:34,465 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:36:34,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:36:34,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ica', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'has', 'the', 'size', 'of', '4@@', '8', 'United', 'States', '.', '</s>']
2024-05-27 20:36:34,466 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:36:34,466 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:36:34,466 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the artica to show that the glacial ice , which for almost three million years , has the size of 48 United States .
2024-05-27 20:36:34,466 - INFO - joeynmt.training - Example #1
2024-05-27 20:36:34,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:36:34,466 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:36:34,466 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:36:34,466 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:36:34,466 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:36:34,466 - INFO - joeynmt.training - 	Hypothesis: But this underneath the gravity of the problem because it &apos;s not showing the ice of the ice of the ice .
2024-05-27 20:36:34,466 - INFO - joeynmt.training - Example #2
2024-05-27 20:36:34,466 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:36:34,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:36:34,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'is', 'gl@@', 'aci@@', 'al', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:36:34,467 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:36:34,467 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:36:34,467 - INFO - joeynmt.training - 	Hypothesis: The artica is glacial ice is , in a sense , the clean heart of global climate system .
2024-05-27 20:36:34,467 - INFO - joeynmt.training - Example #3
2024-05-27 20:36:34,467 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:36:34,467 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:36:34,467 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'about', 'win@@', 'ter', 'and', 'the', 'sum@@', 'mer', '.', '</s>']
2024-05-27 20:36:34,467 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:36:34,468 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:36:34,468 - INFO - joeynmt.training - 	Hypothesis: It &apos;s about winter and the summer .
2024-05-27 20:36:34,468 - INFO - joeynmt.training - Example #4
2024-05-27 20:36:34,468 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:36:34,468 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:36:34,468 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ev@@', 'ant', 're@@', 'ven@@', 'ue', ',', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:36:34,468 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:36:34,468 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:36:34,468 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelevant revenue , the last 25 years .
2024-05-27 20:37:00,702 - INFO - joeynmt.training - Epoch   9, Step:    31600, Batch Loss:     1.438061, Batch Acc: 0.630902, Tokens per Sec:     2664, Lr: 0.000300
2024-05-27 20:37:29,349 - INFO - joeynmt.training - Epoch   9, Step:    31700, Batch Loss:     1.414674, Batch Acc: 0.633320, Tokens per Sec:     2516, Lr: 0.000300
2024-05-27 20:37:55,735 - INFO - joeynmt.training - Epoch   9, Step:    31800, Batch Loss:     1.145058, Batch Acc: 0.630383, Tokens per Sec:     2561, Lr: 0.000300
2024-05-27 20:38:22,362 - INFO - joeynmt.training - Epoch   9, Step:    31900, Batch Loss:     1.350046, Batch Acc: 0.624879, Tokens per Sec:     2591, Lr: 0.000300
2024-05-27 20:38:47,323 - INFO - joeynmt.training - Epoch   9, Step:    32000, Batch Loss:     1.306451, Batch Acc: 0.626115, Tokens per Sec:     2766, Lr: 0.000300
2024-05-27 20:38:47,324 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:38:47,324 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:39:47,219 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.22, acc:   0.56, generation: 59.8879[sec], evaluation: 0.0000[sec]
2024-05-27 20:39:47,356 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/31500.ckpt
2024-05-27 20:39:47,357 - INFO - joeynmt.helpers - delete /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/31500.ckpt
2024-05-27 20:39:47,357 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/31500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/31500.ckpt')
2024-05-27 20:39:47,357 - INFO - joeynmt.training - Example #0
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'cal@@', 'f', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'tro@@', 'ops', '40', 'percent', '.', '</s>']
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arctic ice calf , which for almost three million years had the size of 48 , the size of the 48 United States continental , it &apos;s retroops 40 percent .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - Example #1
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ground', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'about', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Hypothesis: But this underground gravity of the problem because it &apos;s not about the ice of the ice .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - Example #2
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:39:47,358 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'cle@@', 'an', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - 	Hypothesis: The arctic calculus is , in a sense , the heart clean , the clean heart of global climate system .
2024-05-27 20:39:47,358 - INFO - joeynmt.training - Example #3
2024-05-27 20:39:47,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:39:47,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:39:47,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'in', 'the', 'sum@@', 'mer', 'and', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 20:39:47,359 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:39:47,359 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:39:47,359 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded in the summer and retreat .
2024-05-27 20:39:47,359 - INFO - joeynmt.training - Example #4
2024-05-27 20:39:47,359 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:39:47,359 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:39:47,359 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ev@@', 'ant', 'rap@@', 'id', 's@@', 'ev@@', 'en@@', '-@@', 'rel@@', 'ated', '.', '</s>']
2024-05-27 20:39:47,359 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:39:47,359 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:39:47,359 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelevant rapid seven-related .
2024-05-27 20:40:12,263 - INFO - joeynmt.training - Epoch   9, Step:    32100, Batch Loss:     1.212342, Batch Acc: 0.631244, Tokens per Sec:     2927, Lr: 0.000300
2024-05-27 20:40:37,878 - INFO - joeynmt.training - Epoch   9, Step:    32200, Batch Loss:     1.325418, Batch Acc: 0.627014, Tokens per Sec:     2745, Lr: 0.000300
2024-05-27 20:41:03,033 - INFO - joeynmt.training - Epoch   9, Step:    32300, Batch Loss:     1.341281, Batch Acc: 0.624763, Tokens per Sec:     2787, Lr: 0.000300
2024-05-27 20:41:29,133 - INFO - joeynmt.training - Epoch   9, Step:    32400, Batch Loss:     1.222634, Batch Acc: 0.628643, Tokens per Sec:     2669, Lr: 0.000300
2024-05-27 20:41:54,259 - INFO - joeynmt.training - Epoch   9, Step:    32500, Batch Loss:     1.260979, Batch Acc: 0.622952, Tokens per Sec:     2755, Lr: 0.000300
2024-05-27 20:41:54,260 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:41:54,260 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:42:55,291 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.56, generation: 61.0244[sec], evaluation: 0.0000[sec]
2024-05-27 20:42:55,434 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/32000.ckpt
2024-05-27 20:42:55,437 - INFO - joeynmt.helpers - delete /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/32000.ckpt
2024-05-27 20:42:55,437 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/32000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/32000.ckpt')
2024-05-27 20:42:55,437 - INFO - joeynmt.training - Example #0
2024-05-27 20:42:55,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:42:55,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:42:55,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'that', 'ar@@', 'c@@', 'tic', 'gl@@', 'aci@@', 'al', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent', ',', 'the', 'United', 'States', 'has', 'been', 're@@', 'struc@@', 'k', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:42:55,437 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:42:55,437 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:42:55,437 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arctic ice ice that arctic glacial , which for almost three million years had the size of the 48 continent , the United States has been restruck of 40 percent .
2024-05-27 20:42:55,437 - INFO - joeynmt.training - Example #1
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Hypothesis: But that underneath the gravity of the problem because it doesn &apos;t show the ice of ice .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - Example #2
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'gl@@', 'aci@@', 'al', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Hypothesis: The arctic ice ice is , in a sense , the glacial heart of global climate system .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - Example #3
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 's@@', 'ounds', 'like', 'the', 'win@@', 'ter', 'and', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - 	Hypothesis: It &apos;s sounds like the winter and retreat .
2024-05-27 20:42:55,438 - INFO - joeynmt.training - Example #4
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:42:55,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 're@@', 'ach@@', 'age', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:42:55,439 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:42:55,439 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:42:55,439 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelated reachage to the last 25 years .
2024-05-27 20:43:23,430 - INFO - joeynmt.training - Epoch   9, Step:    32600, Batch Loss:     1.292235, Batch Acc: 0.623545, Tokens per Sec:     2413, Lr: 0.000300
2024-05-27 20:43:52,470 - INFO - joeynmt.training - Epoch   9, Step:    32700, Batch Loss:     1.192669, Batch Acc: 0.626114, Tokens per Sec:     2395, Lr: 0.000300
2024-05-27 20:44:18,734 - INFO - joeynmt.training - Epoch   9, Step:    32800, Batch Loss:     1.466493, Batch Acc: 0.624300, Tokens per Sec:     2603, Lr: 0.000300
2024-05-27 20:44:45,051 - INFO - joeynmt.training - Epoch   9, Step:    32900, Batch Loss:     1.444879, Batch Acc: 0.627362, Tokens per Sec:     2807, Lr: 0.000300
2024-05-27 20:45:13,410 - INFO - joeynmt.training - Epoch   9, Step:    33000, Batch Loss:     1.255637, Batch Acc: 0.626897, Tokens per Sec:     2516, Lr: 0.000300
2024-05-27 20:45:13,411 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:45:13,411 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:46:15,032 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.56, generation: 61.6135[sec], evaluation: 0.0000[sec]
2024-05-27 20:46:15,034 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:46:15,170 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/29500.ckpt
2024-05-27 20:46:15,174 - INFO - joeynmt.training - Example #0
2024-05-27 20:46:15,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:46:15,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:46:15,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', ',', 'which', 'is', 'the', 'ar@@', 'c@@', 'tic', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'has', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', '4@@', '8', ',', 'the', 'contin@@', 'ent@@', 'al', 'United', 'States', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:46:15,174 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:46:15,174 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:46:15,174 - INFO - joeynmt.training - 	Hypothesis: Last year showed these slides to show that the arctic ice , which is the arctic ice , which for almost three million years has the size of 48 United States , 48 , the continental United States , it &apos;s retrofit of 40 percent .
2024-05-27 20:46:15,174 - INFO - joeynmt.training - Example #1
2024-05-27 20:46:15,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:46:15,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:46:15,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', ',', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 20:46:15,174 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Hypothesis: However , this underlying gravity of the problem because it doesn &apos;t show the ice of ice .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - Example #2
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Hypothesis: The arctic calculus is , in a sense , the clean heart of global climate system .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - Example #3
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'and', 're@@', 'ver@@', 'n', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded and revern expanded .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - Example #4
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:46:15,175 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'id', 'to', 'be', 'a', 'car@@', 'l@@', 'ying', 're@@', 'ven@@', 'ement', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:46:15,175 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying reid to be a carlying revenement last 25 years .
2024-05-27 20:46:39,781 - INFO - joeynmt.training - Epoch   9, Step:    33100, Batch Loss:     1.338292, Batch Acc: 0.629210, Tokens per Sec:     2870, Lr: 0.000300
2024-05-27 20:47:06,527 - INFO - joeynmt.training - Epoch   9, Step:    33200, Batch Loss:     1.340416, Batch Acc: 0.627893, Tokens per Sec:     2748, Lr: 0.000300
2024-05-27 20:47:34,727 - INFO - joeynmt.training - Epoch   9, Step:    33300, Batch Loss:     1.488035, Batch Acc: 0.622146, Tokens per Sec:     2477, Lr: 0.000300
2024-05-27 20:48:01,619 - INFO - joeynmt.training - Epoch   9, Step:    33400, Batch Loss:     1.220485, Batch Acc: 0.618145, Tokens per Sec:     2561, Lr: 0.000300
2024-05-27 20:48:31,981 - INFO - joeynmt.training - Epoch   9, Step:    33500, Batch Loss:     1.376934, Batch Acc: 0.619417, Tokens per Sec:     2287, Lr: 0.000300
2024-05-27 20:48:31,981 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:48:31,981 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:49:33,042 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.56, generation: 61.0531[sec], evaluation: 0.0000[sec]
2024-05-27 20:49:33,044 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:49:33,175 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/31000.ckpt
2024-05-27 20:49:33,181 - INFO - joeynmt.training - Example #0
2024-05-27 20:49:33,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:49:33,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:49:33,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'ice', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'the', 'U.S.', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'tro@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:49:33,181 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:49:33,181 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:49:33,181 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides slides to show that the arctic ice ice ice to show that the arctic ice ice , which for almost three million years had the size of 48 United States continental , the U.S. continental , it &apos;s retroit of 40 percent .
2024-05-27 20:49:33,181 - INFO - joeynmt.training - Example #1
2024-05-27 20:49:33,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:49:33,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:49:33,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'sub@@', 'j@@', 'ected', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'ex@@', 'hi@@', 'b@@', 'ition', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:49:33,181 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:49:33,181 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:49:33,182 - INFO - joeynmt.training - 	Hypothesis: However this subjected the gravity of the problem because it doesn &apos;t exhibition of the ice .
2024-05-27 20:49:33,182 - INFO - joeynmt.training - Example #2
2024-05-27 20:49:33,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:49:33,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:49:33,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'f@@', 'ear@@', 'th', 'of', 'climate', 'system', '.', '</s>']
2024-05-27 20:49:33,182 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:49:33,182 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:49:33,182 - INFO - joeynmt.training - 	Hypothesis: The arctic ice is , in a certain sense , the fearth of climate system .
2024-05-27 20:49:33,182 - INFO - joeynmt.training - Example #3
2024-05-27 20:49:33,182 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:49:33,182 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:49:33,182 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 're@@', 'ver@@', 'se', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 20:49:33,182 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:49:33,186 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:49:33,186 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and reverse retreat .
2024-05-27 20:49:33,186 - INFO - joeynmt.training - Example #4
2024-05-27 20:49:33,186 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:49:33,186 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:49:33,186 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'id', 'car@@', 'l@@', 'ated', 're@@', 'ach@@', 'ing', 'for', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:49:33,186 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:49:33,186 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:49:33,186 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a reid carlated reaching for the last 25 years .
2024-05-27 20:50:05,470 - INFO - joeynmt.training - Epoch   9, Step:    33600, Batch Loss:     1.351867, Batch Acc: 0.619774, Tokens per Sec:     2192, Lr: 0.000300
2024-05-27 20:50:32,260 - INFO - joeynmt.training - Epoch   9, Step:    33700, Batch Loss:     1.307825, Batch Acc: 0.615603, Tokens per Sec:     2616, Lr: 0.000300
2024-05-27 20:50:57,734 - INFO - joeynmt.training - Epoch   9, Step:    33800, Batch Loss:     1.384248, Batch Acc: 0.619073, Tokens per Sec:     2759, Lr: 0.000300
2024-05-27 20:51:22,449 - INFO - joeynmt.training - Epoch   9, Step:    33900, Batch Loss:     1.395426, Batch Acc: 0.620780, Tokens per Sec:     2784, Lr: 0.000300
2024-05-27 20:51:48,719 - INFO - joeynmt.training - Epoch   9, Step:    34000, Batch Loss:     1.395307, Batch Acc: 0.620190, Tokens per Sec:     2673, Lr: 0.000300
2024-05-27 20:51:48,719 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:51:48,719 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:52:46,923 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.14, acc:   0.56, generation: 58.1959[sec], evaluation: 0.0000[sec]
2024-05-27 20:52:46,925 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 20:52:47,053 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/30500.ckpt
2024-05-27 20:52:47,058 - INFO - joeynmt.training - Example #0
2024-05-27 20:52:47,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:52:47,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:52:47,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'prove', 'that', 'the', 'ar@@', 'c@@', 'tic', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'size', 'of', '4@@', '8', 'United', 'States', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to prove that the arctic calculus , which for almost three million years had the size of 48 , the size of 48 United States continental , it &apos;s retrofit of 40 percent .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - Example #1
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ur@@', 'bia', 'this', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ac@@', 'es', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Hypothesis: But this suburbia this underlying the gravity of the problem because it doesn &apos;t show the spaces of the ice .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - Example #2
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'way', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Hypothesis: The arctic ice ice ice ice is , in a way , the clean heart of global climate system .
2024-05-27 20:52:47,059 - INFO - joeynmt.training - Example #3
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:52:47,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'be', 're@@', 'ver@@', 'se', 'and', 'sum@@', 'mer', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 20:52:47,059 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:52:47,060 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:52:47,060 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to be reverse and summer retreat .
2024-05-27 20:52:47,060 - INFO - joeynmt.training - Example #4
2024-05-27 20:52:47,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:52:47,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:52:47,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 'car@@', 'l@@', 'ying', 'on', 'on', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:52:47,060 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:52:47,060 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:52:47,060 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a carrelated carlying on on the last 25 years .
2024-05-27 20:53:12,371 - INFO - joeynmt.training - Epoch   9, Step:    34100, Batch Loss:     1.433522, Batch Acc: 0.617753, Tokens per Sec:     2694, Lr: 0.000300
2024-05-27 20:53:39,425 - INFO - joeynmt.training - Epoch   9, Step:    34200, Batch Loss:     1.384101, Batch Acc: 0.622113, Tokens per Sec:     2620, Lr: 0.000300
2024-05-27 20:54:06,523 - INFO - joeynmt.training - Epoch   9, Step:    34300, Batch Loss:     1.332000, Batch Acc: 0.623287, Tokens per Sec:     2682, Lr: 0.000300
2024-05-27 20:54:33,620 - INFO - joeynmt.training - Epoch   9, Step:    34400, Batch Loss:     1.547843, Batch Acc: 0.619654, Tokens per Sec:     2640, Lr: 0.000300
2024-05-27 20:55:01,692 - INFO - joeynmt.training - Epoch   9, Step:    34500, Batch Loss:     1.331748, Batch Acc: 0.620868, Tokens per Sec:     2471, Lr: 0.000300
2024-05-27 20:55:01,693 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:55:01,693 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:55:57,640 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.56, generation: 55.9401[sec], evaluation: 0.0000[sec]
2024-05-27 20:55:57,765 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/32500.ckpt
2024-05-27 20:55:57,768 - INFO - joeynmt.training - Example #0
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'tic', 'ice', 'ice', 'ice', 'ice', ',', 'which', 'is', 'about', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', ',', 'the', 'contin@@', 'ent', ',', 'has', 'been', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 20:55:57,769 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:55:57,769 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:55:57,769 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the artic ice ice ice ice , which is about three million years had the size of 48 , the United States of 48 , the continent , has been retrofit of 40 percent .
2024-05-27 20:55:57,769 - INFO - joeynmt.training - Example #1
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'the', 'ice', 'of', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 20:55:57,769 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:55:57,769 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:55:57,769 - INFO - joeynmt.training - 	Hypothesis: However this underlying gravity of the problem because it &apos;s not the ice of the ice of ice .
2024-05-27 20:55:57,769 - INFO - joeynmt.training - Example #2
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:55:57,769 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'ice', 'ice', 'is', ',', 'in', 'a', 'certain', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Hypothesis: The glacial ice ice is , in a certain sense , the clean heart of global climate system .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - Example #3
2024-05-27 20:55:57,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:55:57,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:55:57,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'and', 're@@', 'ver@@', 'se', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Hypothesis: It expanded up and reverse retreat .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - Example #4
2024-05-27 20:55:57,770 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:55:57,770 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:55:57,770 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'few', 'sli@@', 'des', 'will', 'be', 'a', 'car@@', 'rel@@', 'ated', ',', 'which', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 'car@@', 'ried', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:55:57,770 - INFO - joeynmt.training - 	Hypothesis: The next few slides will be a carrelated , which is going to be a carrelated carried in the last 25 years .
2024-05-27 20:56:24,764 - INFO - joeynmt.training - Epoch   9, Step:    34600, Batch Loss:     1.464518, Batch Acc: 0.619803, Tokens per Sec:     2588, Lr: 0.000300
2024-05-27 20:56:52,052 - INFO - joeynmt.training - Epoch   9, Step:    34700, Batch Loss:     1.365932, Batch Acc: 0.614031, Tokens per Sec:     2488, Lr: 0.000300
2024-05-27 20:57:19,812 - INFO - joeynmt.training - Epoch   9, Step:    34800, Batch Loss:     1.397282, Batch Acc: 0.620148, Tokens per Sec:     2623, Lr: 0.000300
2024-05-27 20:57:39,489 - INFO - joeynmt.training - Epoch   9: total training loss 5218.18
2024-05-27 20:57:39,490 - INFO - joeynmt.training - EPOCH 10
2024-05-27 20:57:46,892 - INFO - joeynmt.training - Epoch  10, Step:    34900, Batch Loss:     1.165253, Batch Acc: 0.644244, Tokens per Sec:     2428, Lr: 0.000300
2024-05-27 20:58:13,693 - INFO - joeynmt.training - Epoch  10, Step:    35000, Batch Loss:     1.168478, Batch Acc: 0.644077, Tokens per Sec:     2621, Lr: 0.000300
2024-05-27 20:58:13,694 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 20:58:13,694 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 20:59:05,036 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.17, acc:   0.56, generation: 51.3340[sec], evaluation: 0.0000[sec]
2024-05-27 20:59:05,169 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/30000.ckpt
2024-05-27 20:59:05,173 - INFO - joeynmt.training - Example #0
2024-05-27 20:59:05,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 20:59:05,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 20:59:05,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'ice', 'ice', 'ice', 'ice', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'ac@@', 'tual', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'contin@@', 'ent', ',', 'is', 're@@', 'tro@@', 'f@@', 'its', '.', '</s>']
2024-05-27 20:59:05,173 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 20:59:05,173 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 20:59:05,173 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to show that the glacial ice ice ice ice to show that the glacial actual calculus , which for almost three million years had the size of the 48 continent , is retrofits .
2024-05-27 20:59:05,173 - INFO - joeynmt.training - Example #1
2024-05-27 20:59:05,173 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 20:59:05,173 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 20:59:05,173 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'ex@@', 'hi@@', 'b@@', 'ition', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Hypothesis: But this underlying the gravity of the problem because it &apos;s not exhibition of the ice .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - Example #2
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Hypothesis: The arctic ice ice is , in a sense , the heart of the global climate system .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - Example #3
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'got', 'to', 'the', 'win@@', 'ter', 'and', 're@@', 'ver@@', 'se', 're@@', 'tre@@', 'ated', '.', '</s>']
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Hypothesis: It &apos;s got to the winter and reverse retreated .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - Example #4
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 20:59:05,174 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'ven@@', 'ues', 'for', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 20:59:05,174 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable revenues for the last 25 years .
2024-05-27 20:59:29,867 - INFO - joeynmt.training - Epoch  10, Step:    35100, Batch Loss:     1.276471, Batch Acc: 0.645895, Tokens per Sec:     2879, Lr: 0.000300
2024-05-27 20:59:53,956 - INFO - joeynmt.training - Epoch  10, Step:    35200, Batch Loss:     1.343551, Batch Acc: 0.646921, Tokens per Sec:     2870, Lr: 0.000300
2024-05-27 21:00:16,338 - INFO - joeynmt.training - Epoch  10, Step:    35300, Batch Loss:     1.462336, Batch Acc: 0.638354, Tokens per Sec:     3094, Lr: 0.000300
2024-05-27 21:00:38,931 - INFO - joeynmt.training - Epoch  10, Step:    35400, Batch Loss:     1.302856, Batch Acc: 0.646125, Tokens per Sec:     3201, Lr: 0.000300
2024-05-27 21:01:01,490 - INFO - joeynmt.training - Epoch  10, Step:    35500, Batch Loss:     1.112114, Batch Acc: 0.642484, Tokens per Sec:     3162, Lr: 0.000300
2024-05-27 21:01:01,490 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:01:01,490 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:01:49,320 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.20, acc:   0.56, generation: 47.8233[sec], evaluation: 0.0000[sec]
2024-05-27 21:01:49,322 - INFO - joeynmt.training - Example #0
2024-05-27 21:01:49,322 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 21:01:49,322 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 21:01:49,322 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'prove', 'that', 'the', 'gl@@', 'aci@@', 'al', 'hy@@', 'th@@', 'ic', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'has', '4@@', '8', 'size', ',', 'has', 're@@', 'tro@@', 'f@@', 'ed', 'the', 'size', 'of', '4@@', '8', '.', '</s>']
2024-05-27 21:01:49,322 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to prove that the glacial hythic calculus , which for almost three million years had the size of 48 , the United States has 48 size , has retrofed the size of 48 .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - Example #1
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'ground', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Hypothesis: However this underground gravity of the problem because it &apos;s not showing the ice of the ice of the ice of the ice .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - Example #2
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Hypothesis: The glacial ice is , in a sense , the heart of the global climate system .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - Example #3
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 21:01:49,323 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'got', 'to', 'win@@', 'ter', 'and', 're@@', 'ver@@', 'se', 're@@', 'tre@@', 'ated', '.', '</s>']
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - 	Hypothesis: It &apos;s got to winter and reverse retreated .
2024-05-27 21:01:49,323 - INFO - joeynmt.training - Example #4
2024-05-27 21:01:49,324 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 21:01:49,324 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 21:01:49,324 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'r@@', 'ates', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 21:01:49,324 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 21:01:49,324 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 21:01:49,324 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable remarkable rates in the last 25 years .
2024-05-27 21:02:12,922 - INFO - joeynmt.training - Epoch  10, Step:    35600, Batch Loss:     1.227567, Batch Acc: 0.638437, Tokens per Sec:     3085, Lr: 0.000300
2024-05-27 21:02:36,383 - INFO - joeynmt.training - Epoch  10, Step:    35700, Batch Loss:     1.171157, Batch Acc: 0.636908, Tokens per Sec:     3070, Lr: 0.000300
2024-05-27 21:02:59,372 - INFO - joeynmt.training - Epoch  10, Step:    35800, Batch Loss:     1.265190, Batch Acc: 0.637004, Tokens per Sec:     2938, Lr: 0.000300
2024-05-27 21:03:21,528 - INFO - joeynmt.training - Epoch  10, Step:    35900, Batch Loss:     1.205763, Batch Acc: 0.633431, Tokens per Sec:     3176, Lr: 0.000300
2024-05-27 21:03:43,643 - INFO - joeynmt.training - Epoch  10, Step:    36000, Batch Loss:     1.355511, Batch Acc: 0.630190, Tokens per Sec:     3179, Lr: 0.000300
2024-05-27 21:03:43,644 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:03:43,644 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:04:35,393 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.19, acc:   0.56, generation: 51.7426[sec], evaluation: 0.0000[sec]
2024-05-27 21:04:35,395 - INFO - joeynmt.training - Example #0
2024-05-27 21:04:35,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 21:04:35,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 21:04:35,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'you', 'that', 'the', 'ar@@', 't@@', 'ica', 'of', 'the', 'ar@@', 't@@', 'ica', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'United', 'States', ',', 're@@', 'ach@@', 'es', '.', '</s>']
2024-05-27 21:04:35,395 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 21:04:35,395 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 21:04:35,395 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show you that the artica of the artica , which for almost three million years had the size of 48 , the United States of 48 continental United States , reaches .
2024-05-27 21:04:35,395 - INFO - joeynmt.training - Example #1
2024-05-27 21:04:35,395 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 21:04:35,395 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 21:04:35,395 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Hypothesis: But this underlying gravity of the problem because it doesn &apos;t show the ice ice of ice .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - Example #2
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'way', ',', 'the', 'heart', 'b@@', 'utt@@', 'on@@', '-@@', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Hypothesis: The glacial calculus is , in a way , the heart button-heart of global climate system .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - Example #3
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'up', 'and', 're@@', 'ver@@', 'se', 're@@', 'ver@@', 'se', '.', '</s>']
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Hypothesis: It expanded up and reverse reverse .
2024-05-27 21:04:35,396 - INFO - joeynmt.training - Example #4
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 21:04:35,396 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 're@@', '-@@', 'rel@@', 'ated', 'rap@@', 'id', 'to', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 21:04:35,396 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 21:04:35,397 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 21:04:35,397 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrelated re-related rapid to the last 25 years .
2024-05-27 21:04:56,785 - INFO - joeynmt.training - Epoch  10, Step:    36100, Batch Loss:     1.327555, Batch Acc: 0.635249, Tokens per Sec:     3310, Lr: 0.000300
2024-05-27 21:05:18,910 - INFO - joeynmt.training - Epoch  10, Step:    36200, Batch Loss:     1.285107, Batch Acc: 0.640757, Tokens per Sec:     3233, Lr: 0.000300
2024-05-27 21:05:40,863 - INFO - joeynmt.training - Epoch  10, Step:    36300, Batch Loss:     1.332543, Batch Acc: 0.630327, Tokens per Sec:     3266, Lr: 0.000300
2024-05-27 21:06:03,183 - INFO - joeynmt.training - Epoch  10, Step:    36400, Batch Loss:     1.214921, Batch Acc: 0.637769, Tokens per Sec:     3313, Lr: 0.000300
2024-05-27 21:06:26,716 - INFO - joeynmt.training - Epoch  10, Step:    36500, Batch Loss:     1.154199, Batch Acc: 0.635327, Tokens per Sec:     3093, Lr: 0.000300
2024-05-27 21:06:26,716 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:06:26,716 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:07:20,112 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.14, acc:   0.56, generation: 53.3894[sec], evaluation: 0.0000[sec]
2024-05-27 21:07:20,239 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/35000.ckpt
2024-05-27 21:07:20,243 - INFO - joeynmt.helpers - delete /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/35000.ckpt
2024-05-27 21:07:20,243 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/35000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/35000.ckpt')
2024-05-27 21:07:20,243 - INFO - joeynmt.training - Example #0
2024-05-27 21:07:20,243 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 21:07:20,243 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 21:07:20,243 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'ice', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', 'contin@@', 'ent', ',', 'the', 'size', 'of', 'the', 'United', 'States', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'United', 'States', '.', '</s>']
2024-05-27 21:07:20,243 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arctic ice ice ice , which for almost three million years had the size of the 48 United States continent , the size of the United States of 48 continental United States .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - Example #1
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', 'under@@', 'ne@@', 'ath', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Hypothesis: But that underneath the gravity of the problem because it doesn &apos;t show the ice of ice .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - Example #2
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cle@@', 'an', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Hypothesis: The arctic ice ice ice ice is , in a sense , the clean heart of global climate system .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - Example #3
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 21:07:20,244 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'by', 'win@@', 'ter', 'and', 'sum@@', 'mer', '.', '</s>']
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded by winter and summer .
2024-05-27 21:07:20,244 - INFO - joeynmt.training - Example #4
2024-05-27 21:07:20,245 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 21:07:20,245 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 21:07:20,245 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ate', 're@@', 'ven@@', 'ement', ',', 'the', 'next', '25', 'years', '.', '</s>']
2024-05-27 21:07:20,245 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 21:07:20,245 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 21:07:20,245 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carlate revenement , the next 25 years .
2024-05-27 21:07:43,173 - INFO - joeynmt.training - Epoch  10, Step:    36600, Batch Loss:     1.220535, Batch Acc: 0.634920, Tokens per Sec:     3012, Lr: 0.000300
2024-05-27 21:08:05,334 - INFO - joeynmt.training - Epoch  10, Step:    36700, Batch Loss:     1.150530, Batch Acc: 0.629848, Tokens per Sec:     3162, Lr: 0.000300
2024-05-27 21:08:28,777 - INFO - joeynmt.training - Epoch  10, Step:    36800, Batch Loss:     1.267844, Batch Acc: 0.634052, Tokens per Sec:     3018, Lr: 0.000300
2024-05-27 21:08:52,380 - INFO - joeynmt.training - Epoch  10, Step:    36900, Batch Loss:     1.254179, Batch Acc: 0.634504, Tokens per Sec:     2922, Lr: 0.000300
2024-05-27 21:09:14,559 - INFO - joeynmt.training - Epoch  10, Step:    37000, Batch Loss:     1.381296, Batch Acc: 0.630506, Tokens per Sec:     3234, Lr: 0.000300
2024-05-27 21:09:14,560 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:09:14,560 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:10:07,261 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.16, acc:   0.56, generation: 52.6949[sec], evaluation: 0.0000[sec]
2024-05-27 21:10:07,381 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/33000.ckpt
2024-05-27 21:10:07,385 - INFO - joeynmt.training - Example #0
2024-05-27 21:10:07,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 21:10:07,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 21:10:07,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'showed', 'these', 'sli@@', 'des', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', ',', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', ',', 'it', '&apos;s', 're@@', 'qui@@', 'red', 'over', '40', 'percent', '.', '</s>']
2024-05-27 21:10:07,385 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 21:10:07,385 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 21:10:07,385 - INFO - joeynmt.training - 	Hypothesis: Last year showed these slides slides to demonstrate that the arctic calculus , which for almost three million years had the size of the 48 United States , the size of 48 , the United States , it &apos;s required over 40 percent .
2024-05-27 21:10:07,385 - INFO - joeynmt.training - Example #1
2024-05-27 21:10:07,385 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 21:10:07,385 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 21:10:07,385 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'that', 'under@@', 'water', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'about', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Hypothesis: But that underwater gravity of the problem because it &apos;s not about the ice of the ice of the ice .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - Example #2
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'is', ',', 'in', 'a', 'way', ',', 'the', 'gl@@', 'aci@@', 'al', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Hypothesis: The arctic ice ice is , in a way , the glacial heart of global climate system .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - Example #3
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'got', 'win@@', 'ter', 'and', 'you', 're@@', 'ver@@', 'se', 're@@', 'qui@@', 'red', '.', '</s>']
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - 	Hypothesis: It &apos;s got winter and you reverse required .
2024-05-27 21:10:07,386 - INFO - joeynmt.training - Example #4
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 21:10:07,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'ven@@', 'ue', 'rap@@', 'id', 'about', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 21:10:07,387 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 21:10:07,387 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 21:10:07,387 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying revenue rapid about the last 25 years .
2024-05-27 21:10:28,950 - INFO - joeynmt.training - Epoch  10, Step:    37100, Batch Loss:     1.256596, Batch Acc: 0.635111, Tokens per Sec:     3309, Lr: 0.000300
2024-05-27 21:10:50,566 - INFO - joeynmt.training - Epoch  10, Step:    37200, Batch Loss:     1.453632, Batch Acc: 0.629403, Tokens per Sec:     3254, Lr: 0.000300
2024-05-27 21:11:12,781 - INFO - joeynmt.training - Epoch  10, Step:    37300, Batch Loss:     1.461781, Batch Acc: 0.625032, Tokens per Sec:     3215, Lr: 0.000300
2024-05-27 21:11:34,932 - INFO - joeynmt.training - Epoch  10, Step:    37400, Batch Loss:     1.166615, Batch Acc: 0.633859, Tokens per Sec:     3200, Lr: 0.000300
2024-05-27 21:11:56,743 - INFO - joeynmt.training - Epoch  10, Step:    37500, Batch Loss:     1.376363, Batch Acc: 0.629407, Tokens per Sec:     3350, Lr: 0.000300
2024-05-27 21:11:56,744 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:11:56,744 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:12:50,531 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.15, acc:   0.56, generation: 53.7804[sec], evaluation: 0.0000[sec]
2024-05-27 21:12:50,652 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/37000.ckpt
2024-05-27 21:12:50,655 - INFO - joeynmt.helpers - delete /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/37000.ckpt
2024-05-27 21:12:50,655 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/37000.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/37000.ckpt')
2024-05-27 21:12:50,656 - INFO - joeynmt.training - Example #0
2024-05-27 21:12:50,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 21:12:50,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 21:12:50,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'ated', ',', 'which', 'for', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', '4@@', '8', 'United', 'States', ',', 'the', 'contin@@', 'ent@@', 'al', 'size', ',', 'it', '&apos;s', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 21:12:50,656 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 21:12:50,656 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 21:12:50,656 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to demonstrate that the glacial calculated , which for almost three million years had the size of 48 United States , the continental size , it &apos;s retrofit of 40 percent .
2024-05-27 21:12:50,656 - INFO - joeynmt.training - Example #1
2024-05-27 21:12:50,656 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 21:12:50,656 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 21:12:50,656 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'l@@', 'ying', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Hypothesis: But this underlying the gravity of the problem because it &apos;s not showing the ice of the ice of the ice .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - Example #2
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'gl@@', 'aci@@', 'al', 'heart', 'of', 'global', 'climate', '.', '</s>']
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Hypothesis: The arctic ice ice ice ice ice ice is , in a sense , the glacial heart of global climate .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - Example #3
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 're@@', 'ver@@', 'se', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and reverse retreat .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - Example #4
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 21:12:50,657 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'ven@@', 'ess', ',', 'which', 'is', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 21:12:50,657 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying reveness , which is the last 25 years .
2024-05-27 21:13:12,884 - INFO - joeynmt.training - Epoch  10, Step:    37600, Batch Loss:     1.480727, Batch Acc: 0.629715, Tokens per Sec:     3126, Lr: 0.000300
2024-05-27 21:13:34,386 - INFO - joeynmt.training - Epoch  10, Step:    37700, Batch Loss:     1.330267, Batch Acc: 0.630106, Tokens per Sec:     3341, Lr: 0.000300
2024-05-27 21:13:57,955 - INFO - joeynmt.training - Epoch  10, Step:    37800, Batch Loss:     1.239769, Batch Acc: 0.628473, Tokens per Sec:     3090, Lr: 0.000300
2024-05-27 21:14:21,458 - INFO - joeynmt.training - Epoch  10, Step:    37900, Batch Loss:     1.284302, Batch Acc: 0.625906, Tokens per Sec:     2947, Lr: 0.000300
2024-05-27 21:14:46,017 - INFO - joeynmt.training - Epoch  10, Step:    38000, Batch Loss:     1.392895, Batch Acc: 0.625431, Tokens per Sec:     2879, Lr: 0.000300
2024-05-27 21:14:46,017 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:14:46,017 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:15:31,165 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.13, acc:   0.56, generation: 45.1417[sec], evaluation: 0.0000[sec]
2024-05-27 21:15:31,167 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 21:15:31,283 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/34500.ckpt
2024-05-27 21:15:31,287 - INFO - joeynmt.training - Example #0
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'ice', ',', 'which', 'is', 'almost', 'three', 'million', 'years', 'had', 'the', 'size', 'of', 'the', '4@@', '8', 'United', 'States', ',', 'the', '4@@', '8', 'United', 'States', ',', 'has', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 21:15:31,287 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 21:15:31,287 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 21:15:31,287 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arctic ice ice ice , which is almost three million years had the size of the 48 United States , the 48 United States , has retrofit of 40 percent .
2024-05-27 21:15:31,287 - INFO - joeynmt.training - Example #1
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'ow@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'ice', 'ice', 'ice', 'ice', '.', '</s>']
2024-05-27 21:15:31,287 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 21:15:31,287 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 21:15:31,287 - INFO - joeynmt.training - 	Hypothesis: However this underlying gravity of the problem because it &apos;s not showing the ice ice ice ice ice .
2024-05-27 21:15:31,287 - INFO - joeynmt.training - Example #2
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 21:15:31,287 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ice', 'ice', 'ice', 'ice', 'ice', 'is', ',', 'in', 'a', 'way', ',', 'the', 'heart', 'of', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Hypothesis: The arctic ice ice ice ice ice ice is , in a way , the heart of global climate system .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - Example #3
2024-05-27 21:15:31,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 21:15:31,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 21:15:31,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'got', 'win@@', 'ter', 'and', 're@@', 'ver@@', 'se', 're@@', 'tre@@', 'at', '.', '</s>']
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Hypothesis: It &apos;s got winter and reverse retreat .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - Example #4
2024-05-27 21:15:31,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 21:15:31,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 21:15:31,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'l@@', 'ying', 're@@', 'mark@@', 'able', ',', 'in', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 21:15:31,288 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carlying remarkable , in the last 25 years .
2024-05-27 21:15:53,368 - INFO - joeynmt.training - Epoch  10, Step:    38100, Batch Loss:     1.274954, Batch Acc: 0.629236, Tokens per Sec:     3263, Lr: 0.000300
2024-05-27 21:16:17,044 - INFO - joeynmt.training - Epoch  10, Step:    38200, Batch Loss:     1.209191, Batch Acc: 0.625180, Tokens per Sec:     2929, Lr: 0.000300
2024-05-27 21:16:39,157 - INFO - joeynmt.training - Epoch  10, Step:    38300, Batch Loss:     1.178252, Batch Acc: 0.626687, Tokens per Sec:     3090, Lr: 0.000300
2024-05-27 21:17:01,014 - INFO - joeynmt.training - Epoch  10, Step:    38400, Batch Loss:     1.467271, Batch Acc: 0.624514, Tokens per Sec:     3202, Lr: 0.000300
2024-05-27 21:17:22,527 - INFO - joeynmt.training - Epoch  10, Step:    38500, Batch Loss:     1.358979, Batch Acc: 0.628969, Tokens per Sec:     3284, Lr: 0.000300
2024-05-27 21:17:22,528 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:17:22,528 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:18:11,308 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.10, acc:   0.56, generation: 48.7739[sec], evaluation: 0.0000[sec]
2024-05-27 21:18:11,310 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 21:18:11,432 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe5000/33500.ckpt
2024-05-27 21:18:11,436 - INFO - joeynmt.training - Example #0
2024-05-27 21:18:11,436 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'scorso', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'itive', 'per', 'dimostr@@', 'are', 'che', 'la', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'quasi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimensioni', 'dei', '4@@', '8', 'Stati', 'Uniti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '40', '%', '.']
2024-05-27 21:18:11,436 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'two', 'sli@@', 'des', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'size', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'run@@', 'k', 'by', '40', 'percent', '.']
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'showed', 'these', 'sli@@', 'des', 'to', 'show', 'that', 'the', 'gl@@', 'aci@@', 'al', 'calc@@', 'ul@@', 'us', ',', 'which', 'for', 'almost', 'three', 'million', 'years', ',', 'had', 'the', 'size', 'of', '4@@', '8', ',', 'the', 'United', 'States', 'has', '4@@', '8', 'size', ',', 'the', 'United', 'States', 'has', 're@@', 'tro@@', 'f@@', 'it', 'of', '40', 'percent', '.', '</s>']
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the glacial calculus , which for almost three million years , had the size of 48 , the United States has 48 size , the United States has retrofit of 40 percent .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - Example #1
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 'sott@@', 'ov@@', 'al@@', 'uta', 'la', 'grav@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostra', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'ghiaccio', '.']
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'seri@@', 'ous@@', 'ness', 'of', 'this', 'particular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ick@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 't@@', 'le', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'shows', 'it', '&apos;s', 'not', 'the', 'ice', 'sp@@', 'ex@@', 'ten@@', 'se', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'the', 'ice', 'sp@@', 'ex@@', 'ec@@', 'ti@@', 'vely', 'because', 'it', '&apos;s', 'not', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'the', 'ex@@', 'pan@@', 'ded', 'of', 'the', 'ice', ',', 'because', 'it', '&apos;s', 'not', 'showing', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'problem', 'because', 'it', 'shows', 'the', 'grav@@', 'ity', 'of', 'the', 'problem', 'because']
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Hypothesis: But this subtle the gravity of the problem because it shows it &apos;s not the ice spextense of the ice of the ice of the problem because it &apos;s not the ice spexectively because it &apos;s not the ice of the ice of the problem because it &apos;s not the expanded of the ice , because it &apos;s not showing the ice of the ice of the problem because it shows the gravity of the problem because
2024-05-27 21:18:11,437 - INFO - joeynmt.training - Example #2
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'otta', 'gl@@', 'aci@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cuore', 'pul@@', 's@@', 'ante', 'del', 'sistema', 'climat@@', 'ico', 'globale', '.']
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'tic', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'heart', 'of', 'the', 'global', 'climate', 'system', '.']
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'tic', 'calc@@', 'ul@@', 'us', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'heart', 'of', 'the', 'global', 'climate', 'system', '.', '</s>']
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - 	Hypothesis: The arctic calculus is , in a sense , the heart of the global climate system .
2024-05-27 21:18:11,437 - INFO - joeynmt.training - Example #3
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'exp@@', 'ands', 'in', 'win@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'mer', '.']
2024-05-27 21:18:11,437 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'in@@', 'ver@@', 'n', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 21:18:11,438 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 21:18:11,438 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 21:18:11,438 - INFO - joeynmt.training - 	Hypothesis: It &apos;s invern expanded .
2024-05-27 21:18:11,438 - INFO - joeynmt.training - Example #4
2024-05-27 21:18:11,438 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'sima', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'ida', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'imenti', 'degli', 'ultimi', '25', 'anni', '.']
2024-05-27 21:18:11,438 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 'slide', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'forward', 'of', 'what', '&apos;s', 'happened', 'over', 'the', 'last', '25', 'years', '.']
2024-05-27 21:18:11,438 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'slide', 'is', 'going', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'id', 'to', 'be', 'a', 'car@@', 'r@@', 'ying', 're@@', 'qui@@', 'red', 'of', 'the', 'last', '25', 'years', '.', '</s>']
2024-05-27 21:18:11,438 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 21:18:11,438 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 21:18:11,438 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a carrying reid to be a carrying required of the last 25 years .
2024-05-27 21:18:32,814 - INFO - joeynmt.training - Epoch  10, Step:    38600, Batch Loss:     1.269721, Batch Acc: 0.628188, Tokens per Sec:     3237, Lr: 0.000300
2024-05-27 21:18:56,151 - INFO - joeynmt.training - Epoch  10, Step:    38700, Batch Loss:     1.350323, Batch Acc: 0.621693, Tokens per Sec:     2984, Lr: 0.000300
2024-05-27 21:19:03,292 - INFO - joeynmt.training - Epoch  10: total training loss 5057.61
2024-05-27 21:19:03,292 - INFO - joeynmt.training - Training ended after  10 epochs.
2024-05-27 21:19:03,292 - INFO - joeynmt.training - Best validation result (greedy) at step    38500:   5.10 ppl.
2024-05-27 21:19:03,303 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-27 21:19:03,354 - INFO - joeynmt.model - Enc-dec model built.
2024-05-27 21:19:03,390 - INFO - joeynmt.helpers - Load model from /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/38500.ckpt.
2024-05-27 21:19:03,393 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=4988),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=4988),
	loss_function=None)
2024-05-27 21:19:03,395 - INFO - joeynmt.prediction - Decoding on dev set...
2024-05-27 21:19:03,395 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:19:03,395 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:19:56,934 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 53.5329[sec], evaluation: 0.0000[sec]
2024-05-27 21:19:56,935 - INFO - joeynmt.prediction - Translations saved to: /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/00038500.hyps.dev.
2024-05-27 21:19:56,935 - INFO - joeynmt.prediction - Decoding on test set...
2024-05-27 21:19:56,935 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 21:19:56,935 - INFO - joeynmt.prediction - Predicting 1566 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 21:21:12,178 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 75.2312[sec], evaluation: 0.0000[sec]
2024-05-27 21:21:12,181 - INFO - joeynmt.prediction - Translations saved to: /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe5000/00038500.hyps.test.
