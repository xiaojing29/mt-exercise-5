2024-05-27 13:39:16,372 - INFO - root - Hello! This is Joey-NMT (version 2.2.0).
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                           cfg.name : iten_transformer_bpe2000
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                cfg.joeynmt_version : 2.0.0
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                     cfg.data.train : data/preprocessed/train.sampled
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                       cfg.data.dev : data/preprocessed/valid
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                      cfg.data.test : data/preprocessed/test
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -              cfg.data.dataset_type : plain
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                  cfg.data.src.lang : it
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                 cfg.data.src.level : bpe
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -             cfg.data.src.lowercase : False
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -       cfg.data.src.max_sent_length : 100
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -              cfg.data.src.voc_file : data/bpe/vocab.2000
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -        cfg.data.src.tokenizer_type : subword-nmt
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -   cfg.data.src.tokenizer_cfg.codes : data/bpe/codes.2000
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                  cfg.data.trg.lang : en
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                 cfg.data.trg.level : bpe
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -             cfg.data.trg.lowercase : False
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -       cfg.data.trg.max_sent_length : 100
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -              cfg.data.trg.voc_file : data/bpe/vocab.2000
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -        cfg.data.trg.tokenizer_type : subword-nmt
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -   cfg.data.trg.tokenizer_cfg.codes : data/bpe/codes.2000
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -              cfg.testing.beam_size : 5
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -                  cfg.testing.alpha : 1.0
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -           cfg.training.random_seed : 42
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -             cfg.training.optimizer : adam
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -         cfg.training.normalization : tokens
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -         cfg.training.learning_rate : 0.0003
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -            cfg.training.batch_size : 2048
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -            cfg.training.batch_type : token
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -       cfg.training.eval_batch_size : 1024
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -       cfg.training.eval_batch_type : token
2024-05-27 13:39:16,372 - INFO - joeynmt.helpers -            cfg.training.scheduling : plateau
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -              cfg.training.patience : 8
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.training.weight_decay : 0.0
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -       cfg.training.decrease_factor : 0.7
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers - cfg.training.early_stopping_metric : ppl
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -                cfg.training.epochs : 10
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -       cfg.training.validation_freq : 500
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.training.logging_freq : 100
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -           cfg.training.eval_metric : bleu
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -             cfg.training.model_dir : models/iten_transformer_bpe2000
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -             cfg.training.overwrite : False
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -               cfg.training.shuffle : True
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -              cfg.training.use_cuda : False
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -     cfg.training.max_output_length : 100
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -     cfg.training.print_valid_sents : [0, 1, 2, 3, 4]
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -       cfg.training.label_smoothing : 0.3
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -              cfg.model.initializer : xavier_uniform
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -         cfg.model.bias_initializer : zeros
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -                cfg.model.init_gain : 1.0
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -        cfg.model.embed_initializer : xavier_uniform
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.model.embed_init_gain : 1.0
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.model.tied_embeddings : True
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -             cfg.model.tied_softmax : True
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -             cfg.model.encoder.type : transformer
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -       cfg.model.encoder.num_layers : 4
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -        cfg.model.encoder.num_heads : 2
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.embedding_dim : 256
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.scale : True
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers - cfg.model.encoder.embeddings.dropout : 0
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -      cfg.model.encoder.hidden_size : 256
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.model.encoder.ff_size : 512
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.model.encoder.dropout : 0
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -             cfg.model.decoder.type : transformer
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -       cfg.model.decoder.num_layers : 1
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -        cfg.model.decoder.num_heads : 2
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.embedding_dim : 256
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.scale : True
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers - cfg.model.decoder.embeddings.dropout : 0
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -      cfg.model.decoder.hidden_size : 256
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.model.decoder.ff_size : 512
2024-05-27 13:39:16,373 - INFO - joeynmt.helpers -          cfg.model.decoder.dropout : 0
2024-05-27 13:39:16,375 - INFO - joeynmt.data - Building tokenizer...
2024-05-27 13:39:16,378 - INFO - joeynmt.tokenizers - it tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-27 13:39:16,378 - INFO - joeynmt.tokenizers - en tokenizer: SubwordNMTTokenizer(level=bpe, lowercase=False, normalize=False, filter_by_length=(-1, -1), pretokenizer=none, tokenizer=BPE, separator=@@, dropout=0.0)
2024-05-27 13:39:16,378 - INFO - joeynmt.data - Loading train set...
2024-05-27 13:39:16,478 - INFO - joeynmt.data - Building vocabulary...
2024-05-27 13:39:16,507 - INFO - joeynmt.data - Loading dev set...
2024-05-27 13:39:16,508 - INFO - joeynmt.data - Loading test set...
2024-05-27 13:39:16,510 - INFO - joeynmt.data - Data loaded.
2024-05-27 13:39:16,510 - INFO - joeynmt.data - Train dataset: PlaintextDataset(split=train, len=100000, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-27 13:39:16,510 - INFO - joeynmt.data - Valid dataset: PlaintextDataset(split=dev, len=929, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-27 13:39:16,510 - INFO - joeynmt.data -  Test dataset: PlaintextDataset(split=test, len=1566, src_lang=it, trg_lang=en, has_trg=True, random_subset=-1)
2024-05-27 13:39:16,510 - INFO - joeynmt.data - First training example:
	[SRC] A@@ l G@@ ore : ar@@ res@@ ti@@ amo il ri@@ sc@@ al@@ d@@ amento glob@@ ale
	[TRG] A@@ l G@@ ore : A@@ ver@@ ting the c@@ lim@@ ate c@@ ris@@ is
2024-05-27 13:39:16,510 - INFO - joeynmt.data - First 10 Src tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) a (7) the (8) to (9) di
2024-05-27 13:39:16,510 - INFO - joeynmt.data - First 10 Trg tokens: (0) <unk> (1) <pad> (2) <s> (3) </s> (4) , (5) . (6) a (7) the (8) to (9) di
2024-05-27 13:39:16,510 - INFO - joeynmt.data - Number of unique Src tokens (vocab_size): 1994
2024-05-27 13:39:16,510 - INFO - joeynmt.data - Number of unique Trg tokens (vocab_size): 1994
2024-05-27 13:39:16,511 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-27 13:39:16,565 - INFO - joeynmt.model - Enc-dec model built.
2024-05-27 13:39:16,567 - INFO - joeynmt.model - Total params: 3409664
2024-05-27 13:39:16,567 - DEBUG - joeynmt.model - Trainable parameters: ['decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'src_embed.lut.weight']
2024-05-27 13:39:16,567 - INFO - joeynmt.training - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1994),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1994),
	loss_function=XentLoss(criterion=KLDivLoss(), smoothing=0.3))
2024-05-27 13:39:16,567 - INFO - joeynmt.builders - Adam(lr=0.0003, weight_decay=0.0, betas=(0.9, 0.999))
2024-05-27 13:39:16,567 - INFO - joeynmt.builders - ReduceLROnPlateau(mode=min, verbose=False, threshold_mode=abs, eps=0.0, factor=0.7, patience=8)
2024-05-27 13:39:16,567 - INFO - joeynmt.training - Train stats:
	device: cpu
	n_gpu: 0
	16-bits training: False
	gradient accumulation: 1
	batch size per device: 2048
	effective batch size (w. parallel & accumulation): 2048
2024-05-27 13:39:16,568 - INFO - joeynmt.training - EPOCH 1
2024-05-27 13:39:34,840 - INFO - joeynmt.training - Epoch   1, Step:      100, Batch Loss:     3.807422, Batch Acc: 0.058016, Tokens per Sec:     3986, Lr: 0.000300
2024-05-27 13:39:53,317 - INFO - joeynmt.training - Epoch   1, Step:      200, Batch Loss:     3.757983, Batch Acc: 0.090671, Tokens per Sec:     3887, Lr: 0.000300
2024-05-27 13:40:11,430 - INFO - joeynmt.training - Epoch   1, Step:      300, Batch Loss:     3.487931, Batch Acc: 0.104780, Tokens per Sec:     3958, Lr: 0.000300
2024-05-27 13:40:30,233 - INFO - joeynmt.training - Epoch   1, Step:      400, Batch Loss:     3.335844, Batch Acc: 0.121018, Tokens per Sec:     3777, Lr: 0.000300
2024-05-27 13:40:49,156 - INFO - joeynmt.training - Epoch   1, Step:      500, Batch Loss:     3.323219, Batch Acc: 0.131854, Tokens per Sec:     3834, Lr: 0.000300
2024-05-27 13:40:49,156 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:40:49,156 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 13:42:13,959 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.39, ppl:  29.59, acc:   0.13, generation: 84.7945[sec], evaluation: 0.0000[sec]
2024-05-27 13:42:13,960 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 13:42:14,088 - INFO - joeynmt.training - Example #0
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'we', 'have', 'the', 'world', ',', 'you', 'have', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', '.', '</s>']
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Hypothesis: And we have the world , you have the world , and the world , and the world , and the world , and the world , and the world , and the world , and the world .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - Example #1
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t', '&apos;t']
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Hypothesis: And I &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t &apos;t
2024-05-27 13:42:14,089 - INFO - joeynmt.training - Example #2
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 13:42:14,089 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'h@@', 's', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', 'the', 'c@@', 's', ',', 'the', 'world', '.', '</s>']
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - 	Hypothesis: The hs , the world , the world , the world , the world , the cs , the world .
2024-05-27 13:42:14,089 - INFO - joeynmt.training - Example #3
2024-05-27 13:42:14,090 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 13:42:14,090 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 13:42:14,090 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'you', 'can', 'be', 'the', 'c@@', 's', ',', 'you', 'do', 'you', 'do', 'you', 'do', '</s>']
2024-05-27 13:42:14,090 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 13:42:14,090 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 13:42:14,090 - INFO - joeynmt.training - 	Hypothesis: And you can be the cs , you do you do you do
2024-05-27 13:42:14,090 - INFO - joeynmt.training - Example #4
2024-05-27 13:42:14,090 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 13:42:14,090 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 13:42:14,090 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'h@@', 's', ',', 'you', '&apos;re', 'a', 'a', 'c@@', 's', ',', 'and', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'c@@', 's', '.', '</s>']
2024-05-27 13:42:14,090 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 13:42:14,090 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 13:42:14,090 - INFO - joeynmt.training - 	Hypothesis: The hs , you &apos;re a a cs , and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the cs .
2024-05-27 13:42:31,448 - INFO - joeynmt.training - Epoch   1, Step:      600, Batch Loss:     3.375846, Batch Acc: 0.142481, Tokens per Sec:     4217, Lr: 0.000300
2024-05-27 13:42:49,741 - INFO - joeynmt.training - Epoch   1, Step:      700, Batch Loss:     3.200138, Batch Acc: 0.146954, Tokens per Sec:     3994, Lr: 0.000300
2024-05-27 13:43:07,333 - INFO - joeynmt.training - Epoch   1, Step:      800, Batch Loss:     3.124040, Batch Acc: 0.156886, Tokens per Sec:     4091, Lr: 0.000300
2024-05-27 13:43:25,745 - INFO - joeynmt.training - Epoch   1, Step:      900, Batch Loss:     3.120913, Batch Acc: 0.161093, Tokens per Sec:     3881, Lr: 0.000300
2024-05-27 13:43:43,656 - INFO - joeynmt.training - Epoch   1, Step:     1000, Batch Loss:     2.979113, Batch Acc: 0.174138, Tokens per Sec:     4066, Lr: 0.000300
2024-05-27 13:43:43,658 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:43:43,658 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 13:45:25,297 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   3.14, ppl:  23.03, acc:   0.18, generation: 101.6245[sec], evaluation: 0.0000[sec]
2024-05-27 13:45:25,300 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 13:45:25,430 - INFO - joeynmt.training - Example #0
2024-05-27 13:45:25,430 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 13:45:25,430 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 13:45:25,430 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', '&apos;re', 'going', 'to', 'be', 'a', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'bit', 'of', 'the', 'world', '.', '</s>']
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Hypothesis: They &apos;re going to be a little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little little bit of the world .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - Example #1
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;m', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not', 'not']
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Hypothesis: I &apos;m not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not not
2024-05-27 13:45:25,431 - INFO - joeynmt.training - Example #2
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'f@@', 'f@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'ul@@', 'al', '.', '</s>']
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - 	Hypothesis: The ffululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululululal .
2024-05-27 13:45:25,431 - INFO - joeynmt.training - Example #3
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 13:45:25,431 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 13:45:25,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'little', 'bit', '.', '</s>']
2024-05-27 13:45:25,432 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 13:45:25,432 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 13:45:25,432 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a little little little little little little little little little little little little little bit .
2024-05-27 13:45:25,432 - INFO - joeynmt.training - Example #4
2024-05-27 13:45:25,432 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 13:45:25,432 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 13:45:25,432 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'h@@', 'h@@', 'h@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@', 'o@@']
2024-05-27 13:45:25,432 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 13:45:25,432 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 13:45:25,432 - INFO - joeynmt.training - 	Hypothesis: The hhhooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo
2024-05-27 13:45:43,994 - INFO - joeynmt.training - Epoch   1, Step:     1100, Batch Loss:     3.007322, Batch Acc: 0.192763, Tokens per Sec:     3901, Lr: 0.000300
2024-05-27 13:46:03,226 - INFO - joeynmt.training - Epoch   1, Step:     1200, Batch Loss:     2.866971, Batch Acc: 0.207609, Tokens per Sec:     3700, Lr: 0.000300
2024-05-27 13:46:20,511 - INFO - joeynmt.training - Epoch   1, Step:     1300, Batch Loss:     2.843267, Batch Acc: 0.220903, Tokens per Sec:     4253, Lr: 0.000300
2024-05-27 13:46:37,327 - INFO - joeynmt.training - Epoch   1, Step:     1400, Batch Loss:     2.858177, Batch Acc: 0.229029, Tokens per Sec:     4239, Lr: 0.000300
2024-05-27 13:46:54,202 - INFO - joeynmt.training - Epoch   1, Step:     1500, Batch Loss:     2.810993, Batch Acc: 0.238333, Tokens per Sec:     4399, Lr: 0.000300
2024-05-27 13:46:54,204 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:46:54,204 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 13:48:04,062 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.81, ppl:  16.69, acc:   0.23, generation: 69.8508[sec], evaluation: 0.0000[sec]
2024-05-27 13:48:04,064 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 13:48:04,168 - INFO - joeynmt.training - Example #0
2024-05-27 13:48:04,168 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 13:48:04,168 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 13:48:04,168 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', 'have', 'to', 'be', 'a', 'little', 'bit', 'of', 'the', 'world', ',', 'I', '&apos;ve', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been', 'been']
2024-05-27 13:48:04,168 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 13:48:04,168 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Hypothesis: They have to be a little bit of the world , I &apos;ve been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been been
2024-05-27 13:48:04,169 - INFO - joeynmt.training - Example #1
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'of', 'the', 'world', ',', 'I', '&apos;m', 'not', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', ',', 'and', 'the', 'world', '.', '</s>']
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Hypothesis: The first of the world , I &apos;m not the world , and the world , and the world , and the world , and the world .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - Example #2
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'other', 'other', 'other', ',', 'the', 'c@@', 'ar', 'is', ',', 'is', 'a', 'little', 'bit', 'of', 'the', 'c@@', 'ar', ',', 'is', 'a', 'lot', 'of', 'the', 'world', '.', '</s>']
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Hypothesis: The other other other , the car is , is a little bit of the car , is a lot of the world .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - Example #3
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'be', 'a', 'little', 'bit', 'of', 'the', 'b@@', 'est', '.', '</s>']
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - 	Hypothesis: You can be a little bit of the best .
2024-05-27 13:48:04,169 - INFO - joeynmt.training - Example #4
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 13:48:04,169 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'a', 'little', 'bit', 'of', 'the', 'world', ',', 'the', 'world', ',', 'the', 'world', ',', '</s>']
2024-05-27 13:48:04,170 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 13:48:04,170 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 13:48:04,170 - INFO - joeynmt.training - 	Hypothesis: The first of a little bit of a little bit of a little bit of the world , the world , the world ,
2024-05-27 13:48:20,317 - INFO - joeynmt.training - Epoch   1, Step:     1600, Batch Loss:     2.808348, Batch Acc: 0.245307, Tokens per Sec:     4510, Lr: 0.000300
2024-05-27 13:48:36,528 - INFO - joeynmt.training - Epoch   1, Step:     1700, Batch Loss:     2.701963, Batch Acc: 0.251845, Tokens per Sec:     4363, Lr: 0.000300
2024-05-27 13:48:52,679 - INFO - joeynmt.training - Epoch   1, Step:     1800, Batch Loss:     2.604743, Batch Acc: 0.258601, Tokens per Sec:     4435, Lr: 0.000300
2024-05-27 13:49:09,337 - INFO - joeynmt.training - Epoch   1, Step:     1900, Batch Loss:     2.538376, Batch Acc: 0.269114, Tokens per Sec:     4318, Lr: 0.000300
2024-05-27 13:49:25,529 - INFO - joeynmt.training - Epoch   1, Step:     2000, Batch Loss:     2.572315, Batch Acc: 0.272799, Tokens per Sec:     4452, Lr: 0.000300
2024-05-27 13:49:25,530 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:49:25,530 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 13:50:09,998 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.66, ppl:  14.24, acc:   0.26, generation: 44.4623[sec], evaluation: 0.0000[sec]
2024-05-27 13:50:10,000 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 13:50:10,103 - INFO - joeynmt.training - Example #0
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', '&apos;ve', 'been', 'been', 'been', 'been', 'been', 'to', 'the', 'world', 'to', 'the', 'world', 'that', 'the', 'world', 'that', '&apos;s', 'the', 'world', 'that', '&apos;s', 'the', 'world', ',', 'for', 'the', 'world', ',', 'for', '1@@', '0@@', '0@@', 's', ',', 'in', '1@@', '0@@', ',000', 'years', 'ago', ',', 'in', 'the', 'world', ',', 'in', 'the', 'world', 'in', 'the', 'world', ',', 'in', 'the', 'world', ',', '</s>']
2024-05-27 13:50:10,104 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 13:50:10,104 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 13:50:10,104 - INFO - joeynmt.training - 	Hypothesis: They &apos;ve been been been been been to the world to the world that the world that &apos;s the world that &apos;s the world , for the world , for 100s , in 10,000 years ago , in the world , in the world in the world , in the world ,
2024-05-27 13:50:10,104 - INFO - joeynmt.training - Example #1
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'the', 'first', 'of', 'this', 'is', 'not', 'the', 'same', 'thing', 'that', '&apos;s', 'not', 'not', 'not', 'the', 'same', 'thing', 'to', 'the', 'same', 'thing', '.', '</s>']
2024-05-27 13:50:10,104 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 13:50:10,104 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 13:50:10,104 - INFO - joeynmt.training - 	Hypothesis: And I was the first of this is not the same thing that &apos;s not not not the same thing to the same thing .
2024-05-27 13:50:10,104 - INFO - joeynmt.training - Example #2
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 13:50:10,104 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'ur@@', 'al', 'is', 'a', 'b@@', 'est', 'of', 'the', 'c@@', 'y@@', 'n@@', 'et@@', 'al', ',', 'the', 'c@@', 'y@@', 'n@@', 'ame', ',', 'the', 'c@@', 'ity', 'of', 'the', 'c@@', 'y@@', 'n@@', 'ame', 'of', 'the', 'c@@', 'ar', '.', '</s>']
2024-05-27 13:50:10,104 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Hypothesis: The bural is a best of the cynetal , the cyname , the city of the cyname of the car .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - Example #3
2024-05-27 13:50:10,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 13:50:10,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 13:50:10,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'see', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'ad', '.', '</s>']
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Hypothesis: You can see the best of the bad .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - Example #4
2024-05-27 13:50:10,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 13:50:10,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 13:50:10,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'is', 'a', 'lot', 'of', 'c@@', 'lim@@', 'ate', 'is', 'a', 'lot', 'of', 'the', 'world', 'is', 'the', 'world', 'that', '&apos;s', 'the', 'world', '&apos;s', 'the', 'world', '.', '</s>']
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 13:50:10,105 - INFO - joeynmt.training - 	Hypothesis: The first is a lot of climate is a lot of the world is the world that &apos;s the world &apos;s the world .
2024-05-27 13:50:26,491 - INFO - joeynmt.training - Epoch   1, Step:     2100, Batch Loss:     2.717220, Batch Acc: 0.278211, Tokens per Sec:     4388, Lr: 0.000300
2024-05-27 13:50:43,340 - INFO - joeynmt.training - Epoch   1, Step:     2200, Batch Loss:     2.745217, Batch Acc: 0.281460, Tokens per Sec:     4299, Lr: 0.000300
2024-05-27 13:50:59,960 - INFO - joeynmt.training - Epoch   1, Step:     2300, Batch Loss:     2.508877, Batch Acc: 0.285585, Tokens per Sec:     4322, Lr: 0.000300
2024-05-27 13:51:16,199 - INFO - joeynmt.training - Epoch   1, Step:     2400, Batch Loss:     2.444558, Batch Acc: 0.292436, Tokens per Sec:     4442, Lr: 0.000300
2024-05-27 13:51:32,287 - INFO - joeynmt.training - Epoch   1, Step:     2500, Batch Loss:     2.564091, Batch Acc: 0.298217, Tokens per Sec:     4432, Lr: 0.000300
2024-05-27 13:51:32,288 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:51:32,288 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 13:52:44,716 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.54, ppl:  12.67, acc:   0.28, generation: 72.4183[sec], evaluation: 0.0000[sec]
2024-05-27 13:52:44,720 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 13:52:44,824 - INFO - joeynmt.training - Example #0
2024-05-27 13:52:44,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 13:52:44,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 13:52:44,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'the', 'first', 'first', 'first', 'I', '&apos;ve', 'been', 'been', 'to', 'show', 'you', 'you', 'to', 'show', 'the', 'first', 'thing', 'that', 'the', 'most', 'of', 'the', 's@@', 'li@@', 'st@@', 'em@@', 's', ',', 'which', 'is', 'the', 'most', 'years', ',', 'which', 'was', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', ',000', 'percent', ',', 'the', 'last', '1@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '0@@', '-@@', 'year@@', '-@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', '-@@', '-@@', '-@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@', 'year@@', '-@@']
2024-05-27 13:52:44,824 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 13:52:44,824 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 13:52:44,824 - INFO - joeynmt.training - 	Hypothesis: The the first first first I &apos;ve been been to show you you to show the first thing that the most of the slistems , which is the most years , which was 1000000000000000000,000 percent , the last 1000000000000-year--year-year-year-year-year-year-year-year-year--year-year-year-----year-year-year-year-
2024-05-27 13:52:44,824 - INFO - joeynmt.training - Example #1
2024-05-27 13:52:44,824 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 13:52:44,824 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 13:52:44,824 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'going', 'to', 'this', 'this', 'is', 'the', 'problem', 'of', 'the', 'the', 'the', 'the', 'the', 'problem', 'of', 'the', 'problem', 'is', 'not', 'the', 'problem', 'of', 'the', 'problem', 'of', 'the', 'world', '.', '</s>']
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Hypothesis: It &apos;s going to this this is the problem of the the the the the problem of the problem is not the problem of the problem of the world .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - Example #2
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'the', 'c@@', 'rit@@', 'ical', 'l@@', 'it@@', 'al', ',', 'is', 'a', 'very', ',', 'in', 'a', 'little', 'bit', ',', 'the', 's@@', 'li@@', 'st@@', 'em@@', 's', 'of', 'the', 'c@@', 'are', 'of', 'the', 'c@@', 'are', '.', '</s>']
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Hypothesis: The the critical lital , is a very , in a little bit , the slistems of the care of the care .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - Example #3
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'h@@', 'un@@', 'der', 'and', 'and', 'and', 'and', 'and', 'you', '&apos;re', 'going', 'to', 'the', 'h@@', 'ist@@', 'ory', '.', '</s>']
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a hunder and and and and and you &apos;re going to the history .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - Example #4
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 13:52:44,825 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'The', 'The', 'one', 'is', 'a', 'lot', 'of', 'a', 'lot', 'of', 'a', 'lot', 'of', 'd@@', 'ays', ',', 'the', 'last', 'last', 'years', 'ago', ',', 'the', 'last', 'years', '.', '</s>']
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 13:52:44,825 - INFO - joeynmt.training - 	Hypothesis: The The The one is a lot of a lot of a lot of days , the last last years ago , the last years .
2024-05-27 13:53:01,576 - INFO - joeynmt.training - Epoch   1, Step:     2600, Batch Loss:     2.488409, Batch Acc: 0.305975, Tokens per Sec:     4373, Lr: 0.000300
2024-05-27 13:53:18,098 - INFO - joeynmt.training - Epoch   1, Step:     2700, Batch Loss:     2.396328, Batch Acc: 0.307986, Tokens per Sec:     4419, Lr: 0.000300
2024-05-27 13:53:34,224 - INFO - joeynmt.training - Epoch   1, Step:     2800, Batch Loss:     2.533528, Batch Acc: 0.307969, Tokens per Sec:     4416, Lr: 0.000300
2024-05-27 13:53:50,970 - INFO - joeynmt.training - Epoch   1, Step:     2900, Batch Loss:     2.439468, Batch Acc: 0.312121, Tokens per Sec:     4190, Lr: 0.000300
2024-05-27 13:54:08,166 - INFO - joeynmt.training - Epoch   1, Step:     3000, Batch Loss:     2.433640, Batch Acc: 0.319919, Tokens per Sec:     4239, Lr: 0.000300
2024-05-27 13:54:08,169 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:54:08,169 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 13:55:12,931 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.45, ppl:  11.57, acc:   0.30, generation: 64.7543[sec], evaluation: 0.0000[sec]
2024-05-27 13:55:12,935 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 13:55:13,073 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/500.ckpt
2024-05-27 13:55:13,078 - INFO - joeynmt.training - Example #0
2024-05-27 13:55:13,078 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 13:55:13,078 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 13:55:13,078 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['They', 'have', 'to', 'show', 'this', 'this', 'is', 'that', 'I', '&apos;ve', 'got', 'to', 'show', 'you', 'you', 'to', 'show', 'you', 'that', 'the', 're@@', 'ad', 'of', 'the', '1@@', '0@@', '0@@', '0@@', '-@@', 'h@@', 'y@@', '-@@', 'million', 'years', ',', 'for', '4@@', '0', 'years', 'ago', ',', 'which', 'was', 'a', '4@@', '0', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-27 13:55:13,078 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 13:55:13,078 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 13:55:13,078 - INFO - joeynmt.training - 	Hypothesis: They have to show this this is that I &apos;ve got to show you you to show you that the read of the 1000-hy-million years , for 40 years ago , which was a 40 percent of the U.S.
2024-05-27 13:55:13,078 - INFO - joeynmt.training - Example #1
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'just', 'this', 'this', 'is', 'the', 'ex@@', 'ity', 'of', 'the', 'the', 'the', 'problem', 'because', 'the', 'problem', 'because', 'the', 'problem', 'is', 'not', 'the', 'problem', 'of', 'the', 'problem', '.', '</s>']
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Hypothesis: It &apos;s just this this is the exity of the the the problem because the problem because the problem is not the problem of the problem .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - Example #2
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'un', 'is', 'the', 'h@@', 'y@@', 's@@', 'es', ',', 'in', 'a', 'a', 'h@@', 'y@@', 'pe', ',', 'in', 'a', 'a', 'h@@', 'y@@', 'pe', 'of', 'the', 'c@@', 'le', 'of', 'the', 'world', '.', '</s>']
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Hypothesis: The run is the hyses , in a a hype , in a a hype of the cle of the world .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - Example #3
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'just', 'a', 'h@@', 'un@@', 'dre@@', 'd', 'and', 'and', 'they', '&apos;re', 'going', 'to', 'be', '.', '</s>']
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - 	Hypothesis: It &apos;s just a hundred and and they &apos;re going to be .
2024-05-27 13:55:13,079 - INFO - joeynmt.training - Example #4
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 13:55:13,079 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'secon@@', 'd', 'is', 'a', 'lot', 'of', 'h@@', 'un@@', 'dre@@', 'ds', 'of', 'the', 'last', 'year', '.', '</s>']
2024-05-27 13:55:13,080 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 13:55:13,080 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 13:55:13,080 - INFO - joeynmt.training - 	Hypothesis: The second is a lot of hundreds of the last year .
2024-05-27 13:55:34,561 - INFO - joeynmt.training - Epoch   1, Step:     3100, Batch Loss:     2.493366, Batch Acc: 0.325421, Tokens per Sec:     3372, Lr: 0.000300
2024-05-27 13:55:53,528 - INFO - joeynmt.training - Epoch   1, Step:     3200, Batch Loss:     2.356619, Batch Acc: 0.324453, Tokens per Sec:     3733, Lr: 0.000300
2024-05-27 13:56:14,015 - INFO - joeynmt.training - Epoch   1, Step:     3300, Batch Loss:     2.321461, Batch Acc: 0.330854, Tokens per Sec:     3459, Lr: 0.000300
2024-05-27 13:56:33,175 - INFO - joeynmt.training - Epoch   1, Step:     3400, Batch Loss:     2.305279, Batch Acc: 0.335756, Tokens per Sec:     3813, Lr: 0.000300
2024-05-27 13:56:51,538 - INFO - joeynmt.training - Epoch   1, Step:     3500, Batch Loss:     2.196151, Batch Acc: 0.342775, Tokens per Sec:     3982, Lr: 0.000300
2024-05-27 13:56:51,539 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:56:51,539 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 13:57:51,936 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.36, ppl:  10.57, acc:   0.33, generation: 60.3897[sec], evaluation: 0.0000[sec]
2024-05-27 13:57:51,937 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 13:57:52,047 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/1000.ckpt
2024-05-27 13:57:52,052 - INFO - joeynmt.training - Example #0
2024-05-27 13:57:52,052 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 13:57:52,052 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 13:57:52,052 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'first', 'first', 'first', 'I', '&apos;ve', 'been', 'been', 'been', 'this', 'to', 'show', 'you', 'you', 'to', 'show', 'you', 'the', 'c@@', 'y@@', 'l@@', 'ed', 'that', 'the', 'c@@', 'y@@', 'l@@', 'it@@', 'er@@', 'ally', ',', 'for', 'three', 'years', ',', 'for', 'three', 'years', 'ago', ',', 'for', '4@@', '0', 'years', 'ago', ',', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'the', 'last', '4@@', '0', 'percent', 'of', 'the', 'last', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Hypothesis: The first first first I &apos;ve been been been this to show you you to show you the cyled that the cyliterally , for three years , for three years ago , for 40 years ago , the United States , the United States , the last 40 percent of the last 40 percent .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - Example #1
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'very', 's@@', 'w@@', 'ou@@', 'ght', 'the', 'c@@', 'ity', 'of', 'the', 'problem', 'because', 'I', 'don', '&apos;t', 'show', 'you', 'the', 'question', 'of', 'the', 'w@@', 'in@@', 'd', '.', '</s>']
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a very swought the city of the problem because I don &apos;t show you the question of the wind .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - Example #2
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'g@@', 'am@@', 'es', 'is', 'a', 'very', 'f@@', 'ul@@', 'l', 'is', ',', 'is', 'a', 'very', ',', 'in', 'a', 'very', ',', 'the', 'c@@', 'y@@', 'n@@', 'et@@', 'work', '.', '</s>']
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - 	Hypothesis: The games is a very full is , is a very , in a very , the cynetwork .
2024-05-27 13:57:52,053 - INFO - joeynmt.training - Example #3
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 13:57:52,053 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'going', 'to', 'be', 'the', 'p@@', 'ec@@', 't@@', 'or', 'and', 'it', '&apos;s', 'the', 'b@@', 'est', '.', '</s>']
2024-05-27 13:57:52,054 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 13:57:52,054 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 13:57:52,054 - INFO - joeynmt.training - 	Hypothesis: It &apos;s going to be the pector and it &apos;s the best .
2024-05-27 13:57:52,054 - INFO - joeynmt.training - Example #4
2024-05-27 13:57:52,054 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 13:57:52,054 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 13:57:52,054 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'last', 'year', 'is', 'a', 'lot', 'of', 'a', 's@@', 'li@@', 'gh@@', 'tly', 'b@@', 'ook', 'is', 'a', 'last', 'last', '1@@', '5', 'years', '.', '</s>']
2024-05-27 13:57:52,054 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 13:57:52,054 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 13:57:52,054 - INFO - joeynmt.training - 	Hypothesis: The last last year is a lot of a slightly book is a last last 15 years .
2024-05-27 13:58:10,679 - INFO - joeynmt.training - Epoch   1, Step:     3600, Batch Loss:     2.263219, Batch Acc: 0.342603, Tokens per Sec:     3872, Lr: 0.000300
2024-05-27 13:58:28,831 - INFO - joeynmt.training - Epoch   1, Step:     3700, Batch Loss:     2.215054, Batch Acc: 0.354897, Tokens per Sec:     3995, Lr: 0.000300
2024-05-27 13:58:47,743 - INFO - joeynmt.training - Epoch   1, Step:     3800, Batch Loss:     2.243375, Batch Acc: 0.355920, Tokens per Sec:     3819, Lr: 0.000300
2024-05-27 13:59:06,680 - INFO - joeynmt.training - Epoch   1, Step:     3900, Batch Loss:     2.159087, Batch Acc: 0.362325, Tokens per Sec:     3826, Lr: 0.000300
2024-05-27 13:59:25,771 - INFO - joeynmt.training - Epoch   1, Step:     4000, Batch Loss:     2.238855, Batch Acc: 0.370547, Tokens per Sec:     3816, Lr: 0.000300
2024-05-27 13:59:25,771 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 13:59:25,771 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:00:13,733 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.27, ppl:   9.68, acc:   0.35, generation: 47.9548[sec], evaluation: 0.0000[sec]
2024-05-27 14:00:13,735 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:00:13,850 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/1500.ckpt
2024-05-27 14:00:13,854 - INFO - joeynmt.training - Example #0
2024-05-27 14:00:13,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:00:13,854 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:00:13,854 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'they', '&apos;re', 'going', 'to', 'show', 'these', 's@@', 'even', 'of', 'the', 's@@', 'li@@', 'gh@@', 'ts', 'that', 'the', 'w@@', 'al@@', 'g@@', 'ame', 'that', '&apos;s', 'the', 'c@@', 'le@@', 'ar', ',', 'which', 'for', 'three', 'million', 'years', ',', 'which', 'was', 'the', 'si@@', 'x', 'years', ',', 'and', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-27 14:00:13,854 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:00:13,854 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:00:13,854 - INFO - joeynmt.training - 	Hypothesis: And they &apos;re going to show these seven of the slights that the walgame that &apos;s the clear , which for three million years , which was the six years , and the U.S.
2024-05-27 14:00:13,854 - INFO - joeynmt.training - Example #1
2024-05-27 14:00:13,854 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:00:13,854 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:00:13,854 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'w@@', 'o', 'this', 's@@', 'av@@', 'ing', 'the', 'problem', 'of', 'the', 'problem', 'of', 'the', 'problem', 'of', 'the', 'problem', 'of', 'the', 'problem', 'of', 'the', 'problem', '.', '</s>']
2024-05-27 14:00:13,854 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:00:13,854 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:00:13,854 - INFO - joeynmt.training - 	Hypothesis: Two this saving the problem of the problem of the problem of the problem of the problem of the problem .
2024-05-27 14:00:13,854 - INFO - joeynmt.training - Example #2
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'r@@', 'ul@@', 'es', 'is', ',', 'is', ',', 'is', ',', 'is', ',', 'in', 'a', 'sense', 'of', 'the', 'p@@', 'ur@@', 'p@@', 'ing', 'of', 'the', 'c@@', 'ity', 'of', 'the', 'c@@', 'ity', 'of', 'the', 'c@@', 'ell', 'of', 'the', 'c@@', 'ar', '.', '</s>']
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Hypothesis: The rules is , is , is , is , in a sense of the purping of the city of the city of the cell of the car .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - Example #3
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'be', 'in@@', 'spi@@', 'red', 'and', 'the', 'h@@', 'un@@', 'dre@@', 'd', '.', '</s>']
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Hypothesis: You can be inspired and the hundred .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - Example #4
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:00:13,855 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'to', 'be', 'going', 'to', 'be', 'going', 'to', 'be', 'a', 're@@', 'ali@@', 've', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:00:13,855 - INFO - joeynmt.training - 	Hypothesis: The next to be going to be going to be a realive of the last 25 years .
2024-05-27 14:00:31,262 - INFO - joeynmt.training - Epoch   1, Step:     4100, Batch Loss:     2.170243, Batch Acc: 0.376173, Tokens per Sec:     3993, Lr: 0.000300
2024-05-27 14:00:48,840 - INFO - joeynmt.training - Epoch   1, Step:     4200, Batch Loss:     2.183122, Batch Acc: 0.387115, Tokens per Sec:     4133, Lr: 0.000300
2024-05-27 14:01:07,553 - INFO - joeynmt.training - Epoch   1, Step:     4300, Batch Loss:     1.964392, Batch Acc: 0.394759, Tokens per Sec:     3865, Lr: 0.000300
2024-05-27 14:01:25,075 - INFO - joeynmt.training - Epoch   1, Step:     4400, Batch Loss:     2.273028, Batch Acc: 0.395741, Tokens per Sec:     4141, Lr: 0.000300
2024-05-27 14:01:30,259 - INFO - joeynmt.training - Epoch   1: total training loss 11911.79
2024-05-27 14:01:30,260 - INFO - joeynmt.training - EPOCH 2
2024-05-27 14:01:43,076 - INFO - joeynmt.training - Epoch   2, Step:     4500, Batch Loss:     2.190890, Batch Acc: 0.410178, Tokens per Sec:     4025, Lr: 0.000300
2024-05-27 14:01:43,078 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:01:43,078 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:02:31,175 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.18, ppl:   8.83, acc:   0.38, generation: 48.0903[sec], evaluation: 0.0000[sec]
2024-05-27 14:02:31,176 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:02:31,282 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/2000.ckpt
2024-05-27 14:02:31,287 - INFO - joeynmt.training - Example #0
2024-05-27 14:02:31,287 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', 'these', 'pic@@', 'tu@@', 'res', 'to', 'show', 'these', 'si@@', 'mil@@', 'ar', 'to', 'show', 'that', 'the', 'c@@', 'ar', 'g@@', 'l@@', 'ac@@', 'y', ',', 'which', 'for', 'three', 'million', 'years', 'ago', ',', 'which', 'for', 'three', 'million', 'years', 'ago', ',', 'and', 'the', 'univer@@', 'se', ',', 'is', 'the', 'univer@@', 'se', ',', 'is', 'the', 'univer@@', 'se', ',', 'it', '&apos;s', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Hypothesis: The year I shows these pictures to show these similar to show that the car glacy , which for three million years ago , which for three million years ago , and the universe , is the universe , is the universe , it &apos;s 40 percent .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - Example #1
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'going', 'to', 'show', 'that', 'the', 'gr@@', 'ou@@', 'p', 'of', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'of', 'the', 'b@@', 'est', 'of', 'the', 'b@@', 'a@@', 'ke', '.', '</s>']
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Hypothesis: It &apos;s going to show that the group of the problem because of the problem because of the problem because of the best of the bake .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - Example #2
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'b@@', 'ad', 'is', 'the', 'c@@', 'le@@', 'ar', 'system', 'is', ',', 'in', 'a', 'sense', 'of', 'sense', ',', 'the', 'res@@', 'p@@', 'ect', 'system', 'of', 'the', 'c@@', 'lim@@', 'b', 'system', '.', '</s>']
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - 	Hypothesis: The bad is the clear system is , in a sense of sense , the respect system of the climb system .
2024-05-27 14:02:31,288 - INFO - joeynmt.training - Example #3
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:02:31,288 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'h@@', 'un@@', 'dre@@', 'ds', 'of', 'the', 't@@', 'y@@', 'pe', 'of', 'the', 't@@', 'y@@', 'pe', '.', '</s>']
2024-05-27 14:02:31,289 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:02:31,289 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:02:31,289 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a hundreds of the type of the type .
2024-05-27 14:02:31,289 - INFO - joeynmt.training - Example #4
2024-05-27 14:02:31,289 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:02:31,289 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:02:31,289 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'li@@', 'gh@@', 'tly', 'going', 'to', 'be', 'a', 're@@', 'ad', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:02:31,289 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:02:31,289 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:02:31,289 - INFO - joeynmt.training - 	Hypothesis: The next slilightly going to be a read of the last 25 years .
2024-05-27 14:02:49,289 - INFO - joeynmt.training - Epoch   2, Step:     4600, Batch Loss:     1.841626, Batch Acc: 0.413811, Tokens per Sec:     3974, Lr: 0.000300
2024-05-27 14:03:07,573 - INFO - joeynmt.training - Epoch   2, Step:     4700, Batch Loss:     2.121229, Batch Acc: 0.419799, Tokens per Sec:     3968, Lr: 0.000300
2024-05-27 14:03:25,675 - INFO - joeynmt.training - Epoch   2, Step:     4800, Batch Loss:     1.975331, Batch Acc: 0.426978, Tokens per Sec:     4018, Lr: 0.000300
2024-05-27 14:03:43,529 - INFO - joeynmt.training - Epoch   2, Step:     4900, Batch Loss:     1.974186, Batch Acc: 0.423716, Tokens per Sec:     4031, Lr: 0.000300
2024-05-27 14:04:01,644 - INFO - joeynmt.training - Epoch   2, Step:     5000, Batch Loss:     2.113923, Batch Acc: 0.433384, Tokens per Sec:     4069, Lr: 0.000300
2024-05-27 14:04:01,645 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:04:01,645 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:05:05,961 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.08, ppl:   8.00, acc:   0.41, generation: 64.2199[sec], evaluation: 0.0000[sec]
2024-05-27 14:05:05,963 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:05:06,080 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/2500.ckpt
2024-05-27 14:05:06,084 - INFO - joeynmt.training - Example #0
2024-05-27 14:05:06,084 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:05:06,084 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:05:06,084 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', '&apos;ve', 'sho@@', 'wn', 'these', 'si@@', 'gn@@', 'als', 'for', 'di@@', 'rec@@', 't', 'that', 'the', 'c@@', 'lim@@', 'b', 'is', 'the', 'c@@', 'ra@@', 'z@@', 'y', ',', 'which', 'is', 'that', 'for', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ons', 'of', 'years', 'had', 'the', '4@@', '8', 'bil@@', 'lion', 'years', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Hypothesis: The year I &apos;ve shown these signals for direct that the climb is the crazy , which is that for three million years had the sions of years had the 48 billion years of the U.S.
2024-05-27 14:05:06,085 - INFO - joeynmt.training - Example #1
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'o', 'this', 's@@', 'av@@', 'ing', 'this', 's@@', 'av@@', 'ing', 'to', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'of', 'the', 'c@@', 'le@@', 'ar', 'of', 'the', 'c@@', 'le@@', 'ar', '.', '</s>']
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Hypothesis: To this saving this saving to the problem because of the problem because not shows of the clear of the clear .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - Example #2
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'ot@@', 'i@@', 'onal', 'g@@', 'l@@', 'ac@@', 'i@@', 'p@@', 'p@@', 'ul@@', 'l', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'ma@@', 'j@@', 'or', 'of', 'c@@', 'lim@@', 'b', '.', '</s>']
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Hypothesis: The cotional glacippull is , in a sense , the major of climb .
2024-05-27 14:05:06,085 - INFO - joeynmt.training - Example #3
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:05:06,085 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'h@@', 'un@@', 'dre@@', 'd', 'of', 'the', 's@@', 'itu@@', 'de', '.', '</s>']
2024-05-27 14:05:06,085 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:05:06,086 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:05:06,086 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a hundred of the situde .
2024-05-27 14:05:06,086 - INFO - joeynmt.training - Example #4
2024-05-27 14:05:06,086 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:05:06,086 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:05:06,086 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'will', 'be', 'a', 'very', 'qu@@', 'ic@@', 'k@@', 'ly', ',', 'the', 'next', '1@@', '5', 'years', '.', '</s>']
2024-05-27 14:05:06,086 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:05:06,086 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:05:06,086 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a very quickly , the next 15 years .
2024-05-27 14:05:24,581 - INFO - joeynmt.training - Epoch   2, Step:     5100, Batch Loss:     2.088553, Batch Acc: 0.434392, Tokens per Sec:     3782, Lr: 0.000300
2024-05-27 14:05:44,059 - INFO - joeynmt.training - Epoch   2, Step:     5200, Batch Loss:     1.858662, Batch Acc: 0.443011, Tokens per Sec:     3769, Lr: 0.000300
2024-05-27 14:06:03,486 - INFO - joeynmt.training - Epoch   2, Step:     5300, Batch Loss:     1.946447, Batch Acc: 0.439857, Tokens per Sec:     3738, Lr: 0.000300
2024-05-27 14:06:22,877 - INFO - joeynmt.training - Epoch   2, Step:     5400, Batch Loss:     1.866765, Batch Acc: 0.448177, Tokens per Sec:     3656, Lr: 0.000300
2024-05-27 14:06:42,787 - INFO - joeynmt.training - Epoch   2, Step:     5500, Batch Loss:     2.007555, Batch Acc: 0.453706, Tokens per Sec:     3657, Lr: 0.000300
2024-05-27 14:06:42,788 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:06:42,788 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:07:39,384 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   2.02, ppl:   7.54, acc:   0.43, generation: 56.5878[sec], evaluation: 0.0000[sec]
2024-05-27 14:07:39,385 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:07:39,507 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/3000.ckpt
2024-05-27 14:07:39,509 - INFO - joeynmt.training - Example #0
2024-05-27 14:07:39,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:07:39,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:07:39,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', 'these', 'these', 's@@', 'li@@', 'de', 'for', 'the', 's@@', 'li@@', 'de', 'that', 'the', 'h@@', 'o@@', 't', 'of', 'the', 'h@@', 'o@@', 'd@@', '-@@', 'three', 'million', 'years', 'of', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'years', 'had', 'the', 'next', '4@@', '8', 'de@@', 'ta@@', 'in@@', 's', ',', 'is', 'the', 'contin@@', 'ent', ',', 'is', 'the', 'str@@', 'e@@', 'et', 'of', 'the', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:07:39,509 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:07:39,509 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:07:39,509 - INFO - joeynmt.training - 	Hypothesis: The year I shows these these slide for the slide that the hot of the hod-three million years of years had the size of years had the next 48 detains , is the continent , is the street of the 40 percent .
2024-05-27 14:07:39,509 - INFO - joeynmt.training - Example #1
2024-05-27 14:07:39,509 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:07:39,509 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:07:39,509 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'w@@', 'o', 'this', 's@@', 'lo@@', 'w@@', 'ed', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'I', 'don', '&apos;t', 'show', 'you', 'that', 'I', '&apos;m', 'going', 'to', 'show', 'you', '.', '</s>']
2024-05-27 14:07:39,509 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:07:39,509 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:07:39,509 - INFO - joeynmt.training - 	Hypothesis: Two this slowed the problem because of the problem because I don &apos;t show you that I &apos;m going to show you .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - Example #2
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'ool', 'is', ',', 'the', 'c@@', 'lim@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'sense', ',', 'in', 'a', 'sense', 'of', 'c@@', 'lim@@', 'b@@', 'ing', 'system', '.', '</s>']
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Hypothesis: The cool is , the climate glacial sense , in a sense of climbing system .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - Example #3
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'you', '&apos;re', 'going', 'to', 'be', 'r@@', 'un@@', 'ning', '.', '</s>']
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Hypothesis: You can expected and you &apos;re going to be running .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - Example #4
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:07:39,510 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mem@@', 'ber', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:07:39,510 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remember of the last 25 years .
2024-05-27 14:07:58,294 - INFO - joeynmt.training - Epoch   2, Step:     5600, Batch Loss:     1.843421, Batch Acc: 0.456964, Tokens per Sec:     3807, Lr: 0.000300
2024-05-27 14:08:16,771 - INFO - joeynmt.training - Epoch   2, Step:     5700, Batch Loss:     1.771466, Batch Acc: 0.463794, Tokens per Sec:     3808, Lr: 0.000300
2024-05-27 14:08:36,694 - INFO - joeynmt.training - Epoch   2, Step:     5800, Batch Loss:     1.825619, Batch Acc: 0.463965, Tokens per Sec:     3631, Lr: 0.000300
2024-05-27 14:08:55,097 - INFO - joeynmt.training - Epoch   2, Step:     5900, Batch Loss:     1.979255, Batch Acc: 0.460633, Tokens per Sec:     3970, Lr: 0.000300
2024-05-27 14:09:13,234 - INFO - joeynmt.training - Epoch   2, Step:     6000, Batch Loss:     1.684126, Batch Acc: 0.468837, Tokens per Sec:     3955, Lr: 0.000300
2024-05-27 14:09:13,235 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:09:13,235 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:10:00,730 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.96, ppl:   7.11, acc:   0.45, generation: 47.4877[sec], evaluation: 0.0000[sec]
2024-05-27 14:10:00,732 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:10:00,860 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/3500.ckpt
2024-05-27 14:10:00,863 - INFO - joeynmt.training - Example #0
2024-05-27 14:10:00,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:10:00,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:10:00,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'di@@', 've', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', ',', 'which', 'is', 'that', 'for', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '8', 'percent', 'of', 'the', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 14:10:00,863 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:10:00,863 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:10:00,863 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to dive to show that the calculate that the calculate , which is that for three million years had the size of years had the size of the 48 percent of the 48 percent .
2024-05-27 14:10:00,863 - INFO - joeynmt.training - Example #1
2024-05-27 14:10:00,863 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:10:00,863 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:10:00,863 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'I', 'was', 'a', 'lot', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'I', 'don', '&apos;t', 'show', 'it', '.', '</s>']
2024-05-27 14:10:00,863 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Hypothesis: And I was a lot of the gravity of the problem because of the problem because I don &apos;t show it .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - Example #2
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cas@@', 'e', 'of', 'the', 'cul@@', 'tur@@', 'al', 'system', '.', '</s>']
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial is , in a sense , the case of the cultural system .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - Example #3
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'you', 're@@', 'ver@@', 'se', '.', '</s>']
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expected and you reverse .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - Example #4
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:10:00,864 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'very', 'rap@@', 'i@@', 've', 'car@@', 'ry', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:10:00,864 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a very rapive carry on the last 25 years .
2024-05-27 14:10:19,047 - INFO - joeynmt.training - Epoch   2, Step:     6100, Batch Loss:     1.809441, Batch Acc: 0.468122, Tokens per Sec:     3890, Lr: 0.000300
2024-05-27 14:10:38,125 - INFO - joeynmt.training - Epoch   2, Step:     6200, Batch Loss:     1.836120, Batch Acc: 0.477657, Tokens per Sec:     3830, Lr: 0.000300
2024-05-27 14:10:58,559 - INFO - joeynmt.training - Epoch   2, Step:     6300, Batch Loss:     1.630799, Batch Acc: 0.476094, Tokens per Sec:     3637, Lr: 0.000300
2024-05-27 14:11:17,556 - INFO - joeynmt.training - Epoch   2, Step:     6400, Batch Loss:     1.982886, Batch Acc: 0.480655, Tokens per Sec:     3718, Lr: 0.000300
2024-05-27 14:11:36,676 - INFO - joeynmt.training - Epoch   2, Step:     6500, Batch Loss:     1.851746, Batch Acc: 0.476695, Tokens per Sec:     3701, Lr: 0.000300
2024-05-27 14:11:36,676 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:11:36,676 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:12:28,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.92, ppl:   6.80, acc:   0.46, generation: 51.6656[sec], evaluation: 0.0000[sec]
2024-05-27 14:12:28,351 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:12:28,478 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/4000.ckpt
2024-05-27 14:12:28,485 - INFO - joeynmt.training - Example #0
2024-05-27 14:12:28,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:12:28,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:12:28,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', '&apos;ve', 'sho@@', 'wing', 'these', 'li@@', 'ving', 'these', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ing', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', '4@@', '8', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'million', 'years', 'had', 'the', '4@@', '8', '.', '</s>']
2024-05-27 14:12:28,485 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:12:28,485 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:12:28,485 - INFO - joeynmt.training - 	Hypothesis: The year I &apos;ve showing these living these slide to demonstring that the calculate glacial , which for 48 million years had the size of 48 million years had the 48 .
2024-05-27 14:12:28,485 - INFO - joeynmt.training - Example #1
2024-05-27 14:12:28,485 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:12:28,485 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:12:28,485 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'lot', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'the', 'f@@', 'all', '.', '</s>']
2024-05-27 14:12:28,485 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:12:28,485 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:12:28,485 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a lot of the gravity of the gravity of the problem because of the problem because not shows the fall .
2024-05-27 14:12:28,485 - INFO - joeynmt.training - Example #2
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'in', 'a', 'sense', ',', 'the', 'cu@@', 'or', 'of', 'the', 'glob@@', 'al', 'system', '.', '</s>']
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial is , in a sense , in a sense , the cuor of the global system .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - Example #3
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'have', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'you', 'get', 'the', 'h@@', 'un@@', 'dre@@', 'ds', '.', '</s>']
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Hypothesis: You have expected and you get the hundreds .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - Example #4
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:12:28,486 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'to', 'be', 'a', 're@@', 'cor@@', 'ding', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:12:28,486 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a record to be a recording to the last 25 years .
2024-05-27 14:12:47,942 - INFO - joeynmt.training - Epoch   2, Step:     6600, Batch Loss:     1.775546, Batch Acc: 0.487630, Tokens per Sec:     3743, Lr: 0.000300
2024-05-27 14:13:08,626 - INFO - joeynmt.training - Epoch   2, Step:     6700, Batch Loss:     1.678277, Batch Acc: 0.487554, Tokens per Sec:     3421, Lr: 0.000300
2024-05-27 14:13:26,364 - INFO - joeynmt.training - Epoch   2, Step:     6800, Batch Loss:     1.744040, Batch Acc: 0.490290, Tokens per Sec:     4061, Lr: 0.000300
2024-05-27 14:13:45,379 - INFO - joeynmt.training - Epoch   2, Step:     6900, Batch Loss:     1.711915, Batch Acc: 0.488448, Tokens per Sec:     3813, Lr: 0.000300
2024-05-27 14:14:04,457 - INFO - joeynmt.training - Epoch   2, Step:     7000, Batch Loss:     1.821244, Batch Acc: 0.491674, Tokens per Sec:     3840, Lr: 0.000300
2024-05-27 14:14:04,458 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:14:04,458 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:14:57,701 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.88, ppl:   6.56, acc:   0.47, generation: 53.2355[sec], evaluation: 0.0000[sec]
2024-05-27 14:14:57,702 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:14:57,816 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/4500.ckpt
2024-05-27 14:14:57,822 - INFO - joeynmt.training - Example #0
2024-05-27 14:14:57,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:14:57,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:14:57,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', 'these', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'si@@', 'ze', ',', 'for', 'three', 'million', 'years', ',', 'and', 'it', '&apos;s', 'l@@', 'ac@@', 'ros@@', 's', 'the', '4@@', '8', 'contin@@', 'ents', ',', 'it', '&apos;s', 're@@', 'cor@@', 'ding', '.', '</s>']
2024-05-27 14:14:57,822 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:14:57,822 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:14:57,822 - INFO - joeynmt.training - 	Hypothesis: The year I shows these slide slide to show that the calculate that the calculate glacial size , for three million years , and it &apos;s lacross the 48 continents , it &apos;s recording .
2024-05-27 14:14:57,822 - INFO - joeynmt.training - Example #1
2024-05-27 14:14:57,822 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:14:57,822 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:14:57,822 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'ur@@', 'ch', 'this', 's@@', 'l@@', 'it@@', 'er@@', 'ally', ',', 'because', 'of', 'the', 'problem', 'because', 'of', 'the', 'f@@', 'lo@@', 'or', 'of', 'the', 'f@@', 'lo@@', 'or', '.', '</s>']
2024-05-27 14:14:57,822 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:14:57,822 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:14:57,822 - INFO - joeynmt.training - 	Hypothesis: Turch this sliterally , because of the problem because of the floor of the floor .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - Example #2
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'in', 'a', 'sense', ',', 'the', 'cu@@', 'or', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial is , in a sense , in a sense , the cuor of the global climate system .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - Example #3
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'get', 'up', 'and', 'you', 'get', 'up', 'and', 'you', 'r@@', 'iti@@', 've', '.', '</s>']
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Hypothesis: You get up and you get up and you ritive .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - Example #4
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:14:57,823 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'will', 'be', 'a', 're@@', 'cor@@', 'd', 'is', 'a', 'car@@', 'e@@', 'er', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:14:57,823 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:14:57,824 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a record is a career of the last 25 years .
2024-05-27 14:15:16,932 - INFO - joeynmt.training - Epoch   2, Step:     7100, Batch Loss:     1.698745, Batch Acc: 0.494601, Tokens per Sec:     3785, Lr: 0.000300
2024-05-27 14:15:34,847 - INFO - joeynmt.training - Epoch   2, Step:     7200, Batch Loss:     1.775576, Batch Acc: 0.495868, Tokens per Sec:     4066, Lr: 0.000300
2024-05-27 14:15:53,628 - INFO - joeynmt.training - Epoch   2, Step:     7300, Batch Loss:     1.946361, Batch Acc: 0.500787, Tokens per Sec:     3821, Lr: 0.000300
2024-05-27 14:16:11,502 - INFO - joeynmt.training - Epoch   2, Step:     7400, Batch Loss:     1.869477, Batch Acc: 0.493226, Tokens per Sec:     4015, Lr: 0.000300
2024-05-27 14:16:29,866 - INFO - joeynmt.training - Epoch   2, Step:     7500, Batch Loss:     1.802551, Batch Acc: 0.499307, Tokens per Sec:     4008, Lr: 0.000300
2024-05-27 14:16:29,867 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:16:29,868 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:17:15,658 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.85, ppl:   6.36, acc:   0.48, generation: 45.7838[sec], evaluation: 0.0000[sec]
2024-05-27 14:17:15,659 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:17:15,775 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/5000.ckpt
2024-05-27 14:17:15,779 - INFO - joeynmt.training - Example #0
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'this', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'of', 'years', ',', 'which', 'for', '4@@', '8', 'de@@', 'de@@', 'n', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-27 14:17:15,780 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:17:15,780 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:17:15,780 - INFO - joeynmt.training - 	Hypothesis: The year I shows these slides to show this slide to show that the calculate glacial , which for almost of years , which for 48 deden the U.S.
2024-05-27 14:17:15,780 - INFO - joeynmt.training - Example #1
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'w@@', 'o', 'this', 's@@', 'w@@', 'it@@', 'ch', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'I', 'don', '&apos;t', 'show', 'you', 'the', 'f@@', 'lo@@', 'or', '.', '</s>']
2024-05-27 14:17:15,780 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:17:15,780 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:17:15,780 - INFO - joeynmt.training - 	Hypothesis: Two this switch the gravity of the problem because I don &apos;t show you the floor .
2024-05-27 14:17:15,780 - INFO - joeynmt.training - Example #2
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:17:15,780 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cu@@', 'er', ',', 'the', 'cu@@', 'er', 'system', '.', '</s>']
2024-05-27 14:17:15,780 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial is , in a sense , the cuer , the cuer system .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - Example #3
2024-05-27 14:17:15,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:17:15,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:17:15,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'ec@@', 'ted', 'in@@', 'ver@@', 's', 'and', 'you', '&apos;re', 'going', 'to', 'be', '.', '</s>']
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Hypothesis: You expected invers and you &apos;re going to be .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - Example #4
2024-05-27 14:17:15,781 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:17:15,781 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:17:15,781 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 's@@', 'li@@', 'de@@', 's', 'is', 'going', 'to', 'be', 'a', 'car@@', 'ri@@', 'er', '.', '</s>']
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:17:15,781 - INFO - joeynmt.training - 	Hypothesis: The next next slides is going to be a carrier .
2024-05-27 14:17:36,332 - INFO - joeynmt.training - Epoch   2, Step:     7600, Batch Loss:     1.816577, Batch Acc: 0.498016, Tokens per Sec:     3413, Lr: 0.000300
2024-05-27 14:17:54,931 - INFO - joeynmt.training - Epoch   2, Step:     7700, Batch Loss:     1.737217, Batch Acc: 0.504362, Tokens per Sec:     3932, Lr: 0.000300
2024-05-27 14:18:14,445 - INFO - joeynmt.training - Epoch   2, Step:     7800, Batch Loss:     1.849837, Batch Acc: 0.508072, Tokens per Sec:     3832, Lr: 0.000300
2024-05-27 14:18:32,976 - INFO - joeynmt.training - Epoch   2, Step:     7900, Batch Loss:     1.748212, Batch Acc: 0.506421, Tokens per Sec:     3803, Lr: 0.000300
2024-05-27 14:18:52,602 - INFO - joeynmt.training - Epoch   2, Step:     8000, Batch Loss:     1.655170, Batch Acc: 0.507236, Tokens per Sec:     3785, Lr: 0.000300
2024-05-27 14:18:52,603 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:18:52,603 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:19:43,420 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.81, ppl:   6.12, acc:   0.48, generation: 50.8066[sec], evaluation: 0.0000[sec]
2024-05-27 14:19:43,422 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:19:43,531 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/5500.ckpt
2024-05-27 14:19:43,535 - INFO - joeynmt.training - Example #0
2024-05-27 14:19:43,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:19:43,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:19:43,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'si@@', 'ze', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'l@@', 'ater', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 14:19:43,535 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:19:43,535 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:19:43,535 - INFO - joeynmt.training - 	Hypothesis: And year I showed these slide to show that the calculate that the calculate glacial size , which for almost three million years later had the size of 48 percent .
2024-05-27 14:19:43,535 - INFO - joeynmt.training - Example #1
2024-05-27 14:19:43,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:19:43,535 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:19:43,535 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'w@@', 'a@@', 'ke', 'this', 's@@', 'un@@', 'der', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'the', 'sp@@', 'ac@@', 'i@@', 'al', '.', '</s>']
2024-05-27 14:19:43,535 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:19:43,535 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:19:43,535 - INFO - joeynmt.training - 	Hypothesis: Twake this sunder the gravity of the problem because it doesn &apos;t show it the spacial .
2024-05-27 14:19:43,535 - INFO - joeynmt.training - Example #2
2024-05-27 14:19:43,535 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'the', 'cu@@', 'or', 'the', 'cu@@', 'or', 'the', 'ma@@', 'j@@', 'or', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial glacial , the cuor the cuor the major the global climate system .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - Example #3
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'ect', 'in@@', 'side', 'and', 'you', 'get', 'up', '.', '</s>']
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Hypothesis: You expect inside and you get up .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - Example #4
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:19:43,536 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'very', 'qu@@', 'ic@@', 'k@@', 'ly', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:19:43,536 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a very quickly the last 25 years .
2024-05-27 14:20:03,209 - INFO - joeynmt.training - Epoch   2, Step:     8100, Batch Loss:     1.801013, Batch Acc: 0.509218, Tokens per Sec:     3539, Lr: 0.000300
2024-05-27 14:20:22,907 - INFO - joeynmt.training - Epoch   2, Step:     8200, Batch Loss:     1.741748, Batch Acc: 0.508300, Tokens per Sec:     3636, Lr: 0.000300
2024-05-27 14:20:42,279 - INFO - joeynmt.training - Epoch   2, Step:     8300, Batch Loss:     1.856403, Batch Acc: 0.512953, Tokens per Sec:     3697, Lr: 0.000300
2024-05-27 14:21:02,138 - INFO - joeynmt.training - Epoch   2, Step:     8400, Batch Loss:     1.783702, Batch Acc: 0.514053, Tokens per Sec:     3562, Lr: 0.000300
2024-05-27 14:21:21,302 - INFO - joeynmt.training - Epoch   2, Step:     8500, Batch Loss:     1.659824, Batch Acc: 0.513419, Tokens per Sec:     3747, Lr: 0.000300
2024-05-27 14:21:21,303 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:21:21,303 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:22:15,496 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.79, ppl:   6.00, acc:   0.49, generation: 54.1846[sec], evaluation: 0.0000[sec]
2024-05-27 14:22:15,498 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:22:15,641 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/6000.ckpt
2024-05-27 14:22:15,644 - INFO - joeynmt.training - Example #0
2024-05-27 14:22:15,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:22:15,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:22:15,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', ',', 'I', 'sho@@', 'ws', 'these', 's@@', 'li@@', 'es', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'si@@', 'ze', ',', 'that', 'for', 'the', '4@@', '8', 'million', 'years', 'had', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-27 14:22:15,644 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:22:15,644 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:22:15,644 - INFO - joeynmt.training - 	Hypothesis: The year I shows , I shows these slies to show that the calculate glacial glacial size , that for the 48 million years had the U.S.
2024-05-27 14:22:15,644 - INFO - joeynmt.training - Example #1
2024-05-27 14:22:15,644 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:22:15,644 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:22:15,644 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;m', 'going', 'to', 'have', 'this', 's@@', 'un@@', 'e', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'g@@', 'one', '.', '</s>']
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Hypothesis: I &apos;m going to have this sune of the gravity of the problem because it &apos;s not showing the gone .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - Example #2
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'cu@@', 'er', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial is , in a sense , the cuer of global climate system .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - Example #3
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', 'you', 'know', ',', 'you', 'know', '.', '</s>']
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - 	Hypothesis: You know , you know , you know , you know , you know .
2024-05-27 14:22:15,645 - INFO - joeynmt.training - Example #4
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:22:15,645 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'e-@@', 'car@@', 'rel@@', 'ated', 'by', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:22:15,646 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:22:15,646 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:22:15,646 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a ree-carrelated by the last 25 years .
2024-05-27 14:22:35,505 - INFO - joeynmt.training - Epoch   2, Step:     8600, Batch Loss:     1.705031, Batch Acc: 0.506350, Tokens per Sec:     3515, Lr: 0.000300
2024-05-27 14:22:56,447 - INFO - joeynmt.training - Epoch   2, Step:     8700, Batch Loss:     1.601726, Batch Acc: 0.512551, Tokens per Sec:     3514, Lr: 0.000300
2024-05-27 14:23:16,809 - INFO - joeynmt.training - Epoch   2, Step:     8800, Batch Loss:     1.717917, Batch Acc: 0.513051, Tokens per Sec:     3549, Lr: 0.000300
2024-05-27 14:23:30,124 - INFO - joeynmt.training - Epoch   2: total training loss 8151.44
2024-05-27 14:23:30,125 - INFO - joeynmt.training - EPOCH 3
2024-05-27 14:23:37,084 - INFO - joeynmt.training - Epoch   3, Step:     8900, Batch Loss:     1.616509, Batch Acc: 0.532922, Tokens per Sec:     3891, Lr: 0.000300
2024-05-27 14:23:57,327 - INFO - joeynmt.training - Epoch   3, Step:     9000, Batch Loss:     1.491561, Batch Acc: 0.534051, Tokens per Sec:     3575, Lr: 0.000300
2024-05-27 14:23:57,328 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:23:57,329 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:24:55,365 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.76, ppl:   5.81, acc:   0.50, generation: 58.0203[sec], evaluation: 0.0000[sec]
2024-05-27 14:24:55,368 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:24:55,512 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/6500.ckpt
2024-05-27 14:24:55,516 - INFO - joeynmt.training - Example #0
2024-05-27 14:24:55,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:24:55,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:24:55,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', 'I', 'sho@@', 'wing', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'dimen@@', 'si@@', 'ons', 'of', '4@@', '8', 'million', 'years', ',', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'et', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:24:55,516 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:24:55,516 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:24:55,516 - INFO - joeynmt.training - 	Hypothesis: The year I shows I showing these slide to show that the calculate that the calculate glacial glacial dimensions of 48 million years , the United States , it &apos;s restreet of 40 percent .
2024-05-27 14:24:55,516 - INFO - joeynmt.training - Example #1
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', ',', 'this', 'is', 'a', 'lot', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'it', 'to', 'the', 'sp@@', 'ex@@', 't@@', 'ent', '.', '</s>']
2024-05-27 14:24:55,517 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:24:55,517 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:24:55,517 - INFO - joeynmt.training - 	Hypothesis: So , this is a lot of the gravity of the problem because it &apos;s not showing it to the spextent .
2024-05-27 14:24:55,517 - INFO - joeynmt.training - Example #2
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'system', '.', '</s>']
2024-05-27 14:24:55,517 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:24:55,517 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:24:55,517 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial glacial , the heart heart heart of the global system .
2024-05-27 14:24:55,517 - INFO - joeynmt.training - Example #3
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:24:55,517 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'w@@', 'in@@', 'ter', 'and', 'you', 'get', 'out', 'of', 'the', 't@@', 'est', '.', '</s>']
2024-05-27 14:24:55,518 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:24:55,518 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:24:55,518 - INFO - joeynmt.training - 	Hypothesis: It &apos;s winter and you get out of the test .
2024-05-27 14:24:55,518 - INFO - joeynmt.training - Example #4
2024-05-27 14:24:55,518 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:24:55,518 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:24:55,518 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'will', 'be', 'a', 're@@', 'qu@@', 'i@@', 'res', 'that', '&apos;s', 'a', 're@@', 'cor@@', 'd', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:24:55,518 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:24:55,518 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:24:55,518 - INFO - joeynmt.training - 	Hypothesis: The next slide is will be a requires that &apos;s a record to the last 25 years .
2024-05-27 14:25:17,810 - INFO - joeynmt.training - Epoch   3, Step:     9100, Batch Loss:     1.578634, Batch Acc: 0.536044, Tokens per Sec:     3223, Lr: 0.000300
2024-05-27 14:25:39,631 - INFO - joeynmt.training - Epoch   3, Step:     9200, Batch Loss:     1.601278, Batch Acc: 0.533951, Tokens per Sec:     3371, Lr: 0.000300
2024-05-27 14:26:00,363 - INFO - joeynmt.training - Epoch   3, Step:     9300, Batch Loss:     1.630566, Batch Acc: 0.530235, Tokens per Sec:     3507, Lr: 0.000300
2024-05-27 14:26:20,694 - INFO - joeynmt.training - Epoch   3, Step:     9400, Batch Loss:     1.654441, Batch Acc: 0.530824, Tokens per Sec:     3489, Lr: 0.000300
2024-05-27 14:26:40,403 - INFO - joeynmt.training - Epoch   3, Step:     9500, Batch Loss:     1.745227, Batch Acc: 0.531447, Tokens per Sec:     3609, Lr: 0.000300
2024-05-27 14:26:40,404 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:26:40,404 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:27:25,082 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.75, ppl:   5.77, acc:   0.50, generation: 44.6695[sec], evaluation: 0.0000[sec]
2024-05-27 14:27:25,084 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:27:25,212 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/7000.ckpt
2024-05-27 14:27:25,218 - INFO - joeynmt.training - Example #0
2024-05-27 14:27:25,218 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:27:25,218 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:27:25,218 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', ',', 'I', 'sho@@', 'ws', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'h@@', 'o@@', 't', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', '4@@', '8', 'million', 'years', ',', 'has', 'the', '4@@', '8', 'percent', 'of', 'the', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:27:25,218 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:27:25,218 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:27:25,218 - INFO - joeynmt.training - 	Hypothesis: The year I shows , I shows these slides to show that the hot glacial glacial glacial , which for 48 million years , has the 48 percent of the 40 percent .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - Example #1
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'w@@', 'a@@', 'it', '&apos;s', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'f@@', 'lo@@', 'or', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'g@@', 'l@@', 'ac@@', 'i@@', 'on', '.', '</s>']
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Hypothesis: Twait &apos;s a gravity of the problem because it &apos;s not showing the floor because it &apos;s not showing the glacion .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - Example #2
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'h@@', 'o@@', 't', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'system', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'po@@', 'w@@', 'er@@', 'ful', 'sense', 'of', 'glob@@', 'al', 'system', '.', '</s>']
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Hypothesis: The hot glacial glacial system is , in a sense , the powerful sense of global system .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - Example #3
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:27:25,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'ex@@', 'pan@@', 'ds', 'and', 'you', 'get', 't@@', 'est', '.', '</s>']
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:27:25,219 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:27:25,220 - INFO - joeynmt.training - 	Hypothesis: You can expands and you get test .
2024-05-27 14:27:25,220 - INFO - joeynmt.training - Example #4
2024-05-27 14:27:25,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:27:25,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:27:25,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'gi@@', 'on', 'is', 'a', 're@@', 'cor@@', 'd', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:27:25,220 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:27:25,220 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:27:25,220 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a region is a record to the last 25 years .
2024-05-27 14:27:46,727 - INFO - joeynmt.training - Epoch   3, Step:     9600, Batch Loss:     1.649749, Batch Acc: 0.539173, Tokens per Sec:     3313, Lr: 0.000300
2024-05-27 14:28:06,674 - INFO - joeynmt.training - Epoch   3, Step:     9700, Batch Loss:     1.544653, Batch Acc: 0.540463, Tokens per Sec:     3686, Lr: 0.000300
2024-05-27 14:28:28,118 - INFO - joeynmt.training - Epoch   3, Step:     9800, Batch Loss:     1.740536, Batch Acc: 0.533481, Tokens per Sec:     3441, Lr: 0.000300
2024-05-27 14:28:48,663 - INFO - joeynmt.training - Epoch   3, Step:     9900, Batch Loss:     1.726784, Batch Acc: 0.538123, Tokens per Sec:     3502, Lr: 0.000300
2024-05-27 14:29:07,696 - INFO - joeynmt.training - Epoch   3, Step:    10000, Batch Loss:     1.643314, Batch Acc: 0.528476, Tokens per Sec:     3836, Lr: 0.000300
2024-05-27 14:29:07,696 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:29:07,696 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:30:06,898 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.74, ppl:   5.70, acc:   0.51, generation: 59.1928[sec], evaluation: 0.0000[sec]
2024-05-27 14:30:06,899 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:30:07,033 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/7500.ckpt
2024-05-27 14:30:07,037 - INFO - joeynmt.training - Example #0
2024-05-27 14:30:07,037 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:30:07,037 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:30:07,037 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ture', 'that', 'c@@', 'alc@@', 'ul@@', 'ar@@', 't@@', 'en', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'to', 'the', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent', ',', 'and', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'et', ',', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'et', ',', 'you', 'know', ',', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'et', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:30:07,037 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Hypothesis: And year I showed these slide to show that the calculture that calcularten , which for almost three million years had the size of 48 to the United States continent , and it &apos;s restreet , it &apos;s restreet , you know , it &apos;s restreet 40 percent .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - Example #1
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'w@@', 'o', 'this', 's@@', 'w@@', 'it@@', 'ch', ',', 'because', 'of', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'of', 'the', 'g@@', 'l@@', 'ac@@', 'i@@', 'on', '.', '</s>']
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Hypothesis: Two this switch , because of the problem because of the problem because of the glacion .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - Example #2
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ture', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'the', 'hear@@', 't', 'po@@', 'in@@', 'ts', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - 	Hypothesis: The calculture glacial glacial , the heart points of the global climate system .
2024-05-27 14:30:07,038 - INFO - joeynmt.training - Example #3
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:30:07,038 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'can', 'be', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'you', 'get', 'up', '.', '</s>']
2024-05-27 14:30:07,039 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:30:07,039 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:30:07,039 - INFO - joeynmt.training - 	Hypothesis: You can be expected and you get up .
2024-05-27 14:30:07,039 - INFO - joeynmt.training - Example #4
2024-05-27 14:30:07,039 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:30:07,039 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:30:07,039 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'd@@', 'uc@@', 'ed', 'by', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:30:07,039 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:30:07,039 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:30:07,039 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a reduced by the last 25 years .
2024-05-27 14:30:27,679 - INFO - joeynmt.training - Epoch   3, Step:    10100, Batch Loss:     1.605954, Batch Acc: 0.541392, Tokens per Sec:     3543, Lr: 0.000300
2024-05-27 14:30:49,213 - INFO - joeynmt.training - Epoch   3, Step:    10200, Batch Loss:     1.567839, Batch Acc: 0.535424, Tokens per Sec:     3346, Lr: 0.000300
2024-05-27 14:31:10,086 - INFO - joeynmt.training - Epoch   3, Step:    10300, Batch Loss:     1.545104, Batch Acc: 0.536742, Tokens per Sec:     3442, Lr: 0.000300
2024-05-27 14:31:32,353 - INFO - joeynmt.training - Epoch   3, Step:    10400, Batch Loss:     1.670719, Batch Acc: 0.541841, Tokens per Sec:     3259, Lr: 0.000300
2024-05-27 14:31:53,829 - INFO - joeynmt.training - Epoch   3, Step:    10500, Batch Loss:     1.564355, Batch Acc: 0.535771, Tokens per Sec:     3359, Lr: 0.000300
2024-05-27 14:31:53,830 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:31:53,830 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:32:51,123 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.72, ppl:   5.59, acc:   0.51, generation: 57.2836[sec], evaluation: 0.0000[sec]
2024-05-27 14:32:51,124 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:32:51,268 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/8000.ckpt
2024-05-27 14:32:51,271 - INFO - joeynmt.training - Example #0
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'c@@', 'alc@@', 'ul@@', 'ate', 'that', 'for', 'the', '4@@', '8', 'million', 'years', 'has', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent', 'contin@@', 'ent', 'contin@@', 'ent', ',', 'you', '&apos;re', 're@@', 'str@@', 'e@@', 'am', ',', 'you', 're@@', 'cor@@', 'd', 'that', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:32:51,272 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:32:51,272 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:32:51,272 - INFO - joeynmt.training - 	Hypothesis: The year I shows I showed these slides to show that the calculate calculate that for the 48 million years has the size of the 48 United States continent continent continent , you &apos;re restream , you record that 40 percent .
2024-05-27 14:32:51,272 - INFO - joeynmt.training - Example #1
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', 'this', 'is', 'a', 'very', 'ob@@', 'vi@@', 'ous', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'show', 'the', 'sp@@', 'ex@@', 'ac@@', 'i@@', 'al', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:32:51,272 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:32:51,272 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:32:51,272 - INFO - joeynmt.training - 	Hypothesis: So this is a very obvious gravity of the problem because not show the spexacial of the ice .
2024-05-27 14:32:51,272 - INFO - joeynmt.training - Example #2
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:32:51,272 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:32:51,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ation', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ations', 'of', 'the', 'c@@', 'lim@@', 'ate', 'system', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Hypothesis: The calculation glacial calculations of the climate system of global climate system .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - Example #3
2024-05-27 14:32:51,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:32:51,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:32:51,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'in@@', 'side', 'and', 'you', 'get', 'up', 'and', 'you', 'get', 'the', 'ex@@', 't@@', 'ate', '.', '</s>']
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Hypothesis: It &apos;s inside and you get up and you get the extate .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - Example #4
2024-05-27 14:32:51,273 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:32:51,273 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:32:51,273 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 're@@', 'i@@', 'de', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:32:51,273 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid reide of the last 25 years .
2024-05-27 14:33:12,286 - INFO - joeynmt.training - Epoch   3, Step:    10600, Batch Loss:     1.736271, Batch Acc: 0.538450, Tokens per Sec:     3389, Lr: 0.000300
2024-05-27 14:33:33,277 - INFO - joeynmt.training - Epoch   3, Step:    10700, Batch Loss:     1.472313, Batch Acc: 0.536860, Tokens per Sec:     3428, Lr: 0.000300
2024-05-27 14:33:54,488 - INFO - joeynmt.training - Epoch   3, Step:    10800, Batch Loss:     1.446035, Batch Acc: 0.545286, Tokens per Sec:     3439, Lr: 0.000300
2024-05-27 14:34:14,005 - INFO - joeynmt.training - Epoch   3, Step:    10900, Batch Loss:     1.572160, Batch Acc: 0.545615, Tokens per Sec:     3814, Lr: 0.000300
2024-05-27 14:34:33,791 - INFO - joeynmt.training - Epoch   3, Step:    11000, Batch Loss:     1.712773, Batch Acc: 0.545502, Tokens per Sec:     3643, Lr: 0.000300
2024-05-27 14:34:33,792 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:34:33,793 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:35:33,389 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.71, ppl:   5.50, acc:   0.51, generation: 59.5882[sec], evaluation: 0.0000[sec]
2024-05-27 14:35:33,390 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:35:33,500 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/8500.ckpt
2024-05-27 14:35:33,503 - INFO - joeynmt.training - Example #0
2024-05-27 14:35:33,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:35:33,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:35:33,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'that', 'I', 'sho@@', 'w@@', 'ed', 'this', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'on', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'the', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', '.', '</s>']
2024-05-27 14:35:33,503 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:35:33,503 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:35:33,503 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slides that I showed this slide to show that the glacial glacion , which for almost three million years , has the United States continental continental continental continental continental continental .
2024-05-27 14:35:33,503 - INFO - joeynmt.training - Example #1
2024-05-27 14:35:33,503 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:35:33,503 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:35:33,503 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'so', ',', 'this', 'ob@@', 'vi@@', 'ous', ',', 'because', 'of', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'the', 'sp@@', 'in@@', 'ning', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Hypothesis: And so , this obvious , because of the problem because of the problem because not shows the spinning of the ice .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - Example #2
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ation', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'c@@', 'lim@@', 'ate', ',', 'the', 'po@@', 'or', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Hypothesis: The calculation glacial glacial climate , the poor of global climate system .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - Example #3
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'in@@', 'side', 'and', 'you', 'get', 'up', '.', '</s>']
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded inside and you get up .
2024-05-27 14:35:33,504 - INFO - joeynmt.training - Example #4
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:35:33,504 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'f@@', 'ul@@', 'l', 'f@@', 'ul@@', 'l', 'the', 'f@@', 'ul@@', 'l', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:35:33,505 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:35:33,505 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:35:33,505 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a full full the full 25 years .
2024-05-27 14:35:52,092 - INFO - joeynmt.training - Epoch   3, Step:    11100, Batch Loss:     1.489388, Batch Acc: 0.540596, Tokens per Sec:     3911, Lr: 0.000300
2024-05-27 14:36:13,177 - INFO - joeynmt.training - Epoch   3, Step:    11200, Batch Loss:     1.434991, Batch Acc: 0.548986, Tokens per Sec:     3481, Lr: 0.000300
2024-05-27 14:36:34,382 - INFO - joeynmt.training - Epoch   3, Step:    11300, Batch Loss:     1.583057, Batch Acc: 0.540540, Tokens per Sec:     3421, Lr: 0.000300
2024-05-27 14:36:54,417 - INFO - joeynmt.training - Epoch   3, Step:    11400, Batch Loss:     1.757436, Batch Acc: 0.545959, Tokens per Sec:     3479, Lr: 0.000300
2024-05-27 14:37:13,815 - INFO - joeynmt.training - Epoch   3, Step:    11500, Batch Loss:     1.607635, Batch Acc: 0.547167, Tokens per Sec:     3805, Lr: 0.000300
2024-05-27 14:37:13,816 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:37:13,817 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:38:20,803 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.69, ppl:   5.40, acc:   0.52, generation: 66.9783[sec], evaluation: 0.0000[sec]
2024-05-27 14:38:20,804 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:38:20,924 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/9000.ckpt
2024-05-27 14:38:20,927 - INFO - joeynmt.training - Example #0
2024-05-27 14:38:20,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:38:20,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:38:20,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'ws', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', '4@@', '8', ',', 'the', 'contin@@', 'ent', ',', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'et', ',', 'it', '&apos;s', 'the', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:38:20,927 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:38:20,927 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:38:20,927 - INFO - joeynmt.training - 	Hypothesis: The year I shows I showed these slidemons to show that the calculate glacial glacial glacial , which for 48 , the continent , it &apos;s restreet , it &apos;s the 40 percent .
2024-05-27 14:38:20,927 - INFO - joeynmt.training - Example #1
2024-05-27 14:38:20,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:38:20,927 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:38:20,927 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', ',', 'this', 'w@@', 'on@@', 'der@@', 'ful', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'of', 'the', 'problem', 'because', 'you', 'don', '&apos;t', 'show', 'the', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:38:20,927 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:38:20,927 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:38:20,927 - INFO - joeynmt.training - 	Hypothesis: So , this wonderful gravity of the problem because of the problem because you don &apos;t show the the ice of the ice .
2024-05-27 14:38:20,927 - INFO - joeynmt.training - Example #2
2024-05-27 14:38:20,927 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'is', 'in', 'a', 'sense', ',', 'the', 'po@@', 'or', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Hypothesis: The calculate glacial glacial , is in a sense , the poor of global climate system .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - Example #3
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'and', 'you', 'get', 'the', 'ex@@', 't@@', 'b@@', 'ec@@', 'ame', 'of', 'the', 'ex@@', 't@@', 'act', '.', '</s>']
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Hypothesis: It expands and you get the extbecame of the extact .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - Example #4
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:38:20,928 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'i@@', 'on', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:38:20,928 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a reion of the last 25 years .
2024-05-27 14:38:40,746 - INFO - joeynmt.training - Epoch   3, Step:    11600, Batch Loss:     1.715274, Batch Acc: 0.544981, Tokens per Sec:     3591, Lr: 0.000300
2024-05-27 14:39:00,988 - INFO - joeynmt.training - Epoch   3, Step:    11700, Batch Loss:     1.489359, Batch Acc: 0.546127, Tokens per Sec:     3625, Lr: 0.000300
2024-05-27 14:39:21,985 - INFO - joeynmt.training - Epoch   3, Step:    11800, Batch Loss:     1.375275, Batch Acc: 0.549283, Tokens per Sec:     3354, Lr: 0.000300
2024-05-27 14:39:42,636 - INFO - joeynmt.training - Epoch   3, Step:    11900, Batch Loss:     1.403544, Batch Acc: 0.546661, Tokens per Sec:     3518, Lr: 0.000300
2024-05-27 14:40:05,057 - INFO - joeynmt.training - Epoch   3, Step:    12000, Batch Loss:     1.788009, Batch Acc: 0.547468, Tokens per Sec:     3274, Lr: 0.000300
2024-05-27 14:40:05,058 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:40:05,058 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:40:54,566 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.68, ppl:   5.34, acc:   0.52, generation: 49.4979[sec], evaluation: 0.0000[sec]
2024-05-27 14:40:54,567 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:40:54,682 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/9500.ckpt
2024-05-27 14:40:54,684 - INFO - joeynmt.training - Example #0
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'to', 'show', 'that', 'the', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'all', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', '.', '</s>']
2024-05-27 14:40:54,685 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:40:54,685 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:40:54,685 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the calculus to show that the glacial glacial , which for all three million years has had the size of 48 .
2024-05-27 14:40:54,685 - INFO - joeynmt.training - Example #1
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'lot', 'of', 'the', 't@@', 'y@@', 'pe', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'wing', 'it', 'the', 'sp@@', 'ex@@', 't@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:40:54,685 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:40:54,685 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:40:54,685 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a lot of the type of the problem because not showing it the spextent of the ice .
2024-05-27 14:40:54,685 - INFO - joeynmt.training - Example #2
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:40:54,685 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ation', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'system', '.', '</s>']
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Hypothesis: The calculation glacial glacial , the heart heart of the global system .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - Example #3
2024-05-27 14:40:54,686 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:40:54,686 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:40:54,686 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'de', 'in@@', 'side', 'and', 're@@', 'ver@@', 'se', '.', '</s>']
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expande inside and reverse .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - Example #4
2024-05-27 14:40:54,686 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:40:54,686 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:40:54,686 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '2@@', '5', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', '-@@', 're@@', '-@@', 'h@@', 'ou@@', 'se', 're@@', 'ali@@', 'zed', 're@@', 'tur@@', 'n', 'out', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:40:54,686 - INFO - joeynmt.training - 	Hypothesis: The next 25 slide is going to be a re-re-house realized return out of the last 25 years .
2024-05-27 14:41:13,288 - INFO - joeynmt.training - Epoch   3, Step:    12100, Batch Loss:     1.727452, Batch Acc: 0.550045, Tokens per Sec:     3792, Lr: 0.000300
2024-05-27 14:41:32,606 - INFO - joeynmt.training - Epoch   3, Step:    12200, Batch Loss:     1.356701, Batch Acc: 0.554593, Tokens per Sec:     3659, Lr: 0.000300
2024-05-27 14:41:53,049 - INFO - joeynmt.training - Epoch   3, Step:    12300, Batch Loss:     1.551403, Batch Acc: 0.551244, Tokens per Sec:     3535, Lr: 0.000300
2024-05-27 14:42:13,357 - INFO - joeynmt.training - Epoch   3, Step:    12400, Batch Loss:     1.471156, Batch Acc: 0.553020, Tokens per Sec:     3468, Lr: 0.000300
2024-05-27 14:42:33,082 - INFO - joeynmt.training - Epoch   3, Step:    12500, Batch Loss:     1.809779, Batch Acc: 0.554968, Tokens per Sec:     3651, Lr: 0.000300
2024-05-27 14:42:33,083 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:42:33,083 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:43:25,420 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.66, ppl:   5.27, acc:   0.52, generation: 52.3300[sec], evaluation: 0.0000[sec]
2024-05-27 14:43:25,421 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:43:25,539 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/10000.ckpt
2024-05-27 14:43:25,542 - INFO - joeynmt.training - Example #0
2024-05-27 14:43:25,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:43:25,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:43:25,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'of', 'the', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'on', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'is', 'about', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Hypothesis: The year of the last year I showed these slidemonstrate to demonstrate that the calculate glacion , which for almost three million years has had the size of 48 percent of the United States , is about 40 percent .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - Example #1
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'o@@', 'k@@', 'y', 'this', ',', 'and', 'it', '&apos;s', 'a', 'gr@@', 'av@@', 'ity', 'because', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Hypothesis: Toky this , and it &apos;s a gravity because of the problem because it &apos;s not showing the ice of the ice .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - Example #2
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'in', 'a', 'sense', ',', 'the', 'po@@', 'or', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - 	Hypothesis: It &apos;s calculation is , in a sense , in a sense , the poor of the global climate system .
2024-05-27 14:43:25,543 - INFO - joeynmt.training - Example #3
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:43:25,543 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'be', 'ex@@', 'pan@@', 'ded', 'and', 'it', '&apos;s', 'r@@', 'iti@@', 've', '.', '</s>']
2024-05-27 14:43:25,544 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:43:25,544 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:43:25,544 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to be expanded and it &apos;s ritive .
2024-05-27 14:43:25,544 - INFO - joeynmt.training - Example #4
2024-05-27 14:43:25,544 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:43:25,544 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:43:25,544 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'f@@', 'ul@@', 'l', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:43:25,544 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:43:25,544 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:43:25,544 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a full of the last 25 years .
2024-05-27 14:43:45,978 - INFO - joeynmt.training - Epoch   3, Step:    12600, Batch Loss:     1.689461, Batch Acc: 0.554132, Tokens per Sec:     3490, Lr: 0.000300
2024-05-27 14:44:06,394 - INFO - joeynmt.training - Epoch   3, Step:    12700, Batch Loss:     1.551126, Batch Acc: 0.553624, Tokens per Sec:     3494, Lr: 0.000300
2024-05-27 14:44:26,788 - INFO - joeynmt.training - Epoch   3, Step:    12800, Batch Loss:     1.500231, Batch Acc: 0.549143, Tokens per Sec:     3585, Lr: 0.000300
2024-05-27 14:44:49,144 - INFO - joeynmt.training - Epoch   3, Step:    12900, Batch Loss:     1.459624, Batch Acc: 0.556691, Tokens per Sec:     3209, Lr: 0.000300
2024-05-27 14:45:10,836 - INFO - joeynmt.training - Epoch   3, Step:    13000, Batch Loss:     1.535874, Batch Acc: 0.556107, Tokens per Sec:     3342, Lr: 0.000300
2024-05-27 14:45:10,837 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:45:10,837 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:46:05,495 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.65, ppl:   5.23, acc:   0.53, generation: 54.6493[sec], evaluation: 0.0000[sec]
2024-05-27 14:46:05,496 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:46:05,621 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/10500.ckpt
2024-05-27 14:46:05,626 - INFO - joeynmt.training - Example #0
2024-05-27 14:46:05,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:46:05,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:46:05,626 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'se', ',', '4@@', '8', 'million', 'years', 'l@@', 'ater', 'contin@@', 'ent@@', 'al', '.', '</s>']
2024-05-27 14:46:05,626 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:46:05,626 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:46:05,626 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the slide to show that the artic glacial glacial glacise , 48 million years later continental .
2024-05-27 14:46:05,626 - INFO - joeynmt.training - Example #1
2024-05-27 14:46:05,626 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:46:05,626 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:46:05,626 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', ',', 'this', 's@@', 'w@@', 'im@@', 'm@@', 'ing', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 't@@', 'ac@@', 'ks', '.', '</s>']
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Hypothesis: So , this swimming the gravity of the problem because it &apos;s not showing the spexpectacks .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - Example #2
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 'is', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Hypothesis: The arten is artic glacial is , in a sense , the pulsant heart of the global climate system .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - Example #3
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'ex@@', 'pan@@', 'de', 'and', 'you', 'get', 'ex@@', 'pan@@', 'ds', '.', '</s>']
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - 	Hypothesis: You &apos;re expande and you get expands .
2024-05-27 14:46:05,627 - INFO - joeynmt.training - Example #4
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:46:05,627 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 're@@', 'ma@@', 'in@@', 's', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:46:05,628 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:46:05,628 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:46:05,628 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick remains on the last 25 years .
2024-05-27 14:46:26,396 - INFO - joeynmt.training - Epoch   3, Step:    13100, Batch Loss:     1.700545, Batch Acc: 0.555885, Tokens per Sec:     3562, Lr: 0.000300
2024-05-27 14:46:46,170 - INFO - joeynmt.training - Epoch   3, Step:    13200, Batch Loss:     1.653187, Batch Acc: 0.556227, Tokens per Sec:     3674, Lr: 0.000300
2024-05-27 14:47:03,378 - INFO - joeynmt.training - Epoch   3: total training loss 7054.27
2024-05-27 14:47:03,379 - INFO - joeynmt.training - EPOCH 4
2024-05-27 14:47:06,190 - INFO - joeynmt.training - Epoch   4, Step:    13300, Batch Loss:     1.553585, Batch Acc: 0.577347, Tokens per Sec:     3779, Lr: 0.000300
2024-05-27 14:47:26,033 - INFO - joeynmt.training - Epoch   4, Step:    13400, Batch Loss:     1.587157, Batch Acc: 0.569446, Tokens per Sec:     3632, Lr: 0.000300
2024-05-27 14:47:47,604 - INFO - joeynmt.training - Epoch   4, Step:    13500, Batch Loss:     1.481761, Batch Acc: 0.569932, Tokens per Sec:     3336, Lr: 0.000300
2024-05-27 14:47:47,606 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:47:47,606 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:48:43,647 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.18, acc:   0.53, generation: 56.0321[sec], evaluation: 0.0000[sec]
2024-05-27 14:48:43,649 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:48:43,804 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/11000.ckpt
2024-05-27 14:48:43,808 - INFO - joeynmt.training - Example #0
2024-05-27 14:48:43,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:48:43,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:48:43,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;ve', 'sho@@', 'wn', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'this', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'is', 'about', '4@@', '8', 'percent', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'is', 're@@', 'str@@', 'e@@', 'et', ',', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'et', ',', 'it', '&apos;s', 're@@', 'cor@@', 'ded', 'up', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:48:43,808 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:48:43,808 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:48:43,808 - INFO - joeynmt.training - 	Hypothesis: I &apos;ve shown these slide to show this slide to show that the calculate glacial glacial , which is about 48 percent of the United States , is restreet , it &apos;s restreet , it &apos;s recorded up 40 percent .
2024-05-27 14:48:43,808 - INFO - joeynmt.training - Example #1
2024-05-27 14:48:43,808 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:48:43,808 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:48:43,808 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'o@@', 'w@@', 'ever', ',', 'this', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Hypothesis: Towever , this is the gravity of the problem because it &apos;s not showing the ice of the ice .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - Example #2
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ation', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Hypothesis: The calculation glacial glacial is , in a sense , the pulsant heart of the global climate system .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - Example #3
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'pan@@', 's', 'w@@', 'in@@', 'ter', 'and', 'you', '&apos;re', 'ex@@', 'pan@@', 's', '.', '</s>']
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - 	Hypothesis: You expans winter and you &apos;re expans .
2024-05-27 14:48:43,809 - INFO - joeynmt.training - Example #4
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:48:43,809 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:48:43,810 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'vie@@', 'w', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:48:43,810 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:48:43,810 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:48:43,810 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a review of the last 25 years .
2024-05-27 14:49:04,134 - INFO - joeynmt.training - Epoch   4, Step:    13600, Batch Loss:     1.487660, Batch Acc: 0.577157, Tokens per Sec:     3535, Lr: 0.000300
2024-05-27 14:49:23,938 - INFO - joeynmt.training - Epoch   4, Step:    13700, Batch Loss:     1.502514, Batch Acc: 0.570630, Tokens per Sec:     3711, Lr: 0.000300
2024-05-27 14:49:44,612 - INFO - joeynmt.training - Epoch   4, Step:    13800, Batch Loss:     1.575562, Batch Acc: 0.567588, Tokens per Sec:     3490, Lr: 0.000300
2024-05-27 14:50:04,252 - INFO - joeynmt.training - Epoch   4, Step:    13900, Batch Loss:     1.484431, Batch Acc: 0.574366, Tokens per Sec:     3632, Lr: 0.000300
2024-05-27 14:50:23,696 - INFO - joeynmt.training - Epoch   4, Step:    14000, Batch Loss:     1.253158, Batch Acc: 0.570071, Tokens per Sec:     3741, Lr: 0.000300
2024-05-27 14:50:23,697 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:50:23,697 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:51:19,834 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.64, ppl:   5.14, acc:   0.53, generation: 56.1286[sec], evaluation: 0.0000[sec]
2024-05-27 14:51:19,835 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:51:20,006 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/11500.ckpt
2024-05-27 14:51:20,009 - INFO - joeynmt.training - Example #0
2024-05-27 14:51:20,009 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:51:20,009 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:51:20,009 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'is', 're@@', 'str@@', 'e@@', 'am', 're@@', 'str@@', 'e@@', 'am', ',', 'is', 're@@', 'str@@', 'e@@', 'am', 're@@', 'str@@', 'e@@', 'am', 're@@', 'str@@', 'e@@', 'am', ',', 'is', 're@@', 'str@@', 'e@@', 'am', 're@@', 'str@@', 'e@@', 'am', 're@@', 'str@@', 'e@@', 'am', ',', 'and', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'am', 're@@', 'str@@', 'e@@', 'am', ',', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'am', 're@@', 'tur@@', 'ned', 'to', 'the', 'ar@@', 't@@', 'age', 'of', 'the', 'ar@@', 'c@@', 'le', 'g@@', 'l@@', 'ac@@']
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the cotta glacial glacial glacial glacial glacial , is restream restream , is restream restream restream , is restream restream restream , and it &apos;s restream restream , it &apos;s restream returned to the artage of the arcle glac
2024-05-27 14:51:20,010 - INFO - joeynmt.training - Example #1
2024-05-27 14:51:20,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:51:20,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:51:20,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', ',', 'this', 'is', 'a', 'very', 'ob@@', 'vi@@', 'ous', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Hypothesis: So , this is a very obvious gravity of the problem because not shows it &apos;s not showing the ice of the ice .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - Example #2
2024-05-27 14:51:20,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:51:20,010 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:51:20,010 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'some', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - 	Hypothesis: The artic glacial glacial is , in some sense , the pulsant heart of the global climate of the global climate .
2024-05-27 14:51:20,010 - INFO - joeynmt.training - Example #3
2024-05-27 14:51:20,010 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:51:20,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:51:20,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'you', '&apos;re', 't@@', 'ot@@', 'ally', 'ex@@', 'p@@', 'ec@@', 'ted', '.', '</s>']
2024-05-27 14:51:20,011 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:51:20,011 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:51:20,011 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and you &apos;re totally expected .
2024-05-27 14:51:20,011 - INFO - joeynmt.training - Example #4
2024-05-27 14:51:20,011 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:51:20,011 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:51:20,011 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '2@@', '5', 'years', ',', 'is', 'going', 'to', 'be', 'a', 'car@@', 'rel@@', 'ated', 'by', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:51:20,011 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:51:20,011 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:51:20,011 - INFO - joeynmt.training - 	Hypothesis: The next 25 years , is going to be a carrelated by the last 25 years .
2024-05-27 14:51:37,317 - INFO - joeynmt.training - Epoch   4, Step:    14100, Batch Loss:     1.505863, Batch Acc: 0.571816, Tokens per Sec:     4046, Lr: 0.000300
2024-05-27 14:51:54,359 - INFO - joeynmt.training - Epoch   4, Step:    14200, Batch Loss:     1.803287, Batch Acc: 0.569050, Tokens per Sec:     4230, Lr: 0.000300
2024-05-27 14:52:10,768 - INFO - joeynmt.training - Epoch   4, Step:    14300, Batch Loss:     1.441796, Batch Acc: 0.567274, Tokens per Sec:     4394, Lr: 0.000300
2024-05-27 14:52:27,839 - INFO - joeynmt.training - Epoch   4, Step:    14400, Batch Loss:     1.460490, Batch Acc: 0.566215, Tokens per Sec:     4247, Lr: 0.000300
2024-05-27 14:52:45,157 - INFO - joeynmt.training - Epoch   4, Step:    14500, Batch Loss:     1.504325, Batch Acc: 0.569207, Tokens per Sec:     4144, Lr: 0.000300
2024-05-27 14:52:45,158 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:52:45,158 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:53:36,398 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.63, ppl:   5.09, acc:   0.54, generation: 51.2331[sec], evaluation: 0.0000[sec]
2024-05-27 14:53:36,399 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:53:36,512 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/12000.ckpt
2024-05-27 14:53:36,514 - INFO - joeynmt.training - Example #0
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'is', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'on', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'l@@', 'ab@@', 'or', '.', '</s>']
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrate to demonstrate that the calculus is artic glacion , which for almost three million years labor .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - Example #1
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', 'this', 'sub@@', 'ject', 'of', 'the', 'tr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'the', 'd@@', 'ra@@', 'w@@', 'ings', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Hypothesis: However this subject of the travity of the problem because not shows the drawings of the ice .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - Example #2
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:53:36,515 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'age', 'is', 'ar@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - 	Hypothesis: The artage is artica is , in a sense , the pulsant heart of the global climate system .
2024-05-27 14:53:36,515 - INFO - joeynmt.training - Example #3
2024-05-27 14:53:36,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:53:36,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:53:36,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'be', 'ex@@', 'pan@@', 'ded', 'and', 'ex@@', 't@@', 'ent', '.', '</s>']
2024-05-27 14:53:36,516 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:53:36,516 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:53:36,516 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to be expanded and extent .
2024-05-27 14:53:36,516 - INFO - joeynmt.training - Example #4
2024-05-27 14:53:36,516 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:53:36,516 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:53:36,516 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'de@@', 'al', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'rel@@', 'ated', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:53:36,516 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:53:36,516 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:53:36,516 - INFO - joeynmt.training - 	Hypothesis: The next deal slide is going to be a recorrelated to the last 25 years .
2024-05-27 14:53:54,287 - INFO - joeynmt.training - Epoch   4, Step:    14600, Batch Loss:     1.515828, Batch Acc: 0.567959, Tokens per Sec:     4086, Lr: 0.000300
2024-05-27 14:54:12,765 - INFO - joeynmt.training - Epoch   4, Step:    14700, Batch Loss:     1.363480, Batch Acc: 0.571332, Tokens per Sec:     3846, Lr: 0.000300
2024-05-27 14:54:33,292 - INFO - joeynmt.training - Epoch   4, Step:    14800, Batch Loss:     1.369025, Batch Acc: 0.576121, Tokens per Sec:     3564, Lr: 0.000300
2024-05-27 14:54:53,895 - INFO - joeynmt.training - Epoch   4, Step:    14900, Batch Loss:     1.739940, Batch Acc: 0.571654, Tokens per Sec:     3471, Lr: 0.000300
2024-05-27 14:55:12,030 - INFO - joeynmt.training - Epoch   4, Step:    15000, Batch Loss:     1.566263, Batch Acc: 0.571850, Tokens per Sec:     3944, Lr: 0.000300
2024-05-27 14:55:12,031 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:55:12,032 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:56:03,859 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.02, acc:   0.54, generation: 51.8194[sec], evaluation: 0.0000[sec]
2024-05-27 14:56:03,861 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:56:03,983 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/12500.ckpt
2024-05-27 14:56:03,988 - INFO - joeynmt.training - Example #0
2024-05-27 14:56:03,988 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:56:03,988 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:56:03,988 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', '.', '</s>']
2024-05-27 14:56:03,988 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:56:03,988 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:56:03,988 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrate that the calotta glacial glacial glacial , which for almost three million years has the size of 48 United States .
2024-05-27 14:56:03,988 - INFO - joeynmt.training - Example #1
2024-05-27 14:56:03,988 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:56:03,988 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:56:03,988 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', 'this', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'the', 'sp@@', 'ex@@', 'ex@@', 'ex@@', 't@@', 'ent', '.', '</s>']
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Hypothesis: However this is the gravity of the problem because it doesn &apos;t show it the spexexextent .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - Example #2
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 't@@', 'ex@@', 't', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'c@@', 'lim@@', 'ate', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in@@', 'ly', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Hypothesis: The arten text glacial glacial climate is , in a certainly climate system .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - Example #3
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'ex@@', 'p@@', 'ec@@', 'ted', 'to', 'be', 'ex@@', 'p@@', 'ec@@', 'ted', '.', '</s>']
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Hypothesis: You &apos;re expected to be expected .
2024-05-27 14:56:03,989 - INFO - joeynmt.training - Example #4
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:56:03,989 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '2@@', '5', 'years', 'is', 'going', 'to', 'be', 'a', 're@@', 'gi@@', 'on', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:56:03,989 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:56:03,990 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:56:03,990 - INFO - joeynmt.training - 	Hypothesis: The next 25 years is going to be a region on the last 25 years .
2024-05-27 14:56:23,633 - INFO - joeynmt.training - Epoch   4, Step:    15100, Batch Loss:     1.314533, Batch Acc: 0.572426, Tokens per Sec:     3700, Lr: 0.000300
2024-05-27 14:56:41,805 - INFO - joeynmt.training - Epoch   4, Step:    15200, Batch Loss:     1.642054, Batch Acc: 0.567385, Tokens per Sec:     3892, Lr: 0.000300
2024-05-27 14:57:02,087 - INFO - joeynmt.training - Epoch   4, Step:    15300, Batch Loss:     1.598446, Batch Acc: 0.577743, Tokens per Sec:     3693, Lr: 0.000300
2024-05-27 14:57:21,546 - INFO - joeynmt.training - Epoch   4, Step:    15400, Batch Loss:     1.415333, Batch Acc: 0.571804, Tokens per Sec:     3655, Lr: 0.000300
2024-05-27 14:57:40,735 - INFO - joeynmt.training - Epoch   4, Step:    15500, Batch Loss:     1.540904, Batch Acc: 0.568567, Tokens per Sec:     3796, Lr: 0.000300
2024-05-27 14:57:40,736 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 14:57:40,736 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 14:58:35,588 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.61, ppl:   5.01, acc:   0.54, generation: 54.8430[sec], evaluation: 0.0000[sec]
2024-05-27 14:58:35,589 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 14:58:35,713 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/13000.ckpt
2024-05-27 14:58:35,717 - INFO - joeynmt.training - Example #0
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 14:58:35,717 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 14:58:35,717 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 14:58:35,717 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slides to show that the calculate glacial glacial glacial , which for almost three million years , has the size of the 40 percent .
2024-05-27 14:58:35,717 - INFO - joeynmt.training - Example #1
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'o@@', 'w@@', 'ned', 'this', ',', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'ist@@', 's', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 14:58:35,717 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 14:58:35,717 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 14:58:35,717 - INFO - joeynmt.training - 	Hypothesis: Towned this , the gravity of the problem because it doesn &apos;t show the spexists of the ice .
2024-05-27 14:58:35,717 - INFO - joeynmt.training - Example #2
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 14:58:35,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 14:58:35,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'p@@', 'at@@', 'h', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Hypothesis: The artic glacial glacial is , in a certain sense , the path of global climate system .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - Example #3
2024-05-27 14:58:35,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 14:58:35,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 14:58:35,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 's', 'around', 'and', 'you', '&apos;re', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expans around and you &apos;re expanded .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - Example #4
2024-05-27 14:58:35,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 14:58:35,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 14:58:35,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rel@@', 'ated', 'r@@', 'ai@@', 'se', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 14:58:35,718 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a related raise of the last 25 years .
2024-05-27 14:58:54,381 - INFO - joeynmt.training - Epoch   4, Step:    15600, Batch Loss:     1.462215, Batch Acc: 0.570875, Tokens per Sec:     3897, Lr: 0.000300
2024-05-27 14:59:14,685 - INFO - joeynmt.training - Epoch   4, Step:    15700, Batch Loss:     1.495387, Batch Acc: 0.573655, Tokens per Sec:     3628, Lr: 0.000300
2024-05-27 14:59:34,521 - INFO - joeynmt.training - Epoch   4, Step:    15800, Batch Loss:     1.549879, Batch Acc: 0.571317, Tokens per Sec:     3677, Lr: 0.000300
2024-05-27 14:59:54,313 - INFO - joeynmt.training - Epoch   4, Step:    15900, Batch Loss:     1.518131, Batch Acc: 0.575924, Tokens per Sec:     3708, Lr: 0.000300
2024-05-27 15:00:14,380 - INFO - joeynmt.training - Epoch   4, Step:    16000, Batch Loss:     1.258005, Batch Acc: 0.574621, Tokens per Sec:     3704, Lr: 0.000300
2024-05-27 15:00:14,381 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:00:14,381 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:01:10,472 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.60, ppl:   4.94, acc:   0.55, generation: 56.0835[sec], evaluation: 0.0000[sec]
2024-05-27 15:01:10,473 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:01:10,600 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/13500.ckpt
2024-05-27 15:01:10,606 - INFO - joeynmt.training - Example #0
2024-05-27 15:01:10,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:01:10,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:01:10,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;ve', 'sho@@', 'wn', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ated', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'h@@', 'o@@', 't', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'l@@', 'ater', ',', 'has', 'the', 'si@@', 'ze', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:01:10,606 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:01:10,606 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:01:10,606 - INFO - joeynmt.training - 	Hypothesis: I &apos;ve shown these slidemonstrated these slidemonstrate that the hot glacial , which for almost three million years later , has the size of 40 percent .
2024-05-27 15:01:10,606 - INFO - joeynmt.training - Example #1
2024-05-27 15:01:10,606 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:01:10,606 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:01:10,606 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['T@@', 'o@@', 'ke', 'this', 'sub@@', 'ject', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'ex@@', 'p@@', 'ect', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Hypothesis: Toke this subject of the gravity of the problem because it doesn &apos;t show the spexexpect of the ice .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - Example #2
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', 'ar@@', 'th@@', 'em@@', 'selves', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Hypothesis: The calculation is arthemselves is , in a sense , the pulsant heart of the global climate system .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - Example #3
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'in@@', 'ver@@', 'su@@', 's', 'around', 'and', 'it', '&apos;s', 'r@@', 'iti@@', 'er', '.', '</s>']
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - 	Hypothesis: It &apos;s inversus around and it &apos;s ritier .
2024-05-27 15:01:10,607 - INFO - joeynmt.training - Example #4
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:01:10,607 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'ach', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:01:10,608 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:01:10,608 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:01:10,608 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable reach of the last 25 years .
2024-05-27 15:01:31,513 - INFO - joeynmt.training - Epoch   4, Step:    16100, Batch Loss:     1.514384, Batch Acc: 0.577926, Tokens per Sec:     3496, Lr: 0.000300
2024-05-27 15:01:52,296 - INFO - joeynmt.training - Epoch   4, Step:    16200, Batch Loss:     1.512339, Batch Acc: 0.570663, Tokens per Sec:     3367, Lr: 0.000300
2024-05-27 15:02:11,747 - INFO - joeynmt.training - Epoch   4, Step:    16300, Batch Loss:     1.386837, Batch Acc: 0.575544, Tokens per Sec:     3680, Lr: 0.000300
2024-05-27 15:02:33,367 - INFO - joeynmt.training - Epoch   4, Step:    16400, Batch Loss:     1.496561, Batch Acc: 0.574758, Tokens per Sec:     3382, Lr: 0.000300
2024-05-27 15:02:53,974 - INFO - joeynmt.training - Epoch   4, Step:    16500, Batch Loss:     1.580674, Batch Acc: 0.573507, Tokens per Sec:     3505, Lr: 0.000300
2024-05-27 15:02:53,975 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:02:53,975 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:03:50,615 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.92, acc:   0.55, generation: 56.6311[sec], evaluation: 0.0000[sec]
2024-05-27 15:03:50,616 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:03:50,743 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/14000.ckpt
2024-05-27 15:03:50,746 - INFO - joeynmt.training - Example #0
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'le', 'c@@', 'alc@@', 'ul@@', 'us', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'ous', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'been', 're@@', 'str@@', 'ic@@', 't', '.', '</s>']
2024-05-27 15:03:50,747 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:03:50,747 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:03:50,747 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the arcle calculus to show that the arctic glacious , which for almost three million years , has been restrict .
2024-05-27 15:03:50,747 - INFO - joeynmt.training - Example #1
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 's@@', 'l@@', 'ate', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:03:50,747 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:03:50,747 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:03:50,747 - INFO - joeynmt.training - 	Hypothesis: However , this slate gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 15:03:50,747 - INFO - joeynmt.training - Example #2
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:03:50,747 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 'l@@', '-@@', 'hear@@', 't', 'cu@@', 'er', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a sense , the pull-heart cuer of global climate system .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - Example #3
2024-05-27 15:03:50,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:03:50,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:03:50,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'be', 'ex@@', 'p@@', 'ec@@', 'ted', 'and', 'the', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to be expected and the summer .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - Example #4
2024-05-27 15:03:50,748 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:03:50,748 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:03:50,748 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:03:50,748 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a record on the last 25 years .
2024-05-27 15:04:10,922 - INFO - joeynmt.training - Epoch   4, Step:    16600, Batch Loss:     1.439990, Batch Acc: 0.566332, Tokens per Sec:     3491, Lr: 0.000300
2024-05-27 15:04:30,797 - INFO - joeynmt.training - Epoch   4, Step:    16700, Batch Loss:     1.485341, Batch Acc: 0.580726, Tokens per Sec:     3628, Lr: 0.000300
2024-05-27 15:04:50,027 - INFO - joeynmt.training - Epoch   4, Step:    16800, Batch Loss:     1.582397, Batch Acc: 0.576106, Tokens per Sec:     3604, Lr: 0.000300
2024-05-27 15:05:09,760 - INFO - joeynmt.training - Epoch   4, Step:    16900, Batch Loss:     1.335387, Batch Acc: 0.577673, Tokens per Sec:     3645, Lr: 0.000300
2024-05-27 15:05:30,042 - INFO - joeynmt.training - Epoch   4, Step:    17000, Batch Loss:     1.501158, Batch Acc: 0.574055, Tokens per Sec:     3567, Lr: 0.000300
2024-05-27 15:05:30,043 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:05:30,043 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:06:24,092 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.90, acc:   0.54, generation: 54.0406[sec], evaluation: 0.0000[sec]
2024-05-27 15:06:24,094 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:06:24,214 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/14500.ckpt
2024-05-27 15:06:24,219 - INFO - joeynmt.training - Example #0
2024-05-27 15:06:24,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:06:24,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:06:24,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'h@@', 'o@@', 't', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'been', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'S@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'you', '&apos;re', 're@@', 'str@@', 'i@@', 'p@@', 'p@@', 'ing', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:06:24,219 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:06:24,219 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:06:24,219 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slides to show that the hot glacial , which for almost three million years , has been the size of 48 S.S. continental continental , you &apos;re restripping of 40 percent .
2024-05-27 15:06:24,219 - INFO - joeynmt.training - Example #1
2024-05-27 15:06:24,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:06:24,219 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:06:24,219 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 's@@', 'l@@', 'it@@', 'al@@', 'ute', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'the', 'sp@@', 'ec@@', 'tru@@', 'm', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:06:24,219 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:06:24,219 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:06:24,219 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a slitalute the gravity of the problem because not shows the spectrum of the ice .
2024-05-27 15:06:24,219 - INFO - joeynmt.training - Example #2
2024-05-27 15:06:24,219 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Hypothesis: The artic glacial is , in a sense , the pulsant heart of the global climate system .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - Example #3
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'get', 'into', 'the', 'sum@@', 'm@@', 'er', 'and', 'you', 'get', 'out', 'of', 'the', 't@@', 'est', '.', '</s>']
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Hypothesis: You get into the summer and you get out of the test .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - Example #4
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:06:24,220 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 're@@', 'cor@@', 'd', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:06:24,220 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable record on the last 25 years .
2024-05-27 15:06:43,690 - INFO - joeynmt.training - Epoch   4, Step:    17100, Batch Loss:     1.328400, Batch Acc: 0.581725, Tokens per Sec:     3745, Lr: 0.000300
2024-05-27 15:07:03,377 - INFO - joeynmt.training - Epoch   4, Step:    17200, Batch Loss:     1.446147, Batch Acc: 0.575666, Tokens per Sec:     3663, Lr: 0.000300
2024-05-27 15:07:22,648 - INFO - joeynmt.training - Epoch   4, Step:    17300, Batch Loss:     1.490583, Batch Acc: 0.579190, Tokens per Sec:     3883, Lr: 0.000300
2024-05-27 15:07:42,182 - INFO - joeynmt.training - Epoch   4, Step:    17400, Batch Loss:     1.338284, Batch Acc: 0.579882, Tokens per Sec:     3767, Lr: 0.000300
2024-05-27 15:08:02,089 - INFO - joeynmt.training - Epoch   4, Step:    17500, Batch Loss:     1.471254, Batch Acc: 0.578659, Tokens per Sec:     3589, Lr: 0.000300
2024-05-27 15:08:02,090 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:08:02,090 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:08:55,065 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.59, ppl:   4.90, acc:   0.54, generation: 52.9676[sec], evaluation: 0.0000[sec]
2024-05-27 15:08:55,066 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:08:55,175 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/15000.ckpt
2024-05-27 15:08:55,179 - INFO - joeynmt.training - Example #0
2024-05-27 15:08:55,179 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:08:55,179 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:08:55,179 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-27 15:08:55,179 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:08:55,179 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:08:55,179 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the calculate glacial glacial , which for almost three million years has the size of the U.S.
2024-05-27 15:08:55,179 - INFO - joeynmt.training - Example #1
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', 'was', 'a', 'lot', 'of', 'the', 'gr@@', 'av@@', 'ity', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'gr@@', 'av@@', 'ity', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Hypothesis: But it was a lot of the gravity because it doesn &apos;t show the gravity because it doesn &apos;t show the ice of the ice .
2024-05-27 15:08:55,180 - INFO - joeynmt.training - Example #2
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'cu@@', 'or', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Hypothesis: The artic glacial is , in a sense , the pulsant cuor the global climate system .
2024-05-27 15:08:55,180 - INFO - joeynmt.training - Example #3
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:08:55,180 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ds', 'and', 'you', 'r@@', 'iti@@', 've', 'r@@', 'iti@@', 'ra', '.', '</s>']
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:08:55,180 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:08:55,181 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expands and you ritive ritira .
2024-05-27 15:08:55,181 - INFO - joeynmt.training - Example #4
2024-05-27 15:08:55,181 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:08:55,181 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:08:55,181 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:08:55,181 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:08:55,181 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:08:55,181 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a record to the last 25 years .
2024-05-27 15:09:14,631 - INFO - joeynmt.training - Epoch   4, Step:    17600, Batch Loss:     1.304235, Batch Acc: 0.577608, Tokens per Sec:     3650, Lr: 0.000300
2024-05-27 15:09:35,030 - INFO - joeynmt.training - Epoch   4, Step:    17700, Batch Loss:     1.484313, Batch Acc: 0.577452, Tokens per Sec:     3473, Lr: 0.000300
2024-05-27 15:09:36,625 - INFO - joeynmt.training - Epoch   4: total training loss 6548.74
2024-05-27 15:09:36,625 - INFO - joeynmt.training - EPOCH 5
2024-05-27 15:09:54,548 - INFO - joeynmt.training - Epoch   5, Step:    17800, Batch Loss:     1.465924, Batch Acc: 0.597212, Tokens per Sec:     3646, Lr: 0.000300
2024-05-27 15:10:16,139 - INFO - joeynmt.training - Epoch   5, Step:    17900, Batch Loss:     1.358946, Batch Acc: 0.600070, Tokens per Sec:     3332, Lr: 0.000300
2024-05-27 15:10:36,434 - INFO - joeynmt.training - Epoch   5, Step:    18000, Batch Loss:     1.216845, Batch Acc: 0.598309, Tokens per Sec:     3538, Lr: 0.000300
2024-05-27 15:10:36,435 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:10:36,435 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:11:30,243 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.58, ppl:   4.87, acc:   0.55, generation: 53.7992[sec], evaluation: 0.0000[sec]
2024-05-27 15:11:30,245 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:11:30,351 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/15500.ckpt
2024-05-27 15:11:30,355 - INFO - joeynmt.training - Example #0
2024-05-27 15:11:30,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:11:30,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:11:30,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'the', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:11:30,355 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:11:30,355 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:11:30,355 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the slide to show that the calculus glacial glacial , which for almost three million years , has the 48 percent .
2024-05-27 15:11:30,355 - INFO - joeynmt.training - Example #1
2024-05-27 15:11:30,355 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:11:30,355 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:11:30,355 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', ',', 'this', 'sub@@', 'ject', 'because', 'it', '&apos;s', 'not', 'sho@@', 'ws', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'g@@', 'a@@', 'p', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:11:30,355 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:11:30,355 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:11:30,355 - INFO - joeynmt.training - 	Hypothesis: But this subject , this subject because it &apos;s not shows the gravity of the gap of the ice .
2024-05-27 15:11:30,355 - INFO - joeynmt.training - Example #2
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 'is', 'ar@@', 't@@', 'ic', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'cu@@', 'e', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Hypothesis: The arten is artic is , in a sense , the pulsant cue of the global climate system .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - Example #3
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'of', 'in@@', 'side', 'and', 'res@@', 'ul@@', 't', 'r@@', 'iti@@', 'ra', '.', '</s>']
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Hypothesis: It expands of inside and result ritira .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - Example #4
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:11:30,356 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'rap@@', 'id', 'p@@', 'y', 're@@', 'mark@@', 'able', 'f@@', 'ul@@', 'ly', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:11:30,356 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid rapid py remarkable fully on the last 25 years .
2024-05-27 15:11:49,714 - INFO - joeynmt.training - Epoch   5, Step:    18100, Batch Loss:     1.291860, Batch Acc: 0.594436, Tokens per Sec:     3694, Lr: 0.000300
2024-05-27 15:12:09,594 - INFO - joeynmt.training - Epoch   5, Step:    18200, Batch Loss:     1.361114, Batch Acc: 0.600165, Tokens per Sec:     3712, Lr: 0.000300
2024-05-27 15:12:29,342 - INFO - joeynmt.training - Epoch   5, Step:    18300, Batch Loss:     1.470214, Batch Acc: 0.596324, Tokens per Sec:     3632, Lr: 0.000300
2024-05-27 15:12:49,943 - INFO - joeynmt.training - Epoch   5, Step:    18400, Batch Loss:     1.595424, Batch Acc: 0.591274, Tokens per Sec:     3468, Lr: 0.000300
2024-05-27 15:13:11,688 - INFO - joeynmt.training - Epoch   5, Step:    18500, Batch Loss:     1.278326, Batch Acc: 0.596211, Tokens per Sec:     3272, Lr: 0.000300
2024-05-27 15:13:11,690 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:13:11,690 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:14:08,895 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.81, acc:   0.55, generation: 57.1966[sec], evaluation: 0.0000[sec]
2024-05-27 15:14:08,897 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:14:09,039 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/16000.ckpt
2024-05-27 15:14:09,042 - INFO - joeynmt.training - Example #0
2024-05-27 15:14:09,042 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:14:09,042 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:14:09,042 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'en', 'g@@', 'l@@', 'ac@@', 'i@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'it', '&apos;s', 're@@', 'cor@@', 'd', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:14:09,042 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:14:09,042 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:14:09,042 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the arten glaciacial glacial , which for almost three million years has had the size of the United States of the United States , it &apos;s record 40 percent .
2024-05-27 15:14:09,042 - INFO - joeynmt.training - Example #1
2024-05-27 15:14:09,042 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a gravity of the gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - Example #2
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 'is', 'ar@@', 'c@@', 'lear@@', 'ly', 'ar@@', 't@@', 'ic', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'cu@@', 'er', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Hypothesis: The arten is arclearly artic is , in a sense , the pulsant cuer of global climate .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - Example #3
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:14:09,043 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'and', 'you', '&apos;re', 'p@@', 'utt@@', 'ing', 'up', '.', '</s>']
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:14:09,043 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded and you &apos;re putting up .
2024-05-27 15:14:09,044 - INFO - joeynmt.training - Example #4
2024-05-27 15:14:09,044 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:14:09,044 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:14:09,044 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'f@@', 'ree', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:14:09,044 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:14:09,044 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:14:09,044 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable free of the last 25 years .
2024-05-27 15:14:29,531 - INFO - joeynmt.training - Epoch   5, Step:    18600, Batch Loss:     1.254821, Batch Acc: 0.595582, Tokens per Sec:     3554, Lr: 0.000300
2024-05-27 15:14:50,078 - INFO - joeynmt.training - Epoch   5, Step:    18700, Batch Loss:     1.427611, Batch Acc: 0.589939, Tokens per Sec:     3592, Lr: 0.000300
2024-05-27 15:15:09,839 - INFO - joeynmt.training - Epoch   5, Step:    18800, Batch Loss:     1.434573, Batch Acc: 0.588990, Tokens per Sec:     3610, Lr: 0.000300
2024-05-27 15:15:29,586 - INFO - joeynmt.training - Epoch   5, Step:    18900, Batch Loss:     1.340101, Batch Acc: 0.596830, Tokens per Sec:     3761, Lr: 0.000300
2024-05-27 15:15:49,725 - INFO - joeynmt.training - Epoch   5, Step:    19000, Batch Loss:     1.396568, Batch Acc: 0.592799, Tokens per Sec:     3539, Lr: 0.000300
2024-05-27 15:15:49,726 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:15:49,726 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:16:47,243 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.57, ppl:   4.83, acc:   0.55, generation: 57.5089[sec], evaluation: 0.0000[sec]
2024-05-27 15:16:47,364 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/16500.ckpt
2024-05-27 15:16:47,369 - INFO - joeynmt.training - Example #0
2024-05-27 15:16:47,369 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:16:47,369 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:16:47,369 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ation', 'to', 'show', 'that', 'the', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'the', 'U@@', '.@@', 'S@@', '.', '</s>']
2024-05-27 15:16:47,369 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:16:47,369 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:16:47,369 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slides to show that the calculation to show that the glacial glacial , which for almost three million years , has the U.S.
2024-05-27 15:16:47,369 - INFO - joeynmt.training - Example #1
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['So', ',', 'this', 'is', 'a', 's@@', 'li@@', 'gh@@', 'tly', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'pen@@', 'si@@', 've', '.', '</s>']
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Hypothesis: So , this is a slightly the gravity of the problem because it doesn &apos;t show the spexpensive .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - Example #2
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Hypothesis: The artic calculation is , in a sense , the pulsing heart of the global climate system .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - Example #3
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'be', 'ex@@', 'pan@@', 'ded', 'and', 'the', 't@@', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to be expanded and the texpanded .
2024-05-27 15:16:47,370 - INFO - joeynmt.training - Example #4
2024-05-27 15:16:47,370 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:16:47,371 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:16:47,371 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rel@@', 'ated', 'f@@', 'ast', 'car@@', 'l@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:16:47,371 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:16:47,371 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:16:47,371 - INFO - joeynmt.training - 	Hypothesis: The next slilide is going to be a related fast carled on the last 25 years .
2024-05-27 15:17:06,650 - INFO - joeynmt.training - Epoch   5, Step:    19100, Batch Loss:     1.317599, Batch Acc: 0.591462, Tokens per Sec:     3748, Lr: 0.000300
2024-05-27 15:17:26,631 - INFO - joeynmt.training - Epoch   5, Step:    19200, Batch Loss:     1.491838, Batch Acc: 0.587059, Tokens per Sec:     3556, Lr: 0.000300
2024-05-27 15:17:46,691 - INFO - joeynmt.training - Epoch   5, Step:    19300, Batch Loss:     1.233478, Batch Acc: 0.590735, Tokens per Sec:     3647, Lr: 0.000300
2024-05-27 15:18:06,170 - INFO - joeynmt.training - Epoch   5, Step:    19400, Batch Loss:     1.383784, Batch Acc: 0.597786, Tokens per Sec:     3841, Lr: 0.000300
2024-05-27 15:18:26,247 - INFO - joeynmt.training - Epoch   5, Step:    19500, Batch Loss:     1.570249, Batch Acc: 0.591572, Tokens per Sec:     3619, Lr: 0.000300
2024-05-27 15:18:26,248 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:18:26,248 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:19:24,949 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.72, acc:   0.56, generation: 58.6930[sec], evaluation: 0.0000[sec]
2024-05-27 15:19:24,952 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:19:25,100 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/17000.ckpt
2024-05-27 15:19:25,104 - INFO - joeynmt.training - Example #0
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'alc@@', 'ul@@', 'ation', ',', 'which', 'is', 'al@@', 'most', 'three', 'million', 'years', ',', 'and', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:19:25,105 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:19:25,105 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:19:25,105 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to demonstrate that the cotta calculation , which is almost three million years , and for almost three million years , has the size of 48 percent .
2024-05-27 15:19:25,105 - INFO - joeynmt.training - Example #1
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'lot', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:19:25,105 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:19:25,105 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:19:25,105 - INFO - joeynmt.training - 	Hypothesis: But this is a lot of the gravity of the problem because it doesn &apos;t show the spessor of the ice .
2024-05-27 15:19:25,105 - INFO - joeynmt.training - Example #2
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:19:25,105 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 't@@', 'y@@', 'pic@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'he@@', 'al@@', 'th', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Hypothesis: The arten typical glacial is , in a sense , the health of global climate system .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - Example #3
2024-05-27 15:19:25,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:19:25,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:19:25,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'w@@', 'in@@', 'ter', 'and', 'it', '&apos;s', 'r@@', 'iti@@', 'ical', 'and', 'it', '&apos;s', 'r@@', 'iti@@', 'z@@', 'en@@', 's', '.', '</s>']
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Hypothesis: It &apos;s winter and it &apos;s ritiical and it &apos;s ritizens .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - Example #4
2024-05-27 15:19:25,106 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:19:25,106 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:19:25,106 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', '-@@', 'rel@@', 'ated', 'f@@', 'oun@@', 'd@@', 'ary', 'for', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:19:25,106 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a re-related foundary for the last 25 years .
2024-05-27 15:19:44,341 - INFO - joeynmt.training - Epoch   5, Step:    19600, Batch Loss:     1.437719, Batch Acc: 0.598374, Tokens per Sec:     3775, Lr: 0.000300
2024-05-27 15:20:04,107 - INFO - joeynmt.training - Epoch   5, Step:    19700, Batch Loss:     1.237756, Batch Acc: 0.592439, Tokens per Sec:     3739, Lr: 0.000300
2024-05-27 15:20:24,663 - INFO - joeynmt.training - Epoch   5, Step:    19800, Batch Loss:     1.407081, Batch Acc: 0.594219, Tokens per Sec:     3486, Lr: 0.000300
2024-05-27 15:20:45,167 - INFO - joeynmt.training - Epoch   5, Step:    19900, Batch Loss:     1.416114, Batch Acc: 0.594627, Tokens per Sec:     3582, Lr: 0.000300
2024-05-27 15:21:05,247 - INFO - joeynmt.training - Epoch   5, Step:    20000, Batch Loss:     1.567992, Batch Acc: 0.588821, Tokens per Sec:     3649, Lr: 0.000300
2024-05-27 15:21:05,248 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:21:05,248 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:22:02,084 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.56, ppl:   4.76, acc:   0.55, generation: 56.8274[sec], evaluation: 0.0000[sec]
2024-05-27 15:22:02,204 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/17500.ckpt
2024-05-27 15:22:02,207 - INFO - joeynmt.training - Example #0
2024-05-27 15:22:02,207 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:22:02,207 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:22:02,207 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', '&apos;ve', 'sho@@', 'wn', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:22:02,207 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:22:02,207 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:22:02,207 - INFO - joeynmt.training - 	Hypothesis: The year I &apos;ve shown these slides to show that the calculate glacial glacial , which for almost three million years has the size of 48 percent .
2024-05-27 15:22:02,207 - INFO - joeynmt.training - Example #1
2024-05-27 15:22:02,208 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:22:02,208 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:22:02,208 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', ',', 'I', '&apos;m', 'going', 'to', 'show', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ect', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:22:02,208 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:22:02,208 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:22:02,208 - INFO - joeynmt.training - 	Hypothesis: But this is , I &apos;m going to show the gravity of the problem because it doesn &apos;t show the spexpect of the ice .
2024-05-27 15:22:02,208 - INFO - joeynmt.training - Example #2
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'he@@', 'ad@@', 's', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Hypothesis: The artic heads is , in a sense , the pulsant heart of the global climate .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - Example #3
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'of', 'in@@', 'side', 'and', 're@@', 'iti@@', 've', 're@@', 'iti@@', 've', 'ex@@', 'pan@@', 'ded', '.', '</s>']
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Hypothesis: It expands of inside and reitive reitive expanded .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - Example #4
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:22:02,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:22:02,209 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a record to the last 25 years .
2024-05-27 15:22:22,321 - INFO - joeynmt.training - Epoch   5, Step:    20100, Batch Loss:     1.355216, Batch Acc: 0.589170, Tokens per Sec:     3536, Lr: 0.000300
2024-05-27 15:22:41,944 - INFO - joeynmt.training - Epoch   5, Step:    20200, Batch Loss:     1.475199, Batch Acc: 0.590051, Tokens per Sec:     3760, Lr: 0.000300
2024-05-27 15:23:03,380 - INFO - joeynmt.training - Epoch   5, Step:    20300, Batch Loss:     1.430086, Batch Acc: 0.597771, Tokens per Sec:     3353, Lr: 0.000300
2024-05-27 15:23:23,528 - INFO - joeynmt.training - Epoch   5, Step:    20400, Batch Loss:     1.299232, Batch Acc: 0.592972, Tokens per Sec:     3615, Lr: 0.000300
2024-05-27 15:23:43,298 - INFO - joeynmt.training - Epoch   5, Step:    20500, Batch Loss:     1.429538, Batch Acc: 0.594365, Tokens per Sec:     3618, Lr: 0.000300
2024-05-27 15:23:43,299 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:23:43,299 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:24:40,230 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.71, acc:   0.56, generation: 56.9226[sec], evaluation: 0.0000[sec]
2024-05-27 15:24:40,232 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:24:40,360 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/18000.ckpt
2024-05-27 15:24:40,366 - INFO - joeynmt.training - Example #0
2024-05-27 15:24:40,366 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:24:40,366 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:24:40,366 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ated', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'dimen@@', 'si@@', 'ons', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:24:40,366 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:24:40,366 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrated to demonstrate that the calculus , which for almost three million years , has had the dimensions of 48 percent .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - Example #1
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:24:40,367 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - 	Hypothesis: But this is a gravity of the problem because it doesn &apos;t show the gravity of the ice of the ice .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - Example #2
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 't@@', 'ica', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 15:24:40,367 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - 	Hypothesis: The arten tica glacial is , in a sense , the pulser of the global climate .
2024-05-27 15:24:40,367 - INFO - joeynmt.training - Example #3
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:24:40,367 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'ex@@', 'pan@@', 'ds', 'and', 'you', '&apos;re', 't@@', 'y@@', 'pic@@', 'ally', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 15:24:40,368 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:24:40,368 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:24:40,368 - INFO - joeynmt.training - 	Hypothesis: You &apos;re expands and you &apos;re typically retreatment .
2024-05-27 15:24:40,368 - INFO - joeynmt.training - Example #4
2024-05-27 15:24:40,368 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:24:40,368 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:24:40,368 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'rap@@', 'id', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:24:40,368 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:24:40,368 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:24:40,368 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable rapid carried on the last 25 years .
2024-05-27 15:25:01,059 - INFO - joeynmt.training - Epoch   5, Step:    20600, Batch Loss:     1.364618, Batch Acc: 0.591617, Tokens per Sec:     3446, Lr: 0.000300
2024-05-27 15:25:23,901 - INFO - joeynmt.training - Epoch   5, Step:    20700, Batch Loss:     1.359561, Batch Acc: 0.584559, Tokens per Sec:     3089, Lr: 0.000300
2024-05-27 15:25:45,235 - INFO - joeynmt.training - Epoch   5, Step:    20800, Batch Loss:     1.449854, Batch Acc: 0.591944, Tokens per Sec:     3375, Lr: 0.000300
2024-05-27 15:26:06,540 - INFO - joeynmt.training - Epoch   5, Step:    20900, Batch Loss:     1.509423, Batch Acc: 0.587880, Tokens per Sec:     3392, Lr: 0.000300
2024-05-27 15:26:27,043 - INFO - joeynmt.training - Epoch   5, Step:    21000, Batch Loss:     1.525368, Batch Acc: 0.591171, Tokens per Sec:     3509, Lr: 0.000300
2024-05-27 15:26:27,044 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:26:27,044 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:27:21,956 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.55, ppl:   4.70, acc:   0.56, generation: 54.9033[sec], evaluation: 0.0000[sec]
2024-05-27 15:27:21,958 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:27:22,098 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/19000.ckpt
2024-05-27 15:27:22,101 - INFO - joeynmt.training - Example #0
2024-05-27 15:27:22,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:27:22,102 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:27:22,102 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:27:22,102 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrate glacial glacial glacial glacial , which for almost three million years , has had the size of the 40 percent .
2024-05-27 15:27:22,102 - INFO - joeynmt.training - Example #1
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', 'this', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'in', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:27:22,102 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:27:22,102 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:27:22,102 - INFO - joeynmt.training - 	Hypothesis: However this is the gravity of the problem because it doesn &apos;t show it in the ice of the ice .
2024-05-27 15:27:22,102 - INFO - joeynmt.training - Example #2
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:27:22,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 't@@', 'y@@', 'al', 'c@@', 'lim@@', 'ate', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'p@@', 'ul@@', 'l', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Hypothesis: The arten tyal climate is , in a certain sense , the pull of the global climate system .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - Example #3
2024-05-27 15:27:22,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:27:22,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:27:22,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'w@@', 'in@@', 'ter', 'and', 're@@', 'ver@@', 's@@', 'ing', 'r@@', 'iti@@', 've', 'ex@@', 'p@@', 'ed', '.', '</s>']
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to winter and reversing ritive exped .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - Example #4
2024-05-27 15:27:22,103 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:27:22,103 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:27:22,103 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'ad', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:27:22,103 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a remarkable read of the last 25 years .
2024-05-27 15:27:43,535 - INFO - joeynmt.training - Epoch   5, Step:    21100, Batch Loss:     1.529560, Batch Acc: 0.592109, Tokens per Sec:     3378, Lr: 0.000300
2024-05-27 15:28:04,990 - INFO - joeynmt.training - Epoch   5, Step:    21200, Batch Loss:     1.234857, Batch Acc: 0.590464, Tokens per Sec:     3354, Lr: 0.000300
2024-05-27 15:28:26,262 - INFO - joeynmt.training - Epoch   5, Step:    21300, Batch Loss:     1.343657, Batch Acc: 0.590968, Tokens per Sec:     3343, Lr: 0.000300
2024-05-27 15:28:46,680 - INFO - joeynmt.training - Epoch   5, Step:    21400, Batch Loss:     1.461908, Batch Acc: 0.593333, Tokens per Sec:     3637, Lr: 0.000300
2024-05-27 15:29:07,492 - INFO - joeynmt.training - Epoch   5, Step:    21500, Batch Loss:     1.410226, Batch Acc: 0.596862, Tokens per Sec:     3485, Lr: 0.000300
2024-05-27 15:29:07,493 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:29:07,493 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:30:10,571 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.66, acc:   0.56, generation: 63.0661[sec], evaluation: 0.0000[sec]
2024-05-27 15:30:10,573 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:30:10,712 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/18500.ckpt
2024-05-27 15:30:10,716 - INFO - joeynmt.training - Example #0
2024-05-27 15:30:10,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:30:10,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:30:10,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;ve', 'sho@@', 'wn', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'of', 'the', '4@@', '8', 'dimen@@', 'si@@', 'ons', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Hypothesis: I &apos;ve shown these slidemonstrate to demonstrate that the calculus to show that the calculus of the 48 dimensions of the United States had the size of 48 percent .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - Example #1
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', ',', 'that', 'you', 'can', 'see', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Hypothesis: But this is , that you can see the gravity of the problem because it &apos;s not showing the ice of the ice .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - Example #2
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a sense , the heart heart heart of the global climate system .
2024-05-27 15:30:10,717 - INFO - joeynmt.training - Example #3
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:30:10,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'be', 'ex@@', 'pan@@', 'ded', 'and', 're@@', 'tur@@', 'n', '.', '</s>']
2024-05-27 15:30:10,718 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:30:10,718 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:30:10,718 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to be expanded and return .
2024-05-27 15:30:10,718 - INFO - joeynmt.training - Example #4
2024-05-27 15:30:10,718 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:30:10,718 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:30:10,718 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'en', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:30:10,718 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:30:10,718 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:30:10,718 - INFO - joeynmt.training - 	Hypothesis: The next next slide is going to be a remarkable reen to the last 25 years .
2024-05-27 15:30:34,654 - INFO - joeynmt.training - Epoch   5, Step:    21600, Batch Loss:     1.480306, Batch Acc: 0.591581, Tokens per Sec:     2991, Lr: 0.000300
2024-05-27 15:30:57,949 - INFO - joeynmt.training - Epoch   5, Step:    21700, Batch Loss:     1.433713, Batch Acc: 0.590926, Tokens per Sec:     3105, Lr: 0.000300
2024-05-27 15:31:24,111 - INFO - joeynmt.training - Epoch   5, Step:    21800, Batch Loss:     1.636390, Batch Acc: 0.591249, Tokens per Sec:     2768, Lr: 0.000300
2024-05-27 15:31:46,153 - INFO - joeynmt.training - Epoch   5, Step:    21900, Batch Loss:     1.350091, Batch Acc: 0.595685, Tokens per Sec:     3325, Lr: 0.000300
2024-05-27 15:32:07,132 - INFO - joeynmt.training - Epoch   5, Step:    22000, Batch Loss:     1.134977, Batch Acc: 0.589614, Tokens per Sec:     3459, Lr: 0.000300
2024-05-27 15:32:07,134 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:32:07,134 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:33:02,948 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.54, ppl:   4.66, acc:   0.56, generation: 55.8063[sec], evaluation: 0.0000[sec]
2024-05-27 15:33:03,110 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/20000.ckpt
2024-05-27 15:33:03,119 - INFO - joeynmt.training - Example #0
2024-05-27 15:33:03,119 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:33:03,119 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:33:03,119 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ations', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ations', 'of', 'ar@@', 'c@@', 'ti@@', 'c', ',', 'which', 'is', 'about', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:33:03,119 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the calculations to show that the calculations of arctic , which is about 48 percent .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - Example #1
2024-05-27 15:33:03,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:33:03,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:33:03,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'lot', 'of', 'this', 'sub@@', 'ject', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'in', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a lot of this subject of the problem because it doesn &apos;t show it in the ice of the ice .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - Example #2
2024-05-27 15:33:03,120 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:33:03,120 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:33:03,120 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'age', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - 	Hypothesis: The artage glacial is , in a sense , the heart heart of the global climate system .
2024-05-27 15:33:03,120 - INFO - joeynmt.training - Example #3
2024-05-27 15:33:03,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:33:03,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:33:03,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'w@@', 'in@@', 'ter', 'and', 'it', '&apos;s', 'r@@', 'iti@@', 'er', '.', '</s>']
2024-05-27 15:33:03,121 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:33:03,121 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:33:03,121 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to winter and it &apos;s ritier .
2024-05-27 15:33:03,121 - INFO - joeynmt.training - Example #4
2024-05-27 15:33:03,121 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:33:03,121 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:33:03,121 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'a', 'qu@@', 'ic@@', 'k@@', 'ly', 'car@@', 'ri@@', 'ed', 'on', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:33:03,121 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:33:03,121 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:33:03,121 - INFO - joeynmt.training - 	Hypothesis: The next slide is a quickly carried on on the last 25 years .
2024-05-27 15:33:23,675 - INFO - joeynmt.training - Epoch   5, Step:    22100, Batch Loss:     1.279845, Batch Acc: 0.593769, Tokens per Sec:     3412, Lr: 0.000300
2024-05-27 15:33:28,954 - INFO - joeynmt.training - Epoch   5: total training loss 6217.06
2024-05-27 15:33:28,954 - INFO - joeynmt.training - EPOCH 6
2024-05-27 15:33:44,272 - INFO - joeynmt.training - Epoch   6, Step:    22200, Batch Loss:     1.395369, Batch Acc: 0.611019, Tokens per Sec:     3522, Lr: 0.000300
2024-05-27 15:34:05,856 - INFO - joeynmt.training - Epoch   6, Step:    22300, Batch Loss:     1.134361, Batch Acc: 0.615496, Tokens per Sec:     3341, Lr: 0.000300
2024-05-27 15:34:27,598 - INFO - joeynmt.training - Epoch   6, Step:    22400, Batch Loss:     1.550301, Batch Acc: 0.618207, Tokens per Sec:     3453, Lr: 0.000300
2024-05-27 15:34:47,865 - INFO - joeynmt.training - Epoch   6, Step:    22500, Batch Loss:     1.507445, Batch Acc: 0.612839, Tokens per Sec:     3623, Lr: 0.000300
2024-05-27 15:34:47,866 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:34:47,866 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:35:49,429 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.56, generation: 61.5529[sec], evaluation: 0.0000[sec]
2024-05-27 15:35:49,430 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:35:49,558 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/19500.ckpt
2024-05-27 15:35:49,562 - INFO - joeynmt.training - Example #0
2024-05-27 15:35:49,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:35:49,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:35:49,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ations', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'c@@', 'le@@', 'an', 'is', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', ',', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', '.', 'The', 'next', 'year', ',', 'is', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:35:49,562 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:35:49,562 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:35:49,562 - INFO - joeynmt.training - 	Hypothesis: I showed these slide to show that slide to show that the calculations to demonstrate that clean is 48 United States , the size of 48 United States . The next year , is 40 percent .
2024-05-27 15:35:49,562 - INFO - joeynmt.training - Example #1
2024-05-27 15:35:49,562 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:35:49,562 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:35:49,562 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', ',', 'I', '&apos;m', 'going', 'to', 'be', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'wing', 'the', 'sp@@', 'ex@@', 'ist@@', 'ing', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:35:49,562 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:35:49,562 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:35:49,562 - INFO - joeynmt.training - 	Hypothesis: But this is , I &apos;m going to be the gravity of the problem because not showing the spexisting of the ice .
2024-05-27 15:35:49,562 - INFO - joeynmt.training - Example #2
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'c@@', 'le@@', 'ar', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Hypothesis: The artic clear is , in a certain sense , the heart heart of the global climate system .
2024-05-27 15:35:49,563 - INFO - joeynmt.training - Example #3
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'up', 'and', 'the', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded up and the summer .
2024-05-27 15:35:49,563 - INFO - joeynmt.training - Example #4
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:35:49,563 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ic@@', 'k@@', 'ly', 're@@', 'cor@@', 'd', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:35:49,563 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:35:49,564 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quickly record on the last 25 years .
2024-05-27 15:36:09,979 - INFO - joeynmt.training - Epoch   6, Step:    22600, Batch Loss:     1.469000, Batch Acc: 0.610472, Tokens per Sec:     3613, Lr: 0.000300
2024-05-27 15:36:30,415 - INFO - joeynmt.training - Epoch   6, Step:    22700, Batch Loss:     1.140881, Batch Acc: 0.616439, Tokens per Sec:     3485, Lr: 0.000300
2024-05-27 15:36:50,830 - INFO - joeynmt.training - Epoch   6, Step:    22800, Batch Loss:     1.342649, Batch Acc: 0.607056, Tokens per Sec:     3434, Lr: 0.000300
2024-05-27 15:37:11,438 - INFO - joeynmt.training - Epoch   6, Step:    22900, Batch Loss:     1.230530, Batch Acc: 0.606302, Tokens per Sec:     3474, Lr: 0.000300
2024-05-27 15:37:32,238 - INFO - joeynmt.training - Epoch   6, Step:    23000, Batch Loss:     1.459875, Batch Acc: 0.603749, Tokens per Sec:     3386, Lr: 0.000300
2024-05-27 15:37:32,239 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:37:32,239 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:38:33,680 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.64, acc:   0.56, generation: 61.4328[sec], evaluation: 0.0000[sec]
2024-05-27 15:38:33,792 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/20500.ckpt
2024-05-27 15:38:33,795 - INFO - joeynmt.training - Example #0
2024-05-27 15:38:33,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:38:33,795 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:38:33,795 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'is', 'ar@@', 'c@@', 'ti@@', 'c', 'ar@@', 't@@', 'ics', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:38:33,795 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:38:33,795 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:38:33,795 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to demonstrate that the calculus is arctic artics , which for almost three million years has had the size of 48 percent .
2024-05-27 15:38:33,795 - INFO - joeynmt.training - Example #1
2024-05-27 15:38:33,795 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:38:33,795 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:38:33,795 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', ',', 'this', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:38:33,795 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Hypothesis: But this is , this is the gravity of the problem because not shows the ice of the ice of the ice of the ice .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - Example #2
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'he@@', 'at', 'is', 'ar@@', 't@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Hypothesis: The artic heat is artic glacial is , in a sense , the heart heart heart heart of the global climate system .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - Example #3
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'w@@', 'in@@', 'ter', 'in@@', 'side', 'and', 'it', '&apos;s', 'r@@', 'iti@@', 'ra', '.', '</s>']
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Hypothesis: It &apos;s winter inside and it &apos;s ritira .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - Example #4
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:38:33,796 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'rap@@', 'id', 'in', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:38:33,796 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:38:33,797 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable rapid in the last 25 years .
2024-05-27 15:38:56,006 - INFO - joeynmt.training - Epoch   6, Step:    23100, Batch Loss:     1.319419, Batch Acc: 0.606644, Tokens per Sec:     3211, Lr: 0.000300
2024-05-27 15:39:17,422 - INFO - joeynmt.training - Epoch   6, Step:    23200, Batch Loss:     1.303313, Batch Acc: 0.601588, Tokens per Sec:     3369, Lr: 0.000300
2024-05-27 15:39:38,570 - INFO - joeynmt.training - Epoch   6, Step:    23300, Batch Loss:     1.239834, Batch Acc: 0.607511, Tokens per Sec:     3451, Lr: 0.000300
2024-05-27 15:39:58,988 - INFO - joeynmt.training - Epoch   6, Step:    23400, Batch Loss:     1.484606, Batch Acc: 0.607789, Tokens per Sec:     3500, Lr: 0.000300
2024-05-27 15:40:19,922 - INFO - joeynmt.training - Epoch   6, Step:    23500, Batch Loss:     1.348553, Batch Acc: 0.611918, Tokens per Sec:     3462, Lr: 0.000300
2024-05-27 15:40:19,922 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:40:19,922 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:41:21,303 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.53, ppl:   4.61, acc:   0.56, generation: 61.3717[sec], evaluation: 0.0000[sec]
2024-05-27 15:41:21,448 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/21000.ckpt
2024-05-27 15:41:21,451 - INFO - joeynmt.training - Example #0
2024-05-27 15:41:21,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:41:21,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:41:21,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 't@@', 'age', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'alc@@', 'ul@@', 'us', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'cor@@', 'd@@', '-@@', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:41:21,451 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:41:21,451 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:41:21,451 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the artage to show that the cotta calculus , which for almost three million years , has had the size of the U.S. continental continental , it &apos;s record-40 percent .
2024-05-27 15:41:21,451 - INFO - joeynmt.training - Example #1
2024-05-27 15:41:21,451 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:41:21,451 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:41:21,451 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'under@@', 'es@@', 'tim@@', 'ate', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Hypothesis: However , this underestimate the gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - Example #2
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'age', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Hypothesis: The artage calculation is , in a sense , the pulsant heart of the global climate system .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - Example #3
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'w@@', 'in@@', 'ter', 'and', 're@@', 'ver@@', 's@@', 'ing', 'r@@', 'iti@@', 'ra', '.', '</s>']
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - 	Hypothesis: It &apos;s winter and reversing ritira .
2024-05-27 15:41:21,452 - INFO - joeynmt.training - Example #4
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:41:21,452 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'gi@@', 'onal', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:41:21,453 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:41:21,453 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:41:21,453 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a regional carried on the last 25 years .
2024-05-27 15:41:44,774 - INFO - joeynmt.training - Epoch   6, Step:    23600, Batch Loss:     1.416844, Batch Acc: 0.605778, Tokens per Sec:     3061, Lr: 0.000300
2024-05-27 15:42:06,065 - INFO - joeynmt.training - Epoch   6, Step:    23700, Batch Loss:     1.481422, Batch Acc: 0.602570, Tokens per Sec:     3341, Lr: 0.000300
2024-05-27 15:42:29,439 - INFO - joeynmt.training - Epoch   6, Step:    23800, Batch Loss:     1.214477, Batch Acc: 0.607639, Tokens per Sec:     3163, Lr: 0.000300
2024-05-27 15:42:50,445 - INFO - joeynmt.training - Epoch   6, Step:    23900, Batch Loss:     1.424567, Batch Acc: 0.604163, Tokens per Sec:     3397, Lr: 0.000300
2024-05-27 15:43:11,066 - INFO - joeynmt.training - Epoch   6, Step:    24000, Batch Loss:     1.425338, Batch Acc: 0.602899, Tokens per Sec:     3476, Lr: 0.000300
2024-05-27 15:43:11,069 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:43:11,069 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:44:08,094 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.59, acc:   0.56, generation: 57.0158[sec], evaluation: 0.0000[sec]
2024-05-27 15:44:08,096 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:44:08,206 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/22000.ckpt
2024-05-27 15:44:08,209 - INFO - joeynmt.training - Example #0
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'of', 'ar@@', 't@@', 'ic', 'ar@@', 'c@@', 'ti@@', 'c', ',', 'which', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:44:08,210 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:44:08,210 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:44:08,210 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrate to demonstrate that the calculus of artic arctic , which almost three million years has had the size of 48 percent .
2024-05-27 15:44:08,210 - INFO - joeynmt.training - Example #1
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'to', 'be', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'sho@@', 'ws', 'the', 'sp@@', 'ex@@', 'hi@@', 'b@@', 'ition', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:44:08,210 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:44:08,210 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:44:08,210 - INFO - joeynmt.training - 	Hypothesis: But this is to be the gravity of the problem because not shows the spexhibition of the ice .
2024-05-27 15:44:08,210 - INFO - joeynmt.training - Example #2
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:44:08,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 't@@', 'y@@', 'pic@@', 'al', 'c@@', 'le@@', 'an', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 15:44:08,210 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Hypothesis: The arten typical clean is , in a sense , the pulsant , the pulsant heart of the global climate .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - Example #3
2024-05-27 15:44:08,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:44:08,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:44:08,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'w@@', 'in@@', 'ter', 'and', 'it', 'r@@', 'iti@@', 's', '.', '</s>']
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Hypothesis: You &apos;re winter and it ritis .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - Example #4
2024-05-27 15:44:08,211 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:44:08,211 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:44:08,211 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de@@', 's', 'is', 'going', 'to', 'be', 'a', 'f@@', 'ast@@', 'er', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:44:08,211 - INFO - joeynmt.training - 	Hypothesis: The next slides is going to be a faster of the last 25 years .
2024-05-27 15:44:28,161 - INFO - joeynmt.training - Epoch   6, Step:    24100, Batch Loss:     1.449515, Batch Acc: 0.611805, Tokens per Sec:     3713, Lr: 0.000300
2024-05-27 15:44:47,884 - INFO - joeynmt.training - Epoch   6, Step:    24200, Batch Loss:     1.323745, Batch Acc: 0.607358, Tokens per Sec:     3694, Lr: 0.000300
2024-05-27 15:45:07,767 - INFO - joeynmt.training - Epoch   6, Step:    24300, Batch Loss:     1.243761, Batch Acc: 0.605193, Tokens per Sec:     3533, Lr: 0.000300
2024-05-27 15:45:27,979 - INFO - joeynmt.training - Epoch   6, Step:    24400, Batch Loss:     1.334221, Batch Acc: 0.601027, Tokens per Sec:     3594, Lr: 0.000300
2024-05-27 15:45:47,948 - INFO - joeynmt.training - Epoch   6, Step:    24500, Batch Loss:     1.322185, Batch Acc: 0.607812, Tokens per Sec:     3604, Lr: 0.000300
2024-05-27 15:45:47,949 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:45:47,949 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:46:45,241 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.59, acc:   0.56, generation: 57.2842[sec], evaluation: 0.0000[sec]
2024-05-27 15:46:45,359 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/21500.ckpt
2024-05-27 15:46:45,361 - INFO - joeynmt.training - Example #0
2024-05-27 15:46:45,361 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:46:45,361 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:46:45,361 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 'th@@', 'ic', 'c@@', 'alc@@', 'ul@@', 'ations', 'to', 'show', 'that', 'the', 'ar@@', 'th@@', 'em@@', 'selves', 'of', '4@@', '8', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'The', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', ',', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', '.', '</s>']
2024-05-27 15:46:45,361 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slide to show that the arthic calculations to show that the arthemselves of 48 percent of the U.S. The 48 United States , the 48 continental .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - Example #1
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', '&apos;s', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Hypothesis: But it &apos;s a gravity of the problem because it doesn &apos;t show the ice of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - Example #2
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'th@@', 'i@@', 'al', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'cu@@', 'er', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Hypothesis: The arthial calculation is , in a certain sense , the pulsant cuer of global climate system .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - Example #3
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:46:45,362 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'of', 'the', 'w@@', 'in@@', 'ter', 'and', 'it', 'r@@', 'iti@@', 'es', '.', '</s>']
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:46:45,362 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:46:45,363 - INFO - joeynmt.training - 	Hypothesis: It expands of the winter and it rities .
2024-05-27 15:46:45,363 - INFO - joeynmt.training - Example #4
2024-05-27 15:46:45,363 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:46:45,363 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:46:45,363 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'rap@@', 'id', 'car@@', 'rel@@', 'ated', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:46:45,363 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:46:45,363 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:46:45,363 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid rapid carrelated to the last 25 years .
2024-05-27 15:47:04,954 - INFO - joeynmt.training - Epoch   6, Step:    24600, Batch Loss:     1.363994, Batch Acc: 0.606089, Tokens per Sec:     3767, Lr: 0.000300
2024-05-27 15:47:24,442 - INFO - joeynmt.training - Epoch   6, Step:    24700, Batch Loss:     1.402530, Batch Acc: 0.600599, Tokens per Sec:     3666, Lr: 0.000300
2024-05-27 15:47:44,189 - INFO - joeynmt.training - Epoch   6, Step:    24800, Batch Loss:     1.293010, Batch Acc: 0.602161, Tokens per Sec:     3557, Lr: 0.000300
2024-05-27 15:48:04,027 - INFO - joeynmt.training - Epoch   6, Step:    24900, Batch Loss:     1.293827, Batch Acc: 0.605277, Tokens per Sec:     3642, Lr: 0.000300
2024-05-27 15:48:24,056 - INFO - joeynmt.training - Epoch   6, Step:    25000, Batch Loss:     1.471277, Batch Acc: 0.605030, Tokens per Sec:     3570, Lr: 0.000300
2024-05-27 15:48:24,057 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:48:24,057 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:49:22,146 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.52, ppl:   4.56, acc:   0.57, generation: 58.0805[sec], evaluation: 0.0000[sec]
2024-05-27 15:49:22,148 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:49:22,265 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/23000.ckpt
2024-05-27 15:49:22,267 - INFO - joeynmt.training - Example #0
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'lim@@', 'b@@', 'ing', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', ',', 'it', 'was', 're@@', 'str@@', 'e@@', 'et', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:49:22,267 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:49:22,267 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:49:22,267 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the cotta climbing the arctic calotta , which for almost three million years , has had the size of 48 United States , it was restreet of 40 percent .
2024-05-27 15:49:22,267 - INFO - joeynmt.training - Example #1
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'lot', 'of', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:49:22,267 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:49:22,267 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:49:22,267 - INFO - joeynmt.training - 	Hypothesis: But this is a lot of the gravity of the problem because it doesn &apos;t show the spent of the ice .
2024-05-27 15:49:22,267 - INFO - joeynmt.training - Example #2
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:49:22,267 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'c@@', 'le@@', 'ar', 'cu@@', 'er', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'system', '.', '</s>']
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a sense , the clear cuer , the heart heart of the global system .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - Example #3
2024-05-27 15:49:22,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:49:22,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:49:22,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'ex@@', 'p@@', 'and@@', 'ing', 'and', 'it', 'up', '.', '</s>']
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Hypothesis: You &apos;re expanding and it up .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - Example #4
2024-05-27 15:49:22,268 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:49:22,268 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:49:22,268 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'rel@@', 'ated', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:49:22,268 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a recorrelated to the last 25 years .
2024-05-27 15:49:41,677 - INFO - joeynmt.training - Epoch   6, Step:    25100, Batch Loss:     1.190370, Batch Acc: 0.604515, Tokens per Sec:     3679, Lr: 0.000300
2024-05-27 15:50:01,270 - INFO - joeynmt.training - Epoch   6, Step:    25200, Batch Loss:     1.322890, Batch Acc: 0.602358, Tokens per Sec:     3662, Lr: 0.000300
2024-05-27 15:50:21,251 - INFO - joeynmt.training - Epoch   6, Step:    25300, Batch Loss:     1.307032, Batch Acc: 0.608066, Tokens per Sec:     3647, Lr: 0.000300
2024-05-27 15:50:41,479 - INFO - joeynmt.training - Epoch   6, Step:    25400, Batch Loss:     1.316090, Batch Acc: 0.606762, Tokens per Sec:     3560, Lr: 0.000300
2024-05-27 15:51:01,388 - INFO - joeynmt.training - Epoch   6, Step:    25500, Batch Loss:     1.323874, Batch Acc: 0.611580, Tokens per Sec:     3696, Lr: 0.000300
2024-05-27 15:51:01,388 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:51:01,388 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:51:58,913 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.54, acc:   0.57, generation: 57.5174[sec], evaluation: 0.0000[sec]
2024-05-27 15:51:58,916 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:51:59,023 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/23500.ckpt
2024-05-27 15:51:59,025 - INFO - joeynmt.training - Example #0
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'show', 'that', 'the', 'ar@@', 'th@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', ',', 'it', '&apos;s', 're@@', 'cor@@', 'd', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:51:59,026 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:51:59,026 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:51:59,026 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrate to show that the arthic glacial glacial , which for almost three million years has had the size of 48 United States , it &apos;s record of 40 percent .
2024-05-27 15:51:59,026 - INFO - joeynmt.training - Example #1
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'it', 'tur@@', 'ns', 'out', 'this', 'sub@@', 't@@', 'le', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'it', 'sp@@', 'ex@@', 'p@@', 'ec@@', 'ted', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 15:51:59,026 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:51:59,026 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:51:59,026 - INFO - joeynmt.training - 	Hypothesis: But it turns out this subtle the gravity of the problem because it doesn &apos;t show it spexpected the ice of ice .
2024-05-27 15:51:59,026 - INFO - joeynmt.training - Example #2
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:51:59,026 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'th@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:51:59,026 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Hypothesis: The arthtic calotta is , in a certain sense , the pulsant heart of the global climate system .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - Example #3
2024-05-27 15:51:59,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:51:59,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:51:59,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'you', '&apos;re', 'going', 'to', 'be', 'ex@@', 'pan@@', 'ds', '.', '</s>']
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Hypothesis: It expands you &apos;re going to be expands .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - Example #4
2024-05-27 15:51:59,027 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:51:59,027 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:51:59,027 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'to', 'be', 'a', 'rel@@', 'ated', 'rap@@', 'id', 're@@', 'cor@@', 'd', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:51:59,027 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a record to be a related rapid record on the last 25 years .
2024-05-27 15:52:19,143 - INFO - joeynmt.training - Epoch   6, Step:    25600, Batch Loss:     1.385789, Batch Acc: 0.606161, Tokens per Sec:     3656, Lr: 0.000300
2024-05-27 15:52:39,536 - INFO - joeynmt.training - Epoch   6, Step:    25700, Batch Loss:     1.321548, Batch Acc: 0.609857, Tokens per Sec:     3528, Lr: 0.000300
2024-05-27 15:52:58,823 - INFO - joeynmt.training - Epoch   6, Step:    25800, Batch Loss:     1.437870, Batch Acc: 0.612469, Tokens per Sec:     3737, Lr: 0.000300
2024-05-27 15:53:18,635 - INFO - joeynmt.training - Epoch   6, Step:    25900, Batch Loss:     1.417800, Batch Acc: 0.607229, Tokens per Sec:     3655, Lr: 0.000300
2024-05-27 15:53:37,679 - INFO - joeynmt.training - Epoch   6, Step:    26000, Batch Loss:     1.258059, Batch Acc: 0.604439, Tokens per Sec:     3804, Lr: 0.000300
2024-05-27 15:53:37,679 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:53:37,679 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:54:35,153 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.52, acc:   0.57, generation: 57.4655[sec], evaluation: 0.0000[sec]
2024-05-27 15:54:35,156 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:54:35,264 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/22500.ckpt
2024-05-27 15:54:35,274 - INFO - joeynmt.training - Example #0
2024-05-27 15:54:35,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:54:35,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:54:35,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', '&apos;ve', 'sho@@', 'wn', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 15:54:35,274 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:54:35,274 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:54:35,274 - INFO - joeynmt.training - 	Hypothesis: The year I &apos;ve shown these slidemonstrate to show that the calculate glacial glacial , which for almost three million years , has had the size of the United States , 48 percent .
2024-05-27 15:54:35,274 - INFO - joeynmt.training - Example #1
2024-05-27 15:54:35,274 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:54:35,274 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:54:35,274 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'a', 'problem', ',', 'because', 'it', '&apos;s', 'not', 'sho@@', 'wing', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 15:54:35,274 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:54:35,274 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:54:35,274 - INFO - joeynmt.training - 	Hypothesis: It &apos;s a problem , because it &apos;s not showing the gravity of the problem because it doesn &apos;t show the ice of ice .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - Example #2
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 'l', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Hypothesis: The artica glacial is , in a sense , the pull heart of the global climate system .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - Example #3
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'in@@', 'ver@@', 'su@@', 's', 'and', 'the', 'sum@@', 'm@@', 'er', 'ex@@', 'pan@@', 'ts', '.', '</s>']
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Hypothesis: It expanded inversus and the summer expants .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - Example #4
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:54:35,275 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', '2@@', '5', 'years', 'is', 'going', 'to', 'be', 'a', 're@@', 'vie@@', 'w', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:54:35,275 - INFO - joeynmt.training - 	Hypothesis: The next 25 years is going to be a review of the last 25 years .
2024-05-27 15:54:54,659 - INFO - joeynmt.training - Epoch   6, Step:    26100, Batch Loss:     1.245854, Batch Acc: 0.606046, Tokens per Sec:     3735, Lr: 0.000300
2024-05-27 15:55:14,190 - INFO - joeynmt.training - Epoch   6, Step:    26200, Batch Loss:     1.432994, Batch Acc: 0.611931, Tokens per Sec:     3734, Lr: 0.000300
2024-05-27 15:55:33,299 - INFO - joeynmt.training - Epoch   6, Step:    26300, Batch Loss:     1.219122, Batch Acc: 0.609966, Tokens per Sec:     3783, Lr: 0.000300
2024-05-27 15:55:52,478 - INFO - joeynmt.training - Epoch   6, Step:    26400, Batch Loss:     1.411050, Batch Acc: 0.606253, Tokens per Sec:     3728, Lr: 0.000300
2024-05-27 15:56:11,819 - INFO - joeynmt.training - Epoch   6, Step:    26500, Batch Loss:     1.435364, Batch Acc: 0.602019, Tokens per Sec:     3653, Lr: 0.000300
2024-05-27 15:56:11,820 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:56:11,820 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:57:11,789 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.52, acc:   0.57, generation: 59.9613[sec], evaluation: 0.0000[sec]
2024-05-27 15:57:11,896 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/24500.ckpt
2024-05-27 15:57:11,900 - INFO - joeynmt.training - Example #0
2024-05-27 15:57:11,900 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:57:11,900 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:57:11,900 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ation', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ation', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'e@@', 'am', 're@@', 'str@@', 'e@@', 'am', '.', '</s>']
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the calculation to show that the calculation , which for almost three million years has had the size of the U.S. continental continental continental , it &apos;s restream restream .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - Example #1
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'sub@@', '-@@', 'up', ',', 'because', 'it', 'is', 'not', 'sho@@', 'ws', 'the', 'ice', 'of', 'the', 'ice', ',', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Hypothesis: However , this sub-up , because it is not shows the ice of the ice , because it doesn &apos;t show the ice of the ice .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - Example #2
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - 	Hypothesis: The arctic calculation is , in a sense , the pulsing heart of the global climate system .
2024-05-27 15:57:11,901 - INFO - joeynmt.training - Example #3
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:57:11,901 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'in@@', 'ver@@', 'ter', 'and', 'it', '&apos;s', 'r@@', 'iti@@', 'es', '.', '</s>']
2024-05-27 15:57:11,902 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:57:11,902 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:57:11,902 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded inverter and it &apos;s rities .
2024-05-27 15:57:11,902 - INFO - joeynmt.training - Example #4
2024-05-27 15:57:11,902 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:57:11,902 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:57:11,902 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'qu@@', 'i@@', 'res', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:57:11,902 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:57:11,902 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:57:11,902 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable requires of the last 25 years .
2024-05-27 15:57:21,738 - INFO - joeynmt.training - Epoch   6: total training loss 5993.02
2024-05-27 15:57:21,738 - INFO - joeynmt.training - EPOCH 7
2024-05-27 15:57:31,057 - INFO - joeynmt.training - Epoch   7, Step:    26600, Batch Loss:     1.334262, Batch Acc: 0.624514, Tokens per Sec:     3750, Lr: 0.000300
2024-05-27 15:57:51,001 - INFO - joeynmt.training - Epoch   7, Step:    26700, Batch Loss:     1.209878, Batch Acc: 0.629535, Tokens per Sec:     3690, Lr: 0.000300
2024-05-27 15:58:10,662 - INFO - joeynmt.training - Epoch   7, Step:    26800, Batch Loss:     1.307005, Batch Acc: 0.627059, Tokens per Sec:     3694, Lr: 0.000300
2024-05-27 15:58:30,565 - INFO - joeynmt.training - Epoch   7, Step:    26900, Batch Loss:     1.238142, Batch Acc: 0.624353, Tokens per Sec:     3583, Lr: 0.000300
2024-05-27 15:58:50,566 - INFO - joeynmt.training - Epoch   7, Step:    27000, Batch Loss:     1.442967, Batch Acc: 0.627005, Tokens per Sec:     3603, Lr: 0.000300
2024-05-27 15:58:50,567 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 15:58:50,567 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 15:59:52,337 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.50, acc:   0.57, generation: 61.7615[sec], evaluation: 0.0000[sec]
2024-05-27 15:59:52,339 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 15:59:52,443 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/24000.ckpt
2024-05-27 15:59:52,447 - INFO - joeynmt.training - Example #0
2024-05-27 15:59:52,447 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 15:59:52,447 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 15:59:52,447 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'that', 'c@@', 'alc@@', 'ul@@', 'us', 'is', 'about', '4@@', '8', 'million', 'years', ',', 'has', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', 'has', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', ',', 'has', 're@@', 'cor@@', 'ded', 'up', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slide to show that the calculus that calculus is about 48 million years , has the size of 48 United States has the size of 48 United States , has recorded up 40 percent .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - Example #1
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'that', ',', 'I', '&apos;m', 'going', 'to', 'have', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Hypothesis: But this is that , I &apos;m going to have the gravity of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - Example #2
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - 	Hypothesis: The arctic calculation is , in a sense , the heart heart of the climate system .
2024-05-27 15:59:52,448 - INFO - joeynmt.training - Example #3
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 15:59:52,448 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'be', 'out@@', 'side', 'and', 'you', 'r@@', 'un', 'up', '.', '</s>']
2024-05-27 15:59:52,449 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 15:59:52,449 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 15:59:52,449 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to be outside and you run up .
2024-05-27 15:59:52,449 - INFO - joeynmt.training - Example #4
2024-05-27 15:59:52,449 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 15:59:52,449 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 15:59:52,449 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ic@@', 'k@@', 'ly', 're@@', 'cor@@', 'd', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 15:59:52,449 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 15:59:52,449 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 15:59:52,449 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a quickly record on the last 25 years .
2024-05-27 16:00:12,194 - INFO - joeynmt.training - Epoch   7, Step:    27100, Batch Loss:     1.391142, Batch Acc: 0.622499, Tokens per Sec:     3642, Lr: 0.000300
2024-05-27 16:00:31,323 - INFO - joeynmt.training - Epoch   7, Step:    27200, Batch Loss:     1.272988, Batch Acc: 0.621776, Tokens per Sec:     3687, Lr: 0.000300
2024-05-27 16:00:51,633 - INFO - joeynmt.training - Epoch   7, Step:    27300, Batch Loss:     1.180192, Batch Acc: 0.622919, Tokens per Sec:     3537, Lr: 0.000300
2024-05-27 16:01:11,772 - INFO - joeynmt.training - Epoch   7, Step:    27400, Batch Loss:     1.311154, Batch Acc: 0.622454, Tokens per Sec:     3618, Lr: 0.000300
2024-05-27 16:01:31,737 - INFO - joeynmt.training - Epoch   7, Step:    27500, Batch Loss:     1.300172, Batch Acc: 0.613750, Tokens per Sec:     3703, Lr: 0.000300
2024-05-27 16:01:31,739 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:01:31,739 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:02:27,921 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.52, acc:   0.57, generation: 56.1744[sec], evaluation: 0.0000[sec]
2024-05-27 16:02:28,026 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/25000.ckpt
2024-05-27 16:02:28,031 - INFO - joeynmt.training - Example #0
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', ',', 'is', 're@@', 'str@@', 'i@@', 'ke', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:02:28,031 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:02:28,031 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:02:28,031 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slide to show that the cotta glacial glacial , which for almost three million years has had the size of 48 United States , is restrike of 40 percent .
2024-05-27 16:02:28,031 - INFO - joeynmt.training - Example #1
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'm@@', 'ove', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:02:28,031 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:02:28,031 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:02:28,031 - INFO - joeynmt.training - 	Hypothesis: However , this submove the gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 16:02:28,031 - INFO - joeynmt.training - Example #2
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:02:28,031 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 't@@', 'ica', 'is', 'ar@@', 'c@@', 'ti@@', 'c', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Hypothesis: The arctica is arctic , in a certain sense , the pulsant heart of the global climate .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - Example #3
2024-05-27 16:02:28,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:02:28,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:02:28,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'w@@', 'in@@', 'ter', 'and', 'the', 'sum@@', 'm@@', 'er', 'd@@', 'ri@@', 've', '.', '</s>']
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to winter and the summer drive .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - Example #4
2024-05-27 16:02:28,032 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:02:28,032 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:02:28,032 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'on', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:02:28,032 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a record on the advice of the last 25 years .
2024-05-27 16:02:47,011 - INFO - joeynmt.training - Epoch   7, Step:    27600, Batch Loss:     1.162901, Batch Acc: 0.621253, Tokens per Sec:     3795, Lr: 0.000300
2024-05-27 16:03:06,297 - INFO - joeynmt.training - Epoch   7, Step:    27700, Batch Loss:     1.313348, Batch Acc: 0.617629, Tokens per Sec:     3794, Lr: 0.000300
2024-05-27 16:03:25,944 - INFO - joeynmt.training - Epoch   7, Step:    27800, Batch Loss:     1.129173, Batch Acc: 0.618559, Tokens per Sec:     3723, Lr: 0.000300
2024-05-27 16:03:45,517 - INFO - joeynmt.training - Epoch   7, Step:    27900, Batch Loss:     1.204597, Batch Acc: 0.622960, Tokens per Sec:     3641, Lr: 0.000300
2024-05-27 16:04:04,659 - INFO - joeynmt.training - Epoch   7, Step:    28000, Batch Loss:     1.389960, Batch Acc: 0.624902, Tokens per Sec:     3675, Lr: 0.000300
2024-05-27 16:04:04,660 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:04:04,660 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:05:03,606 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.51, ppl:   4.53, acc:   0.57, generation: 58.9395[sec], evaluation: 0.0000[sec]
2024-05-27 16:05:03,710 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/25500.ckpt
2024-05-27 16:05:03,715 - INFO - joeynmt.training - Example #0
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ated', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 't@@', 'ica', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrated to demonstrate that the artica glacial glacial , which for almost three million years has been the size of 40 percent .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - Example #1
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', '-@@', 'up', 'sub@@', '-@@', 'gr@@', 'av@@', 'ity', ',', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Hypothesis: But this sub-up sub-gravity , because it doesn &apos;t show the gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - Example #2
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:05:03,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'he@@', 'at', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 'l', 'of', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - 	Hypothesis: The arctic heat is , in a sense , the pull of the pulsing heart of the global climate system .
2024-05-27 16:05:03,716 - INFO - joeynmt.training - Example #3
2024-05-27 16:05:03,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:05:03,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:05:03,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'pan@@', 'ded', 'in@@', 'ver@@', 'ter', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 16:05:03,717 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:05:03,717 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:05:03,717 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanded inverter and retreatment .
2024-05-27 16:05:03,717 - INFO - joeynmt.training - Example #4
2024-05-27 16:05:03,717 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:05:03,717 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:05:03,717 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'e@@', 'ful', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:05:03,717 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:05:03,717 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:05:03,717 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a quick careful on the last 25 years .
2024-05-27 16:05:22,937 - INFO - joeynmt.training - Epoch   7, Step:    28100, Batch Loss:     1.274928, Batch Acc: 0.625158, Tokens per Sec:     3732, Lr: 0.000300
2024-05-27 16:05:42,210 - INFO - joeynmt.training - Epoch   7, Step:    28200, Batch Loss:     1.485469, Batch Acc: 0.624449, Tokens per Sec:     3698, Lr: 0.000300
2024-05-27 16:06:01,727 - INFO - joeynmt.training - Epoch   7, Step:    28300, Batch Loss:     1.450307, Batch Acc: 0.614345, Tokens per Sec:     3651, Lr: 0.000300
2024-05-27 16:06:21,274 - INFO - joeynmt.training - Epoch   7, Step:    28400, Batch Loss:     1.429420, Batch Acc: 0.619343, Tokens per Sec:     3739, Lr: 0.000300
2024-05-27 16:06:41,056 - INFO - joeynmt.training - Epoch   7, Step:    28500, Batch Loss:     1.417166, Batch Acc: 0.618909, Tokens per Sec:     3600, Lr: 0.000300
2024-05-27 16:06:41,057 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:06:41,057 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:07:39,981 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.48, acc:   0.57, generation: 58.9172[sec], evaluation: 0.0000[sec]
2024-05-27 16:07:39,983 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:07:40,090 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/28000.ckpt
2024-05-27 16:07:40,091 - INFO - joeynmt.training - Example #0
2024-05-27 16:07:40,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:07:40,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:07:40,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'us', 'is', 'the', 'ar@@', 'th@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'that', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'cor@@', 'ded', 'up', '.', '</s>']
2024-05-27 16:07:40,091 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:07:40,091 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:07:40,091 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these slide to show that the calculus is the arthic glacial glacial , that for almost three million years had the size of the U.S. continental continental , it &apos;s recorded up .
2024-05-27 16:07:40,091 - INFO - joeynmt.training - Example #1
2024-05-27 16:07:40,091 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:07:40,091 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:07:40,091 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', 'this', 'under@@', 'l@@', 'ying', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Hypothesis: However this underlying the gravity of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - Example #2
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'th@@', 'ic', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Hypothesis: The arthic glacial glacial is in a sense , the pulser heart of the global climate system .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - Example #3
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'side', 'and', 'it', 'r@@', 'iti@@', 's', '.', '</s>']
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - 	Hypothesis: It expanding inside and it ritis .
2024-05-27 16:07:40,092 - INFO - joeynmt.training - Example #4
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:07:40,092 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 'thing', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'to', 'be', 'a', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:07:40,093 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:07:40,093 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:07:40,093 - INFO - joeynmt.training - 	Hypothesis: The next thing is going to be a record to be a related to the advice of the last 25 years .
2024-05-27 16:07:58,640 - INFO - joeynmt.training - Epoch   7, Step:    28600, Batch Loss:     1.263043, Batch Acc: 0.615916, Tokens per Sec:     3973, Lr: 0.000300
2024-05-27 16:08:17,060 - INFO - joeynmt.training - Epoch   7, Step:    28700, Batch Loss:     1.176959, Batch Acc: 0.613249, Tokens per Sec:     3899, Lr: 0.000300
2024-05-27 16:08:35,887 - INFO - joeynmt.training - Epoch   7, Step:    28800, Batch Loss:     1.272099, Batch Acc: 0.618645, Tokens per Sec:     3748, Lr: 0.000300
2024-05-27 16:08:54,541 - INFO - joeynmt.training - Epoch   7, Step:    28900, Batch Loss:     1.357351, Batch Acc: 0.613887, Tokens per Sec:     3876, Lr: 0.000300
2024-05-27 16:09:12,358 - INFO - joeynmt.training - Epoch   7, Step:    29000, Batch Loss:     1.297656, Batch Acc: 0.619650, Tokens per Sec:     4033, Lr: 0.000300
2024-05-27 16:09:12,359 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:09:12,359 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:10:08,783 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.49, acc:   0.57, generation: 56.4171[sec], evaluation: 0.0000[sec]
2024-05-27 16:10:08,888 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/26500.ckpt
2024-05-27 16:10:08,893 - INFO - joeynmt.training - Example #0
2024-05-27 16:10:08,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:10:08,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:10:08,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'c@@', 'alc@@', 'ul@@', 'us', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p@@', 'ed', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:10:08,893 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:10:08,893 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:10:08,893 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slidemonstrate that slidemonstrate that calculus almost three million years has had the size of 48 continental United States continental , it &apos;s restriped of 40 percent .
2024-05-27 16:10:08,893 - INFO - joeynmt.training - Example #1
2024-05-27 16:10:08,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:10:08,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:10:08,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', 'this', 'sub@@', 'ject', ',', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:10:08,894 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:10:08,894 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Hypothesis: However this subject , the gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - Example #2
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial is , in a sense , the pulsant heart of the global climate .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - Example #3
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'and@@', 'ing', 'around', 'the', 'sum@@', 'm@@', 'er', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Hypothesis: It expanding around the summer and retreatment .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - Example #4
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:10:08,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de@@', 's', 'is', 'a', 'qu@@', 'ic@@', 'k@@', 'ly', 're@@', 'qu@@', 'i@@', 'red', 'on', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:10:08,895 - INFO - joeynmt.training - 	Hypothesis: The next slides is a quickly required on the advice of the last 25 years .
2024-05-27 16:10:26,117 - INFO - joeynmt.training - Epoch   7, Step:    29100, Batch Loss:     1.361124, Batch Acc: 0.618122, Tokens per Sec:     4192, Lr: 0.000300
2024-05-27 16:10:44,551 - INFO - joeynmt.training - Epoch   7, Step:    29200, Batch Loss:     1.229892, Batch Acc: 0.611183, Tokens per Sec:     4003, Lr: 0.000300
2024-05-27 16:11:02,914 - INFO - joeynmt.training - Epoch   7, Step:    29300, Batch Loss:     1.209591, Batch Acc: 0.617886, Tokens per Sec:     3949, Lr: 0.000300
2024-05-27 16:11:25,140 - INFO - joeynmt.training - Epoch   7, Step:    29400, Batch Loss:     1.334350, Batch Acc: 0.615899, Tokens per Sec:     3259, Lr: 0.000300
2024-05-27 16:11:44,680 - INFO - joeynmt.training - Epoch   7, Step:    29500, Batch Loss:     1.290335, Batch Acc: 0.618666, Tokens per Sec:     3708, Lr: 0.000300
2024-05-27 16:11:44,681 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:11:44,681 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:12:37,896 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.50, ppl:   4.47, acc:   0.57, generation: 53.2077[sec], evaluation: 0.0000[sec]
2024-05-27 16:12:37,898 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:12:37,998 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/27500.ckpt
2024-05-27 16:12:38,003 - INFO - joeynmt.training - Example #0
2024-05-27 16:12:38,003 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:12:38,003 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:12:38,003 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 16:12:38,003 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:12:38,003 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to demonstrate that the cotta glacial glacial , which for almost three million years , has had the size of 48 percent .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - Example #1
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'at@@', 'h', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Hypothesis: But this underneath the gravity of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - Example #2
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', '&apos;s', 'c@@', 'le@@', 'ar', 'system', '.', '</s>']
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial glacial , in a sense , the pulser &apos;s clear system .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - Example #3
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:12:38,004 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'w@@', 'in@@', 'ter', 'and', 'the', 'sum@@', 'm@@', 'er', 'and', 'the', 'sum@@', 'm@@', 'er', 'ex@@', 'p@@', 'ect', '.', '</s>']
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - 	Hypothesis: You winter and the summer and the summer expect .
2024-05-27 16:12:38,004 - INFO - joeynmt.training - Example #4
2024-05-27 16:12:38,005 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:12:38,005 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:12:38,005 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:12:38,005 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:12:38,005 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:12:38,005 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable remarkable to the last 25 years .
2024-05-27 16:12:56,592 - INFO - joeynmt.training - Epoch   7, Step:    29600, Batch Loss:     1.437270, Batch Acc: 0.614033, Tokens per Sec:     3823, Lr: 0.000300
2024-05-27 16:13:15,131 - INFO - joeynmt.training - Epoch   7, Step:    29700, Batch Loss:     1.228337, Batch Acc: 0.617468, Tokens per Sec:     3787, Lr: 0.000300
2024-05-27 16:13:33,207 - INFO - joeynmt.training - Epoch   7, Step:    29800, Batch Loss:     1.086919, Batch Acc: 0.616307, Tokens per Sec:     3925, Lr: 0.000300
2024-05-27 16:13:51,488 - INFO - joeynmt.training - Epoch   7, Step:    29900, Batch Loss:     1.345147, Batch Acc: 0.617950, Tokens per Sec:     3913, Lr: 0.000300
2024-05-27 16:14:10,020 - INFO - joeynmt.training - Epoch   7, Step:    30000, Batch Loss:     1.294748, Batch Acc: 0.612422, Tokens per Sec:     3867, Lr: 0.000300
2024-05-27 16:14:10,021 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:14:10,021 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:15:09,358 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.43, acc:   0.58, generation: 59.3298[sec], evaluation: 0.0000[sec]
2024-05-27 16:15:09,359 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:15:09,471 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/26000.ckpt
2024-05-27 16:15:09,476 - INFO - joeynmt.training - Example #0
2024-05-27 16:15:09,476 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:15:09,476 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:15:09,476 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 't@@', '-@@', 'sho@@', 'wing', 'that', 'the', 'ar@@', 't@@', 'ica', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'the', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slide to show that the art-showing that the artica glacial glacial , which for almost three million years , has had the size of the United States , the 40 percent .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - Example #1
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'ne@@', 'at@@', 'h', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Hypothesis: But this underneath the gravity of the problem because it doesn &apos;t show the spessor of the ice .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - Example #2
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 'c@@', 'le@@', 'ar', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', '&apos;s', 'c@@', 'le@@', 'an', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Hypothesis: The arten clear is , in a sense , the pulser &apos;s clean , the pulsing of global climate .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - Example #3
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:15:09,477 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'w@@', 'in@@', 'ter', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:15:09,477 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to winter and retreatment .
2024-05-27 16:15:09,478 - INFO - joeynmt.training - Example #4
2024-05-27 16:15:09,478 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:15:09,478 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:15:09,478 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'f@@', 'ast', 'car@@', 'l@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:15:09,478 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:15:09,478 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:15:09,478 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a fast carled on the last 25 years .
2024-05-27 16:15:27,953 - INFO - joeynmt.training - Epoch   7, Step:    30100, Batch Loss:     1.198442, Batch Acc: 0.619507, Tokens per Sec:     3970, Lr: 0.000300
2024-05-27 16:15:45,745 - INFO - joeynmt.training - Epoch   7, Step:    30200, Batch Loss:     1.323774, Batch Acc: 0.615304, Tokens per Sec:     4059, Lr: 0.000300
2024-05-27 16:16:04,411 - INFO - joeynmt.training - Epoch   7, Step:    30300, Batch Loss:     1.185336, Batch Acc: 0.615221, Tokens per Sec:     3808, Lr: 0.000300
2024-05-27 16:16:22,797 - INFO - joeynmt.training - Epoch   7, Step:    30400, Batch Loss:     1.257540, Batch Acc: 0.613405, Tokens per Sec:     4008, Lr: 0.000300
2024-05-27 16:16:42,055 - INFO - joeynmt.training - Epoch   7, Step:    30500, Batch Loss:     1.255156, Batch Acc: 0.619387, Tokens per Sec:     3724, Lr: 0.000300
2024-05-27 16:16:42,056 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:16:42,056 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:17:32,080 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.58, generation: 50.0160[sec], evaluation: 0.0000[sec]
2024-05-27 16:17:32,081 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:17:32,190 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/27000.ckpt
2024-05-27 16:17:32,193 - INFO - joeynmt.training - Example #0
2024-05-27 16:17:32,193 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:17:32,193 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:17:32,193 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', '.', 'The', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Hypothesis: I showed these slides to show that the arctic glacial glacial , which for almost three million years had the size of 48 United States . The continental continental , it &apos;s 40 percent .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - Example #1
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'not', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Hypothesis: However , this is the gravity of the problem because not show the ice of the ice of the ice .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - Example #2
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'c@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 'l', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - 	Hypothesis: The arctic cotta is , in a sense , the pull of the global climate system .
2024-05-27 16:17:32,194 - INFO - joeynmt.training - Example #3
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:17:32,194 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'side', 'and', 'it', 'c@@', 'lim@@', 'b@@', 's', '.', '</s>']
2024-05-27 16:17:32,195 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:17:32,195 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:17:32,195 - INFO - joeynmt.training - 	Hypothesis: It expanding inside and it climbs .
2024-05-27 16:17:32,195 - INFO - joeynmt.training - Example #4
2024-05-27 16:17:32,195 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:17:32,195 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:17:32,195 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'very', 'qu@@', 'ic@@', 'k@@', 'ly', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:17:32,195 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:17:32,195 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:17:32,195 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a very quickly carried on the last 25 years .
2024-05-27 16:17:50,928 - INFO - joeynmt.training - Epoch   7, Step:    30600, Batch Loss:     1.171303, Batch Acc: 0.615279, Tokens per Sec:     3828, Lr: 0.000300
2024-05-27 16:18:08,832 - INFO - joeynmt.training - Epoch   7, Step:    30700, Batch Loss:     1.426705, Batch Acc: 0.608892, Tokens per Sec:     3985, Lr: 0.000300
2024-05-27 16:18:26,118 - INFO - joeynmt.training - Epoch   7, Step:    30800, Batch Loss:     1.311588, Batch Acc: 0.614775, Tokens per Sec:     4161, Lr: 0.000300
2024-05-27 16:18:44,598 - INFO - joeynmt.training - Epoch   7, Step:    30900, Batch Loss:     1.153692, Batch Acc: 0.623370, Tokens per Sec:     3959, Lr: 0.000300
2024-05-27 16:18:59,286 - INFO - joeynmt.training - Epoch   7: total training loss 5811.53
2024-05-27 16:18:59,286 - INFO - joeynmt.training - EPOCH 8
2024-05-27 16:19:02,304 - INFO - joeynmt.training - Epoch   8, Step:    31000, Batch Loss:     1.126335, Batch Acc: 0.647106, Tokens per Sec:     4524, Lr: 0.000300
2024-05-27 16:19:02,304 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:19:02,304 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:19:55,174 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.58, generation: 52.8611[sec], evaluation: 0.0000[sec]
2024-05-27 16:19:55,175 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:19:55,289 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/29000.ckpt
2024-05-27 16:19:55,292 - INFO - joeynmt.training - Example #0
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'lim@@', 'b', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', '.', '</s>']
2024-05-27 16:19:55,293 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:19:55,293 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:19:55,293 - INFO - joeynmt.training - 	Hypothesis: The year I showed these slidemonstrate that the cotta climb glacial glacial , which for almost three million years has had the size of 48 United States .
2024-05-27 16:19:55,293 - INFO - joeynmt.training - Example #1
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'that', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'ex@@', 'tra', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:19:55,293 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:19:55,293 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:19:55,293 - INFO - joeynmt.training - 	Hypothesis: But this is that the gravity of the problem because it doesn &apos;t show the spexextra of the ice .
2024-05-27 16:19:55,293 - INFO - joeynmt.training - Example #2
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:19:55,293 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'is', 'ar@@', 'c@@', 'ti@@', 'c', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Hypothesis: The artica is arctic , in a sense , the pulsant heart of the global climate system .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - Example #3
2024-05-27 16:19:55,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:19:55,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:19:55,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'w@@', 'in@@', 'ter', 'and', 'you', 'make', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to winter and you make summer .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - Example #4
2024-05-27 16:19:55,294 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:19:55,294 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:19:55,294 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'will', 'be', 'a', 'rap@@', 'id', 'car@@', 'ri@@', 'ed', 'on', 'the', 'next', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:19:55,294 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a rapid carried on the next 25 years .
2024-05-27 16:20:13,709 - INFO - joeynmt.training - Epoch   8, Step:    31100, Batch Loss:     1.335884, Batch Acc: 0.631296, Tokens per Sec:     3956, Lr: 0.000300
2024-05-27 16:20:32,082 - INFO - joeynmt.training - Epoch   8, Step:    31200, Batch Loss:     1.094359, Batch Acc: 0.632774, Tokens per Sec:     3899, Lr: 0.000300
2024-05-27 16:20:51,437 - INFO - joeynmt.training - Epoch   8, Step:    31300, Batch Loss:     1.307176, Batch Acc: 0.632907, Tokens per Sec:     3705, Lr: 0.000300
2024-05-27 16:21:09,808 - INFO - joeynmt.training - Epoch   8, Step:    31400, Batch Loss:     1.272170, Batch Acc: 0.635586, Tokens per Sec:     3982, Lr: 0.000300
2024-05-27 16:21:28,547 - INFO - joeynmt.training - Epoch   8, Step:    31500, Batch Loss:     1.196016, Batch Acc: 0.632564, Tokens per Sec:     3813, Lr: 0.000300
2024-05-27 16:21:28,548 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:21:28,548 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:22:19,900 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.44, acc:   0.58, generation: 51.3434[sec], evaluation: 0.0000[sec]
2024-05-27 16:22:20,027 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/28500.ckpt
2024-05-27 16:22:20,034 - INFO - joeynmt.training - Example #0
2024-05-27 16:22:20,034 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:22:20,034 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:22:20,034 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'alc@@', 'ul@@', 'ations', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ass@@', 'es', ',', 'which', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'and', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p@@', 'p@@', 'ed', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:22:20,034 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:22:20,034 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slidemonstrate to show that the cotta calculations that the arctic glacial glasses , which almost three million years had the U.S. continental continental , and it &apos;s restripped 40 percent .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - Example #1
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'a', 'lot', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Hypothesis: But this is a lot of the problem because it doesn &apos;t show the gravity of the problem because it doesn &apos;t show the ice of ice .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - Example #2
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ic', 'c@@', 'alc@@', 'ul@@', 'ation', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', '&apos;s', 'c@@', 'le@@', 'an@@', 'ing', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Hypothesis: The artic calculation is , in a sense , the pulser &apos;s cleaning the global climate .
2024-05-27 16:22:20,035 - INFO - joeynmt.training - Example #3
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:22:20,035 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'pan@@', 'ds', 'in', 'the', 'w@@', 'in@@', 'ter', 'and', 'the', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 16:22:20,035 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:22:20,036 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:22:20,036 - INFO - joeynmt.training - 	Hypothesis: You expands in the winter and the summer .
2024-05-27 16:22:20,036 - INFO - joeynmt.training - Example #4
2024-05-27 16:22:20,036 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:22:20,036 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:22:20,036 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'cor@@', 'd', 'of', 'car@@', 'l@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:22:20,036 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:22:20,036 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:22:20,036 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a record of carled on the last 25 years .
2024-05-27 16:22:38,488 - INFO - joeynmt.training - Epoch   8, Step:    31600, Batch Loss:     1.111739, Batch Acc: 0.634250, Tokens per Sec:     3895, Lr: 0.000300
2024-05-27 16:22:56,443 - INFO - joeynmt.training - Epoch   8, Step:    31700, Batch Loss:     1.221134, Batch Acc: 0.634705, Tokens per Sec:     4042, Lr: 0.000300
2024-05-27 16:23:16,241 - INFO - joeynmt.training - Epoch   8, Step:    31800, Batch Loss:     1.212358, Batch Acc: 0.630690, Tokens per Sec:     3743, Lr: 0.000300
2024-05-27 16:23:33,528 - INFO - joeynmt.training - Epoch   8, Step:    31900, Batch Loss:     1.489601, Batch Acc: 0.634725, Tokens per Sec:     4104, Lr: 0.000300
2024-05-27 16:23:54,573 - INFO - joeynmt.training - Epoch   8, Step:    32000, Batch Loss:     1.248552, Batch Acc: 0.631638, Tokens per Sec:     3486, Lr: 0.000300
2024-05-27 16:23:54,574 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:23:54,574 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:24:46,887 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.43, acc:   0.58, generation: 52.3041[sec], evaluation: 0.0000[sec]
2024-05-27 16:24:47,018 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/29500.ckpt
2024-05-27 16:24:47,020 - INFO - joeynmt.training - Example #0
2024-05-27 16:24:47,020 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:24:47,020 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:24:47,020 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ation', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'lim@@', 'b@@', 'ing', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'and', 'it', '&apos;s', 're@@', 'cor@@', 'ded', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:24:47,020 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:24:47,020 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slidemonstration to demonstrate that the climbing glacial glacial , which for almost three million years had the 48 United States continental continental , and it &apos;s recorded 40 percent .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - Example #1
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'there', 'is', 'this', 'under@@', 'esti@@', 'mat@@', 'ing', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:24:47,021 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - 	Hypothesis: But there is this underestimating gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - Example #2
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'he@@', 'at', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'system', '.', '</s>']
2024-05-27 16:24:47,021 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - 	Hypothesis: The arctic heat is , in a certain sense , the heart heart of the global system .
2024-05-27 16:24:47,021 - INFO - joeynmt.training - Example #3
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:24:47,021 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'side', 'and', 'the', 'sum@@', 'm@@', 'er', 'of', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 16:24:47,022 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:24:47,022 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:24:47,022 - INFO - joeynmt.training - 	Hypothesis: You expanding inside and the summer of summer .
2024-05-27 16:24:47,022 - INFO - joeynmt.training - Example #4
2024-05-27 16:24:47,022 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:24:47,022 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:24:47,022 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:24:47,022 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:24:47,022 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:24:47,022 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a rapid carried on the last 25 years .
2024-05-27 16:25:07,954 - INFO - joeynmt.training - Epoch   8, Step:    32100, Batch Loss:     1.206972, Batch Acc: 0.629985, Tokens per Sec:     3501, Lr: 0.000300
2024-05-27 16:25:29,538 - INFO - joeynmt.training - Epoch   8, Step:    32200, Batch Loss:     1.302625, Batch Acc: 0.626901, Tokens per Sec:     3335, Lr: 0.000300
2024-05-27 16:25:50,351 - INFO - joeynmt.training - Epoch   8, Step:    32300, Batch Loss:     1.251398, Batch Acc: 0.627835, Tokens per Sec:     3665, Lr: 0.000300
2024-05-27 16:26:09,470 - INFO - joeynmt.training - Epoch   8, Step:    32400, Batch Loss:     1.297908, Batch Acc: 0.631399, Tokens per Sec:     3838, Lr: 0.000300
2024-05-27 16:26:28,318 - INFO - joeynmt.training - Epoch   8, Step:    32500, Batch Loss:     1.196611, Batch Acc: 0.626512, Tokens per Sec:     3773, Lr: 0.000300
2024-05-27 16:26:28,319 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:26:28,319 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:27:23,081 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.58, generation: 54.7548[sec], evaluation: 0.0000[sec]
2024-05-27 16:27:23,206 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/31500.ckpt
2024-05-27 16:27:23,209 - INFO - joeynmt.training - Example #0
2024-05-27 16:27:23,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:27:23,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:27:23,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'alc@@', 'ul@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'sc@@', 'ale', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', '.', '</s>']
2024-05-27 16:27:23,209 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:27:23,209 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:27:23,209 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to show that the cotta calculate that the arctic glacial glacial scale , which for almost three million years , has had the size of the U.S. .
2024-05-27 16:27:23,209 - INFO - joeynmt.training - Example #1
2024-05-27 16:27:23,209 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:27:23,209 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:27:23,209 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'that', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 't@@', 'or', 'of', 'ice', '.', '</s>']
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Hypothesis: But this subject that is the gravity of the problem because it doesn &apos;t show the spexpector of ice .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - Example #2
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'system', '.', '</s>']
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a sense , the heart heart of the global system .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - Example #3
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'in@@', 'ver@@', 'en', 'in@@', 'ver@@', 'ter', 'and', 'it', '&apos;s', 're@@', 'tur@@', 'n', 'out', '.', '</s>']
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Hypothesis: You &apos;re inveren inverter and it &apos;s return out .
2024-05-27 16:27:23,210 - INFO - joeynmt.training - Example #4
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:27:23,210 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:27:23,210 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:27:23,211 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:27:23,211 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid fast carried on the last 25 years .
2024-05-27 16:27:42,325 - INFO - joeynmt.training - Epoch   8, Step:    32600, Batch Loss:     1.386283, Batch Acc: 0.629006, Tokens per Sec:     3744, Lr: 0.000300
2024-05-27 16:28:01,119 - INFO - joeynmt.training - Epoch   8, Step:    32700, Batch Loss:     1.258001, Batch Acc: 0.627478, Tokens per Sec:     3910, Lr: 0.000300
2024-05-27 16:28:20,722 - INFO - joeynmt.training - Epoch   8, Step:    32800, Batch Loss:     1.308949, Batch Acc: 0.625704, Tokens per Sec:     3604, Lr: 0.000300
2024-05-27 16:28:39,669 - INFO - joeynmt.training - Epoch   8, Step:    32900, Batch Loss:     1.367671, Batch Acc: 0.628493, Tokens per Sec:     3781, Lr: 0.000300
2024-05-27 16:29:00,422 - INFO - joeynmt.training - Epoch   8, Step:    33000, Batch Loss:     1.118635, Batch Acc: 0.618419, Tokens per Sec:     3373, Lr: 0.000300
2024-05-27 16:29:00,422 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:29:00,422 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:30:01,727 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.49, ppl:   4.43, acc:   0.58, generation: 61.2963[sec], evaluation: 0.0000[sec]
2024-05-27 16:30:01,889 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/32000.ckpt
2024-05-27 16:30:01,891 - INFO - joeynmt.training - Example #0
2024-05-27 16:30:01,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:30:01,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:30:01,891 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ated', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'lim@@', 'b', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'has', 're@@', 'h@@', 'ol@@', 'ding', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:30:01,891 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:30:01,891 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:30:01,891 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slidemonstrated to show that the cotta climb , which for almost three million years , has had the size of 48 percent of the United States continental continental , has reholding 40 percent .
2024-05-27 16:30:01,891 - INFO - joeynmt.training - Example #1
2024-05-27 16:30:01,891 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:30:01,891 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:30:01,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['Y@@', 'et', 'this', 'under@@', 'es@@', 'tim@@', 'ate', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Hypothesis: Yet this underestimate gravity of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - Example #2
2024-05-27 16:30:01,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:30:01,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:30:01,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'c@@', 'ot@@', 'ta', 'c@@', 'lim@@', 'ate', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', 'cu@@', 'e', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Hypothesis: The cotta climate is , in a sense , the pulser cue is , in a sense , the pulsant heart of the global climate .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - Example #3
2024-05-27 16:30:01,892 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:30:01,892 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:30:01,892 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'in@@', 'ver@@', 'i@@', 'an', 'and', 'it', 'r@@', 'iti@@', 'es', '.', '</s>']
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - 	Hypothesis: It expands inverian and it rities .
2024-05-27 16:30:01,892 - INFO - joeynmt.training - Example #4
2024-05-27 16:30:01,893 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:30:01,893 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:30:01,893 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'car@@', 'ed', 'on', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:30:01,893 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:30:01,893 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:30:01,893 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid cared on on the last 25 years .
2024-05-27 16:30:22,361 - INFO - joeynmt.training - Epoch   8, Step:    33100, Batch Loss:     1.161786, Batch Acc: 0.625993, Tokens per Sec:     3550, Lr: 0.000300
2024-05-27 16:30:41,405 - INFO - joeynmt.training - Epoch   8, Step:    33200, Batch Loss:     1.368392, Batch Acc: 0.632345, Tokens per Sec:     3841, Lr: 0.000300
2024-05-27 16:31:01,947 - INFO - joeynmt.training - Epoch   8, Step:    33300, Batch Loss:     1.180711, Batch Acc: 0.628771, Tokens per Sec:     3471, Lr: 0.000300
2024-05-27 16:31:22,988 - INFO - joeynmt.training - Epoch   8, Step:    33400, Batch Loss:     1.361104, Batch Acc: 0.628383, Tokens per Sec:     3391, Lr: 0.000300
2024-05-27 16:31:44,464 - INFO - joeynmt.training - Epoch   8, Step:    33500, Batch Loss:     1.206585, Batch Acc: 0.626501, Tokens per Sec:     3389, Lr: 0.000300
2024-05-27 16:31:44,464 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:31:44,464 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:32:47,552 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.41, acc:   0.58, generation: 63.0800[sec], evaluation: 0.0000[sec]
2024-05-27 16:32:47,554 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:32:47,667 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/33000.ckpt
2024-05-27 16:32:47,668 - INFO - joeynmt.training - Example #0
2024-05-27 16:32:47,668 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:32:47,668 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:32:47,668 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', '&apos;ve', 'sho@@', 'wn', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'sho@@', 'wing', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '8', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', '.', '</s>']
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Hypothesis: I &apos;ve shown these slides to show that the calotta showing that the calotta glacial , which for almost three million years had the size of the 48 U.S. continental .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - Example #1
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Hypothesis: However , this is the gravity of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - Example #2
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'way', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', '.', '</s>']
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - 	Hypothesis: The glacial glacial is , in a way , the pulsant heart of the global climate heart of the global climate .
2024-05-27 16:32:47,669 - INFO - joeynmt.training - Example #3
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:32:47,669 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'ver@@', 'ter', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 16:32:47,670 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:32:47,670 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:32:47,670 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanding inverter and retreatment .
2024-05-27 16:32:47,670 - INFO - joeynmt.training - Example #4
2024-05-27 16:32:47,670 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:32:47,670 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:32:47,670 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 're@@', 'ach@@', 'ing', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:32:47,670 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:32:47,670 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:32:47,670 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carried on reaching the advice of the last 25 years .
2024-05-27 16:33:07,754 - INFO - joeynmt.training - Epoch   8, Step:    33600, Batch Loss:     1.258366, Batch Acc: 0.630893, Tokens per Sec:     3526, Lr: 0.000300
2024-05-27 16:33:27,159 - INFO - joeynmt.training - Epoch   8, Step:    33700, Batch Loss:     1.389787, Batch Acc: 0.625186, Tokens per Sec:     3703, Lr: 0.000300
2024-05-27 16:33:46,171 - INFO - joeynmt.training - Epoch   8, Step:    33800, Batch Loss:     1.297228, Batch Acc: 0.623128, Tokens per Sec:     3657, Lr: 0.000300
2024-05-27 16:34:05,087 - INFO - joeynmt.training - Epoch   8, Step:    33900, Batch Loss:     1.252815, Batch Acc: 0.629293, Tokens per Sec:     3758, Lr: 0.000300
2024-05-27 16:34:24,757 - INFO - joeynmt.training - Epoch   8, Step:    34000, Batch Loss:     1.336122, Batch Acc: 0.627856, Tokens per Sec:     3561, Lr: 0.000300
2024-05-27 16:34:24,757 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:34:24,757 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:35:25,176 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.40, acc:   0.58, generation: 60.4112[sec], evaluation: 0.0000[sec]
2024-05-27 16:35:25,178 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:35:25,300 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/30000.ckpt
2024-05-27 16:35:25,303 - INFO - joeynmt.training - Example #0
2024-05-27 16:35:25,303 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:35:25,303 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'alc@@', 'ul@@', 'ation', 'of', 'ar@@', 'c@@', 'ti@@', 'c', ',', 'that', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', ',', 'the', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these slide to demonstrate that the calculation of arctic , that for almost three million years , has had the size of 48 percent of the United States , the 48 percent .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - Example #1
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'is', 'that', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Hypothesis: However , this is that the gravity of the problem because it doesn &apos;t show the ice of the ice of the ice .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - Example #2
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a sense , the pulsant heart of the global climate system .
2024-05-27 16:35:25,304 - INFO - joeynmt.training - Example #3
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:35:25,304 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ded', 'in@@', 'ver@@', 's@@', 'ing', 'and', 'it', '.', '</s>']
2024-05-27 16:35:25,305 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:35:25,305 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:35:25,305 - INFO - joeynmt.training - 	Hypothesis: It expanded inversing and it .
2024-05-27 16:35:25,305 - INFO - joeynmt.training - Example #4
2024-05-27 16:35:25,305 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:35:25,305 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:35:25,305 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 're@@', 'mark@@', 'able', 'to', 'be', 'a', 're@@', 'mark@@', 'able', 'to', 'be', 'a', 'very', 'qu@@', 'ic@@', 'k@@', 'ly', 'p@@', 'ac@@', 'k@@', 'age', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:35:25,305 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:35:25,305 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:35:25,305 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a remarkable remarkable to be a remarkable remarkable to be a remarkable to be a very quickly package of the last 25 years .
2024-05-27 16:35:46,381 - INFO - joeynmt.training - Epoch   8, Step:    34100, Batch Loss:     1.471263, Batch Acc: 0.621305, Tokens per Sec:     3392, Lr: 0.000300
2024-05-27 16:36:06,934 - INFO - joeynmt.training - Epoch   8, Step:    34200, Batch Loss:     1.279080, Batch Acc: 0.628908, Tokens per Sec:     3610, Lr: 0.000300
2024-05-27 16:36:27,436 - INFO - joeynmt.training - Epoch   8, Step:    34300, Batch Loss:     1.372279, Batch Acc: 0.624636, Tokens per Sec:     3469, Lr: 0.000300
2024-05-27 16:36:47,336 - INFO - joeynmt.training - Epoch   8, Step:    34400, Batch Loss:     1.282646, Batch Acc: 0.626480, Tokens per Sec:     3493, Lr: 0.000300
2024-05-27 16:37:07,263 - INFO - joeynmt.training - Epoch   8, Step:    34500, Batch Loss:     1.280943, Batch Acc: 0.627060, Tokens per Sec:     3570, Lr: 0.000300
2024-05-27 16:37:07,264 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:37:07,264 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:38:01,725 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.38, acc:   0.58, generation: 54.4496[sec], evaluation: 0.0000[sec]
2024-05-27 16:38:01,727 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:38:01,875 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/30500.ckpt
2024-05-27 16:38:01,877 - INFO - joeynmt.training - Example #0
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'lim@@', 'b@@', 'ing', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', '.', 'The', 'last', 'year', 'was', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:38:01,877 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:38:01,877 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:38:01,877 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the cotta climbing glacial glacial , which almost three million years has had the size of 48 United States . The last year was 40 percent .
2024-05-27 16:38:01,877 - INFO - joeynmt.training - Example #1
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', 'this', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 'ted', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:38:01,877 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:38:01,877 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:38:01,877 - INFO - joeynmt.training - 	Hypothesis: However this is the gravity of the problem because it doesn &apos;t show the spexpected of the ice .
2024-05-27 16:38:01,877 - INFO - joeynmt.training - Example #2
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:38:01,877 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'les', 'is', 'a', 'kind', 'of', 'ar@@', 'c@@', 'ti@@', 'c', 'c@@', 'le@@', 'ar', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Hypothesis: The arcles is a kind of arctic clear is , in a sense , the heart heart of global climate system .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - Example #3
2024-05-27 16:38:01,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:38:01,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:38:01,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ts', 'in@@', 'ver@@', 'ter', 'and', 'it', '&apos;s', 'ta@@', 'k@@', 'en', '.', '</s>']
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Hypothesis: It expants inverter and it &apos;s taken .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - Example #4
2024-05-27 16:38:01,878 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:38:01,878 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:38:01,878 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'l@@', 'ed', 'on', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:38:01,878 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carled on the advice of the last 25 years .
2024-05-27 16:38:21,425 - INFO - joeynmt.training - Epoch   8, Step:    34600, Batch Loss:     1.242694, Batch Acc: 0.623946, Tokens per Sec:     3647, Lr: 0.000300
2024-05-27 16:38:41,372 - INFO - joeynmt.training - Epoch   8, Step:    34700, Batch Loss:     1.434464, Batch Acc: 0.626889, Tokens per Sec:     3683, Lr: 0.000300
2024-05-27 16:39:02,688 - INFO - joeynmt.training - Epoch   8, Step:    34800, Batch Loss:     1.217588, Batch Acc: 0.622951, Tokens per Sec:     3526, Lr: 0.000300
2024-05-27 16:39:23,535 - INFO - joeynmt.training - Epoch   8, Step:    34900, Batch Loss:     1.150055, Batch Acc: 0.627004, Tokens per Sec:     3408, Lr: 0.000300
2024-05-27 16:39:43,875 - INFO - joeynmt.training - Epoch   8, Step:    35000, Batch Loss:     1.301827, Batch Acc: 0.622957, Tokens per Sec:     3517, Lr: 0.000300
2024-05-27 16:39:43,875 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:39:43,875 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:40:34,313 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.36, acc:   0.58, generation: 50.4298[sec], evaluation: 0.0000[sec]
2024-05-27 16:40:34,315 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:40:34,467 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/32500.ckpt
2024-05-27 16:40:34,470 - INFO - joeynmt.training - Example #0
2024-05-27 16:40:34,470 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:40:34,470 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:40:34,470 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'is', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'h@@', 'ol@@', 'ding', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:40:34,470 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slide slide to demonstrate that the artic glacial glacial , which is almost three million years has had the size of the U.S. continental , it &apos;s reholding 40 percent .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - Example #1
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', ',', 'it', '&apos;s', 'a', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Hypothesis: But this is , it &apos;s a gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - Example #2
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a sense , the pulsant heart of the global climate system .
2024-05-27 16:40:34,471 - INFO - joeynmt.training - Example #3
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:40:34,471 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'get', 'into', 'the', 'sum@@', 'm@@', 'er', 'and', 'you', 'r@@', 'oll@@', 'ed', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 16:40:34,472 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:40:34,472 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:40:34,472 - INFO - joeynmt.training - 	Hypothesis: You get into the summer and you rolled summer .
2024-05-27 16:40:34,472 - INFO - joeynmt.training - Example #4
2024-05-27 16:40:34,472 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:40:34,472 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:40:34,472 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'on', 'the', 'li@@', 'ving', 'be@@', 'au@@', 'ti@@', 'ful', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:40:34,472 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:40:34,472 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:40:34,472 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carried on on the living beautiful 25 years .
2024-05-27 16:40:54,561 - INFO - joeynmt.training - Epoch   8, Step:    35100, Batch Loss:     1.294768, Batch Acc: 0.627315, Tokens per Sec:     3563, Lr: 0.000300
2024-05-27 16:41:14,279 - INFO - joeynmt.training - Epoch   8, Step:    35200, Batch Loss:     1.346506, Batch Acc: 0.618352, Tokens per Sec:     3606, Lr: 0.000300
2024-05-27 16:41:32,921 - INFO - joeynmt.training - Epoch   8, Step:    35300, Batch Loss:     1.130192, Batch Acc: 0.622428, Tokens per Sec:     3896, Lr: 0.000300
2024-05-27 16:41:51,973 - INFO - joeynmt.training - Epoch   8, Step:    35400, Batch Loss:     1.149188, Batch Acc: 0.626573, Tokens per Sec:     3709, Lr: 0.000300
2024-05-27 16:41:54,774 - INFO - joeynmt.training - Epoch   8: total training loss 5662.19
2024-05-27 16:41:54,774 - INFO - joeynmt.training - EPOCH 9
2024-05-27 16:42:13,201 - INFO - joeynmt.training - Epoch   9, Step:    35500, Batch Loss:     1.529129, Batch Acc: 0.644550, Tokens per Sec:     3297, Lr: 0.000300
2024-05-27 16:42:13,202 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:42:13,202 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:43:05,565 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.34, acc:   0.58, generation: 52.3532[sec], evaluation: 0.0000[sec]
2024-05-27 16:43:05,568 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:43:05,754 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/31000.ckpt
2024-05-27 16:43:05,757 - INFO - joeynmt.training - Example #0
2024-05-27 16:43:05,757 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:43:05,757 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:43:05,757 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'it', 'was', 're@@', 'str@@', 'i@@', 'ke', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to show that the arctic glacial glacial , which for almost three million years had the size of 48 United States continental continental , it was restrike of 40 percent .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - Example #1
2024-05-27 16:43:05,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:43:05,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:43:05,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'that', 'un@@', 'ti@@', 'l', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Hypothesis: But this is that until the gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - Example #2
2024-05-27 16:43:05,758 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:43:05,758 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:43:05,758 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:43:05,758 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a sense , the pulsant heart of the global climate system .
2024-05-27 16:43:05,759 - INFO - joeynmt.training - Example #3
2024-05-27 16:43:05,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:43:05,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:43:05,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'in@@', 'side', 'and', 'it', '&apos;s', 'w@@', 'in@@', 'ter', 'and', 'it', '&apos;s', 't@@', 'ot@@', 'ally', '.', '</s>']
2024-05-27 16:43:05,759 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:43:05,759 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:43:05,759 - INFO - joeynmt.training - 	Hypothesis: It &apos;s inside and it &apos;s winter and it &apos;s totally .
2024-05-27 16:43:05,759 - INFO - joeynmt.training - Example #4
2024-05-27 16:43:05,759 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:43:05,759 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:43:05,759 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'f@@', 'ast', 'car@@', 'ri@@', 'ed', 'on', 'the', 'ad@@', 'ven@@', 'u@@', 'es', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:43:05,759 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:43:05,759 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:43:05,759 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a fast carried on the advenues of the last 25 years .
2024-05-27 16:43:27,012 - INFO - joeynmt.training - Epoch   9, Step:    35600, Batch Loss:     1.090722, Batch Acc: 0.650699, Tokens per Sec:     3370, Lr: 0.000300
2024-05-27 16:43:48,351 - INFO - joeynmt.training - Epoch   9, Step:    35700, Batch Loss:     1.116177, Batch Acc: 0.643476, Tokens per Sec:     3345, Lr: 0.000300
2024-05-27 16:44:09,107 - INFO - joeynmt.training - Epoch   9, Step:    35800, Batch Loss:     1.084192, Batch Acc: 0.647845, Tokens per Sec:     3401, Lr: 0.000300
2024-05-27 16:44:30,093 - INFO - joeynmt.training - Epoch   9, Step:    35900, Batch Loss:     1.184658, Batch Acc: 0.640414, Tokens per Sec:     3450, Lr: 0.000300
2024-05-27 16:44:51,245 - INFO - joeynmt.training - Epoch   9, Step:    36000, Batch Loss:     1.297127, Batch Acc: 0.644419, Tokens per Sec:     3443, Lr: 0.000300
2024-05-27 16:44:51,246 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:44:51,246 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:45:50,924 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.37, acc:   0.58, generation: 59.6699[sec], evaluation: 0.0000[sec]
2024-05-27 16:45:51,043 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/33500.ckpt
2024-05-27 16:45:51,048 - INFO - joeynmt.training - Example #0
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'th@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'has', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p@@', 'p@@', 'p@@', 'ed', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:45:51,048 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:45:51,048 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:45:51,048 - INFO - joeynmt.training - 	Hypothesis: And last year I showed these slidemonstrate to demonstrate that the arthctic glacial , which for almost three million years , has the size of 48 United States continental continental , it &apos;s restrippped 40 percent .
2024-05-27 16:45:51,048 - INFO - joeynmt.training - Example #1
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'sub@@', 'ject', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'ac@@', 'tly', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 't@@', 'ation', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:45:51,048 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:45:51,048 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:45:51,048 - INFO - joeynmt.training - 	Hypothesis: However , this subject of the problem because it doesn &apos;t show the spexactly the spexpectation of the ice .
2024-05-27 16:45:51,048 - INFO - joeynmt.training - Example #2
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:45:51,048 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'th@@', 'c@@', 'e@@', 'as', 'is', 'the', 'ar@@', 'th@@', 'ti@@', 'c', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Hypothesis: The arthceas is the arthtic , in a sense , the pulsant heart of the global climate system .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - Example #3
2024-05-27 16:45:51,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:45:51,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:45:51,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'ver@@', 'ter', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Hypothesis: It expanding inverter and retreatment .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - Example #4
2024-05-27 16:45:51,049 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:45:51,049 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:45:51,049 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'car@@', 'l@@', 'ed', 'on', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:45:51,049 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carled on the advice of the last 25 years .
2024-05-27 16:46:11,012 - INFO - joeynmt.training - Epoch   9, Step:    36100, Batch Loss:     1.258143, Batch Acc: 0.639498, Tokens per Sec:     3637, Lr: 0.000300
2024-05-27 16:46:30,038 - INFO - joeynmt.training - Epoch   9, Step:    36200, Batch Loss:     1.191238, Batch Acc: 0.639603, Tokens per Sec:     3798, Lr: 0.000300
2024-05-27 16:46:49,774 - INFO - joeynmt.training - Epoch   9, Step:    36300, Batch Loss:     1.258641, Batch Acc: 0.642764, Tokens per Sec:     3623, Lr: 0.000300
2024-05-27 16:47:09,088 - INFO - joeynmt.training - Epoch   9, Step:    36400, Batch Loss:     1.048044, Batch Acc: 0.634511, Tokens per Sec:     3582, Lr: 0.000300
2024-05-27 16:47:29,057 - INFO - joeynmt.training - Epoch   9, Step:    36500, Batch Loss:     1.127113, Batch Acc: 0.635764, Tokens per Sec:     3570, Lr: 0.000300
2024-05-27 16:47:29,058 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:47:29,058 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:48:24,882 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.40, acc:   0.58, generation: 55.8158[sec], evaluation: 0.0000[sec]
2024-05-27 16:48:25,013 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/34000.ckpt
2024-05-27 16:48:25,017 - INFO - joeynmt.training - Example #0
2024-05-27 16:48:25,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:48:25,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:48:25,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'h@@', 'o@@', 't', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p@@', 'p@@', 'ed', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:48:25,017 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:48:25,017 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:48:25,017 - INFO - joeynmt.training - 	Hypothesis: I showed these slides to show that the slide to show that the hot glacial , which for almost three million years had the size of the U.S. continental , it &apos;s restripped 40 percent .
2024-05-27 16:48:25,017 - INFO - joeynmt.training - Example #1
2024-05-27 16:48:25,017 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:48:25,017 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:48:25,017 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'under@@', '-@@', 'c@@', 'las@@', 's', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 't@@', 'ation', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:48:25,017 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:48:25,017 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:48:25,017 - INFO - joeynmt.training - 	Hypothesis: However , this under-class the problem because it doesn &apos;t show the spexpectation of the ice .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - Example #2
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'th@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', ',', '</s>']
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Hypothesis: The arthtic glacial is , in a sense , the pulsing heart of the global climate ,
2024-05-27 16:48:25,018 - INFO - joeynmt.training - Example #3
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', '&apos;s', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'side', 'and', 'the', 'sum@@', 'm@@', 'it', '.', '</s>']
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Hypothesis: It &apos;s expanding inside and the summit .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - Example #4
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:48:25,018 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:48:25,018 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carried on the advice of the last 25 years .
2024-05-27 16:48:44,597 - INFO - joeynmt.training - Epoch   9, Step:    36600, Batch Loss:     1.172782, Batch Acc: 0.634314, Tokens per Sec:     3665, Lr: 0.000300
2024-05-27 16:49:04,029 - INFO - joeynmt.training - Epoch   9, Step:    36700, Batch Loss:     1.219536, Batch Acc: 0.640301, Tokens per Sec:     3764, Lr: 0.000300
2024-05-27 16:49:24,872 - INFO - joeynmt.training - Epoch   9, Step:    36800, Batch Loss:     1.237337, Batch Acc: 0.637323, Tokens per Sec:     3446, Lr: 0.000300
2024-05-27 16:49:43,914 - INFO - joeynmt.training - Epoch   9, Step:    36900, Batch Loss:     1.308692, Batch Acc: 0.637471, Tokens per Sec:     3839, Lr: 0.000300
2024-05-27 16:50:02,629 - INFO - joeynmt.training - Epoch   9, Step:    37000, Batch Loss:     1.373935, Batch Acc: 0.634327, Tokens per Sec:     3857, Lr: 0.000300
2024-05-27 16:50:02,630 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:50:02,630 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:50:58,564 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.48, ppl:   4.37, acc:   0.58, generation: 55.9253[sec], evaluation: 0.0000[sec]
2024-05-27 16:50:58,710 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/36500.ckpt
2024-05-27 16:50:58,712 - INFO - joeynmt.helpers - delete /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/36500.ckpt
2024-05-27 16:50:58,712 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/36500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/36500.ckpt')
2024-05-27 16:50:58,714 - INFO - joeynmt.training - Example #0
2024-05-27 16:50:58,714 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:50:58,714 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:50:58,714 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', ',', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'that', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', '.', '</s>']
2024-05-27 16:50:58,715 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:50:58,715 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:50:58,715 - INFO - joeynmt.training - 	Hypothesis: Last year , I showed these slides to show that the cotta glacial , that for almost three million years had the size of 48 continental continental continental continental continental continental .
2024-05-27 16:50:58,715 - INFO - joeynmt.training - Example #1
2024-05-27 16:50:58,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:50:58,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:50:58,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'm@@', 'it', ',', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 's@@', 'ev@@', 'en@@', '-@@', 'up', '.', '</s>']
2024-05-27 16:50:58,715 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:50:58,715 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:50:58,715 - INFO - joeynmt.training - 	Hypothesis: But this submit , the gravity of the problem because it doesn &apos;t show the seven-up .
2024-05-27 16:50:58,715 - INFO - joeynmt.training - Example #2
2024-05-27 16:50:58,715 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:50:58,715 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:50:58,715 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a sense , the pulser heart of the global climate system .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - Example #3
2024-05-27 16:50:58,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:50:58,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:50:58,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'ver@@', 'ter', 'and', 'it', 'comes', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Hypothesis: It expanding inverter and it comes summer .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - Example #4
2024-05-27 16:50:58,716 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:50:58,716 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:50:58,716 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'car@@', 'rel@@', 'ated', 'on', 'the', 'ex@@', 'ten@@', 'si@@', 've', 'years', '.', '</s>']
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:50:58,716 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carrelated on the extensive years .
2024-05-27 16:51:17,680 - INFO - joeynmt.training - Epoch   9, Step:    37100, Batch Loss:     1.140384, Batch Acc: 0.634321, Tokens per Sec:     3699, Lr: 0.000300
2024-05-27 16:51:37,982 - INFO - joeynmt.training - Epoch   9, Step:    37200, Batch Loss:     1.254005, Batch Acc: 0.632352, Tokens per Sec:     3486, Lr: 0.000300
2024-05-27 16:52:00,907 - INFO - joeynmt.training - Epoch   9, Step:    37300, Batch Loss:     1.362481, Batch Acc: 0.637164, Tokens per Sec:     3046, Lr: 0.000300
2024-05-27 16:52:21,678 - INFO - joeynmt.training - Epoch   9, Step:    37400, Batch Loss:     1.184264, Batch Acc: 0.637582, Tokens per Sec:     3485, Lr: 0.000300
2024-05-27 16:52:41,468 - INFO - joeynmt.training - Epoch   9, Step:    37500, Batch Loss:     1.178666, Batch Acc: 0.635818, Tokens per Sec:     3652, Lr: 0.000300
2024-05-27 16:52:41,468 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:52:41,469 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:53:40,415 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.35, acc:   0.58, generation: 58.9361[sec], evaluation: 0.0000[sec]
2024-05-27 16:53:40,537 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/34500.ckpt
2024-05-27 16:53:40,541 - INFO - joeynmt.training - Example #0
2024-05-27 16:53:40,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:53:40,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:53:40,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '8', 'contin@@', 'ent@@', 'al', 'Un@@', 'ited', 'St@@', 'ates', ',', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 16:53:40,541 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:53:40,541 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:53:40,541 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to show that the calotta glacial , which for almost three million years has had the size of the 48 continental United States , 40 percent .
2024-05-27 16:53:40,541 - INFO - joeynmt.training - Example #1
2024-05-27 16:53:40,541 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:53:40,541 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:53:40,541 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'm@@', 'it', 'up', ',', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ent', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:53:40,541 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:53:40,541 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Hypothesis: But this submit up , the gravity of the problem because it doesn &apos;t show the spent of the ice .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - Example #2
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'cli@@', 'mat@@', 'ical', 'system', '.', '</s>']
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a sense , the pulsing heart of the global climatical system .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - Example #3
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'and@@', 'ing', 'around', 'the', 'sum@@', 'm@@', 'er', 'and', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Hypothesis: You expanding around the summer and retreatment .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - Example #4
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:53:40,542 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'car@@', 'ed', 'on', 'on', 'the', 'ad@@', 'v@@', 'ice', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:53:40,542 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid cared on on the advice of the last 25 years .
2024-05-27 16:53:59,412 - INFO - joeynmt.training - Epoch   9, Step:    37600, Batch Loss:     1.335801, Batch Acc: 0.638427, Tokens per Sec:     3913, Lr: 0.000300
2024-05-27 16:54:20,899 - INFO - joeynmt.training - Epoch   9, Step:    37700, Batch Loss:     1.407561, Batch Acc: 0.636667, Tokens per Sec:     3365, Lr: 0.000300
2024-05-27 16:54:40,144 - INFO - joeynmt.training - Epoch   9, Step:    37800, Batch Loss:     1.303555, Batch Acc: 0.640510, Tokens per Sec:     3755, Lr: 0.000300
2024-05-27 16:55:01,164 - INFO - joeynmt.training - Epoch   9, Step:    37900, Batch Loss:     1.095433, Batch Acc: 0.638327, Tokens per Sec:     3496, Lr: 0.000300
2024-05-27 16:55:20,511 - INFO - joeynmt.training - Epoch   9, Step:    38000, Batch Loss:     1.204449, Batch Acc: 0.638983, Tokens per Sec:     3843, Lr: 0.000300
2024-05-27 16:55:20,511 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:55:20,511 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:56:19,668 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.35, acc:   0.58, generation: 59.1481[sec], evaluation: 0.0000[sec]
2024-05-27 16:56:19,865 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/37000.ckpt
2024-05-27 16:56:19,867 - INFO - joeynmt.training - Example #0
2024-05-27 16:56:19,867 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:56:19,867 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:56:19,867 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'has', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', '.', '</s>']
2024-05-27 16:56:19,867 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:56:19,867 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:56:19,867 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to show that the cotta calculate glacial glacial , which for almost three million years has had the size of 48 continental continental .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - Example #1
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', ',', 'this', 'under@@', 'esti@@', 'mat@@', 'ing', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 't@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Hypothesis: But this is , this underestimating the gravity of the problem because it doesn &apos;t show the spexpector of the ice .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - Example #2
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a sense , the pulsing heart of the global climate system .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - Example #3
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:56:19,868 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'and@@', 'ing', 'around', 'the', 'sum@@', 'm@@', 'er', 'and', 're@@', 'tre@@', 'at', 'the', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:56:19,868 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:56:19,869 - INFO - joeynmt.training - 	Hypothesis: You expanding around the summer and retreat the summer .
2024-05-27 16:56:19,869 - INFO - joeynmt.training - Example #4
2024-05-27 16:56:19,869 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:56:19,869 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:56:19,869 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'car@@', 'l@@', 'ed', 'on', 'the', 'li@@', 'ving', 'be@@', 'au@@', 'ti@@', 'ful', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:56:19,869 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:56:19,869 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:56:19,869 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carled on the living beautiful 25 years .
2024-05-27 16:56:40,035 - INFO - joeynmt.training - Epoch   9, Step:    38100, Batch Loss:     1.236084, Batch Acc: 0.625296, Tokens per Sec:     3462, Lr: 0.000300
2024-05-27 16:57:00,181 - INFO - joeynmt.training - Epoch   9, Step:    38200, Batch Loss:     1.336131, Batch Acc: 0.629526, Tokens per Sec:     3590, Lr: 0.000300
2024-05-27 16:57:19,565 - INFO - joeynmt.training - Epoch   9, Step:    38300, Batch Loss:     1.345021, Batch Acc: 0.632756, Tokens per Sec:     3609, Lr: 0.000300
2024-05-27 16:57:39,240 - INFO - joeynmt.training - Epoch   9, Step:    38400, Batch Loss:     1.353858, Batch Acc: 0.633101, Tokens per Sec:     3645, Lr: 0.000300
2024-05-27 16:57:59,444 - INFO - joeynmt.training - Epoch   9, Step:    38500, Batch Loss:     1.447795, Batch Acc: 0.628033, Tokens per Sec:     3607, Lr: 0.000300
2024-05-27 16:57:59,444 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 16:57:59,444 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 16:58:51,803 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.30, acc:   0.59, generation: 52.3483[sec], evaluation: 0.0000[sec]
2024-05-27 16:58:51,809 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 16:58:51,937 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/36000.ckpt
2024-05-27 16:58:51,942 - INFO - joeynmt.training - Example #0
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'c@@', 'alc@@', 'ul@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', '.', '</s>']
2024-05-27 16:58:51,943 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 16:58:51,943 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 16:58:51,943 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the cotta calculate glacial glacial , which for almost three million years had the size of 48 continental continental .
2024-05-27 16:58:51,943 - INFO - joeynmt.training - Example #1
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'under@@', 'es@@', 'tim@@', 'ate', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'g@@', 'ri@@', 'd', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 16:58:51,943 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 16:58:51,943 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 16:58:51,943 - INFO - joeynmt.training - 	Hypothesis: However , this underestimate the gravity of the problem because it doesn &apos;t show the grid of the ice .
2024-05-27 16:58:51,943 - INFO - joeynmt.training - Example #2
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 16:58:51,943 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'at', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', ',', '</s>']
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Hypothesis: The arcat glacial is , in a sense , the pulsing heart of the global climate ,
2024-05-27 16:58:51,944 - INFO - joeynmt.training - Example #3
2024-05-27 16:58:51,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 16:58:51,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 16:58:51,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'ex@@', 'pan@@', 'ds', ',', 'and', 'it', 'r@@', 'iti@@', 's', '.', '</s>']
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Hypothesis: You &apos;re expands , and it ritis .
2024-05-27 16:58:51,944 - INFO - joeynmt.training - Example #4
2024-05-27 16:58:51,944 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 16:58:51,944 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 16:58:51,944 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 're@@', 'cor@@', 'd', 'on', 'the', 'li@@', 'gh@@', 'ts', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 16:58:51,944 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid record on the lights of the last 25 years .
2024-05-27 16:59:12,004 - INFO - joeynmt.training - Epoch   9, Step:    38600, Batch Loss:     1.111571, Batch Acc: 0.631147, Tokens per Sec:     3531, Lr: 0.000300
2024-05-27 16:59:31,616 - INFO - joeynmt.training - Epoch   9, Step:    38700, Batch Loss:     1.255799, Batch Acc: 0.632039, Tokens per Sec:     3611, Lr: 0.000300
2024-05-27 16:59:51,258 - INFO - joeynmt.training - Epoch   9, Step:    38800, Batch Loss:     1.313770, Batch Acc: 0.631377, Tokens per Sec:     3676, Lr: 0.000300
2024-05-27 17:00:09,876 - INFO - joeynmt.training - Epoch   9, Step:    38900, Batch Loss:     1.281127, Batch Acc: 0.634699, Tokens per Sec:     3857, Lr: 0.000300
2024-05-27 17:00:30,886 - INFO - joeynmt.training - Epoch   9, Step:    39000, Batch Loss:     1.074532, Batch Acc: 0.629791, Tokens per Sec:     3378, Lr: 0.000300
2024-05-27 17:00:30,887 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:00:30,887 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:01:26,768 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.30, acc:   0.58, generation: 55.8736[sec], evaluation: 0.0000[sec]
2024-05-27 17:01:26,770 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:01:26,890 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/35000.ckpt
2024-05-27 17:01:26,894 - INFO - joeynmt.training - Example #0
2024-05-27 17:01:26,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:01:26,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:01:26,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'last', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', ',', 'has', 're@@', 'str@@', 'i@@', 'p@@', 'ed', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:01:26,894 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:01:26,894 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:01:26,894 - INFO - joeynmt.training - 	Hypothesis: The last year I showed these slide to demonstrate that the artic glacial glacial , which for almost three million years had the size of the 48 United States , has restriped 40 percent .
2024-05-27 17:01:26,894 - INFO - joeynmt.training - Example #1
2024-05-27 17:01:26,894 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:01:26,894 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:01:26,894 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ur@@', 'b@@', 'ing', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 't@@', 'ation', '.', '</s>']
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Hypothesis: But this suburbing the gravity of the problem because it doesn &apos;t show the spexpectation .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - Example #2
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'y@@', 'c@@', 'le', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Hypothesis: The arcycle glacial is , in a sense , the heart heart of the global climate system .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - Example #3
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'w@@', 'in@@', 'ter', 'and', 'w@@', 'in@@', 'ter', 'and', 'the', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - 	Hypothesis: You &apos;re winter and winter and the summer .
2024-05-27 17:01:26,895 - INFO - joeynmt.training - Example #4
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:01:26,895 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'the', 'next', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:01:26,896 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:01:26,896 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:01:26,896 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carried on the next 25 years .
2024-05-27 17:01:46,382 - INFO - joeynmt.training - Epoch   9, Step:    39100, Batch Loss:     1.169610, Batch Acc: 0.635595, Tokens per Sec:     3702, Lr: 0.000300
2024-05-27 17:02:06,040 - INFO - joeynmt.training - Epoch   9, Step:    39200, Batch Loss:     1.068802, Batch Acc: 0.632634, Tokens per Sec:     3770, Lr: 0.000300
2024-05-27 17:02:25,798 - INFO - joeynmt.training - Epoch   9, Step:    39300, Batch Loss:     1.099236, Batch Acc: 0.632816, Tokens per Sec:     3718, Lr: 0.000300
2024-05-27 17:02:46,537 - INFO - joeynmt.training - Epoch   9, Step:    39400, Batch Loss:     1.285102, Batch Acc: 0.632075, Tokens per Sec:     3416, Lr: 0.000300
2024-05-27 17:03:05,877 - INFO - joeynmt.training - Epoch   9, Step:    39500, Batch Loss:     1.166184, Batch Acc: 0.632537, Tokens per Sec:     3794, Lr: 0.000300
2024-05-27 17:03:05,878 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:03:05,878 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:04:01,268 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.31, acc:   0.58, generation: 55.3818[sec], evaluation: 0.0000[sec]
2024-05-27 17:04:01,388 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/37500.ckpt
2024-05-27 17:04:01,391 - INFO - joeynmt.training - Example #0
2024-05-27 17:04:01,391 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:04:01,391 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:04:01,391 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'h@@', 'o@@', 't', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', '.', 'S@@', 'he', 're@@', 'h@@', 'ol@@', 'ds', '.', '</s>']
2024-05-27 17:04:01,391 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slidemonstrate to demonstrate that the hot glacial , which for almost three million years had the size of 48 United States . She reholds .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - Example #1
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'es@@', 'tim@@', 'ate', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'pen@@', 'si@@', 've', '.', '</s>']
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Hypothesis: But this underestimate the gravity of the problem because it doesn &apos;t show the spexpensive .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - Example #2
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'le', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Hypothesis: The arcle glacial is , in a sense , the heart of the global climate system .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - Example #3
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:04:01,392 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'in@@', 'ver@@', 'i@@', 've', 'and', 'it', 'comes', 'back', '.', '</s>']
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:04:01,392 - INFO - joeynmt.training - 	Hypothesis: It expands inverive and it comes back .
2024-05-27 17:04:01,393 - INFO - joeynmt.training - Example #4
2024-05-27 17:04:01,393 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:04:01,393 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:04:01,393 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'the', 'be@@', 'd@@', 'ro@@', 'p', 'of', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:04:01,393 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:04:01,393 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:04:01,393 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carried on the bedrop of last 25 years .
2024-05-27 17:04:21,265 - INFO - joeynmt.training - Epoch   9, Step:    39600, Batch Loss:     1.234956, Batch Acc: 0.630337, Tokens per Sec:     3604, Lr: 0.000300
2024-05-27 17:04:42,604 - INFO - joeynmt.training - Epoch   9, Step:    39700, Batch Loss:     1.129757, Batch Acc: 0.627411, Tokens per Sec:     3417, Lr: 0.000300
2024-05-27 17:05:03,378 - INFO - joeynmt.training - Epoch   9, Step:    39800, Batch Loss:     1.278574, Batch Acc: 0.634465, Tokens per Sec:     3517, Lr: 0.000300
2024-05-27 17:05:13,499 - INFO - joeynmt.training - Epoch   9: total training loss 5538.87
2024-05-27 17:05:13,499 - INFO - joeynmt.training - EPOCH 10
2024-05-27 17:05:22,961 - INFO - joeynmt.training - Epoch  10, Step:    39900, Batch Loss:     1.188324, Batch Acc: 0.649014, Tokens per Sec:     3560, Lr: 0.000300
2024-05-27 17:05:42,780 - INFO - joeynmt.training - Epoch  10, Step:    40000, Batch Loss:     1.343009, Batch Acc: 0.653180, Tokens per Sec:     3737, Lr: 0.000300
2024-05-27 17:05:42,781 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:05:42,781 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:06:37,262 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.30, acc:   0.59, generation: 54.4726[sec], evaluation: 0.0000[sec]
2024-05-27 17:06:37,265 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:06:37,381 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/38000.ckpt
2024-05-27 17:06:37,386 - INFO - joeynmt.training - Example #0
2024-05-27 17:06:37,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:06:37,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:06:37,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'S@@', '.', 'S@@', 'he', '&apos;s', 're@@', 'h@@', 'ol@@', 'ding', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:06:37,386 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:06:37,386 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:06:37,386 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the calotta glacial glacial glacial glacial , which almost three million years had the size of the U.S. S. She &apos;s reholding 40 percent .
2024-05-27 17:06:37,386 - INFO - joeynmt.training - Example #1
2024-05-27 17:06:37,386 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:06:37,386 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:06:37,386 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'is', 'that', 'un@@', 'der', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Hypothesis: But this is that under the gravity of the problem because it doesn &apos;t show the spexpessor of the ice .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - Example #2
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'ica', 'is', 'in', 'a', 'kind', 'of', 'ar@@', 't@@', 'ica', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'hear@@', 't', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Hypothesis: The artica is in a kind of artica is , in a sense , the heart heart of the global climate system .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - Example #3
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'side', 'and', 'it', 'c@@', 'lim@@', 'b@@', 's', '.', '</s>']
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - 	Hypothesis: It expanding inside and it climbs .
2024-05-27 17:06:37,387 - INFO - joeynmt.training - Example #4
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:06:37,387 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'will', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:06:37,388 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:06:37,388 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:06:37,388 - INFO - joeynmt.training - 	Hypothesis: The next slide will be a quick carried on on the last 25 years .
2024-05-27 17:06:56,666 - INFO - joeynmt.training - Epoch  10, Step:    40100, Batch Loss:     1.091143, Batch Acc: 0.651960, Tokens per Sec:     3732, Lr: 0.000300
2024-05-27 17:07:17,165 - INFO - joeynmt.training - Epoch  10, Step:    40200, Batch Loss:     1.272928, Batch Acc: 0.654318, Tokens per Sec:     3509, Lr: 0.000300
2024-05-27 17:07:37,965 - INFO - joeynmt.training - Epoch  10, Step:    40300, Batch Loss:     1.204595, Batch Acc: 0.644993, Tokens per Sec:     3450, Lr: 0.000300
2024-05-27 17:07:58,619 - INFO - joeynmt.training - Epoch  10, Step:    40400, Batch Loss:     1.181367, Batch Acc: 0.651534, Tokens per Sec:     3539, Lr: 0.000300
2024-05-27 17:08:18,557 - INFO - joeynmt.training - Epoch  10, Step:    40500, Batch Loss:     1.236226, Batch Acc: 0.655257, Tokens per Sec:     3662, Lr: 0.000300
2024-05-27 17:08:18,557 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:08:18,557 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:09:15,349 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.47, ppl:   4.33, acc:   0.58, generation: 56.7850[sec], evaluation: 0.0000[sec]
2024-05-27 17:09:15,476 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/35500.ckpt
2024-05-27 17:09:15,480 - INFO - joeynmt.training - Example #0
2024-05-27 17:09:15,480 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:09:15,480 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:09:15,480 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', '4@@', '8', 'percent', '.', '</s>']
2024-05-27 17:09:15,480 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:09:15,480 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:09:15,480 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arctic glacial glacial , which for almost three million years had the size of 48 United States continental continental , 48 percent .
2024-05-27 17:09:15,480 - INFO - joeynmt.training - Example #1
2024-05-27 17:09:15,480 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:09:15,480 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:09:15,480 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'under@@', 'ed@@', 'w@@', 'ood', ',', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'ten@@', 'ding', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:09:15,480 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:09:15,480 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:09:15,480 - INFO - joeynmt.training - 	Hypothesis: However , this underedwood , because it doesn &apos;t show the spextending of the ice .
2024-05-27 17:09:15,480 - INFO - joeynmt.training - Example #2
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'he@@', 'at', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Hypothesis: The arctic heat is , in a sense , the pulsant heart of global climate system .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - Example #3
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'pan@@', 'ds', 'in@@', 'ver@@', 'ter', 'and', 'it', 're@@', 'tre@@', 'at@@', 'ment', '.', '</s>']
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Hypothesis: It expands inverter and it retreatment .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - Example #4
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:09:15,481 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'f@@', 'ast@@', 'er', 're@@', 'id', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:09:15,481 - INFO - joeynmt.training - 	Hypothesis: The next slide slide is going to be a faster reid on the last 25 years .
2024-05-27 17:09:36,400 - INFO - joeynmt.training - Epoch  10, Step:    40600, Batch Loss:     1.006277, Batch Acc: 0.648387, Tokens per Sec:     3467, Lr: 0.000300
2024-05-27 17:09:56,919 - INFO - joeynmt.training - Epoch  10, Step:    40700, Batch Loss:     1.079338, Batch Acc: 0.642175, Tokens per Sec:     3639, Lr: 0.000300
2024-05-27 17:10:17,726 - INFO - joeynmt.training - Epoch  10, Step:    40800, Batch Loss:     1.223626, Batch Acc: 0.645255, Tokens per Sec:     3505, Lr: 0.000300
2024-05-27 17:10:39,664 - INFO - joeynmt.training - Epoch  10, Step:    40900, Batch Loss:     1.032742, Batch Acc: 0.644959, Tokens per Sec:     3292, Lr: 0.000300
2024-05-27 17:11:00,007 - INFO - joeynmt.training - Epoch  10, Step:    41000, Batch Loss:     1.212555, Batch Acc: 0.644644, Tokens per Sec:     3632, Lr: 0.000300
2024-05-27 17:11:00,008 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:11:00,008 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:12:00,931 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.31, acc:   0.58, generation: 60.9133[sec], evaluation: 0.0000[sec]
2024-05-27 17:12:01,054 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/40500.ckpt
2024-05-27 17:12:01,058 - INFO - joeynmt.helpers - delete /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/40500.ckpt
2024-05-27 17:12:01,058 - WARNING - joeynmt.helpers - Wanted to delete old checkpoint /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/40500.ckpt but file does not exist. ([Errno 2] No such file or directory: '/Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/40500.ckpt')
2024-05-27 17:12:01,058 - INFO - joeynmt.training - Example #0
2024-05-27 17:12:01,058 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:12:01,058 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:12:01,058 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['I', 'sho@@', 'w@@', 'ed', 'this', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'c@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', 'the', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Hypothesis: I showed this slides to show that the slides to show that the cotta glacial glacial , which for almost three million years had the size of the 40 percent .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - Example #1
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'that', 'has', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ess@@', 'or', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Hypothesis: But this subject that has the gravity of the problem because it doesn &apos;t show the spexpessor of the ice .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - Example #2
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a certain sense , the heart of the global climate system .
2024-05-27 17:12:01,059 - INFO - joeynmt.training - Example #3
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:12:01,059 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'side', 'and', 'it', 'comes', 'in', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 17:12:01,060 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:12:01,060 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:12:01,060 - INFO - joeynmt.training - 	Hypothesis: It expanding inside and it comes in summer .
2024-05-27 17:12:01,060 - INFO - joeynmt.training - Example #4
2024-05-27 17:12:01,060 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:12:01,060 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:12:01,060 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'rap@@', 'id', 'car@@', 'ri@@', 'ed', 'on', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:12:01,060 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:12:01,060 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:12:01,060 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a rapid carried on on the last 25 years .
2024-05-27 17:12:21,255 - INFO - joeynmt.training - Epoch  10, Step:    41100, Batch Loss:     1.350565, Batch Acc: 0.645056, Tokens per Sec:     3512, Lr: 0.000300
2024-05-27 17:12:41,948 - INFO - joeynmt.training - Epoch  10, Step:    41200, Batch Loss:     1.164454, Batch Acc: 0.639361, Tokens per Sec:     3466, Lr: 0.000300
2024-05-27 17:13:03,437 - INFO - joeynmt.training - Epoch  10, Step:    41300, Batch Loss:     1.141349, Batch Acc: 0.649092, Tokens per Sec:     3351, Lr: 0.000300
2024-05-27 17:13:23,679 - INFO - joeynmt.training - Epoch  10, Step:    41400, Batch Loss:     1.165819, Batch Acc: 0.645216, Tokens per Sec:     3735, Lr: 0.000300
2024-05-27 17:13:42,585 - INFO - joeynmt.training - Epoch  10, Step:    41500, Batch Loss:     1.404921, Batch Acc: 0.641235, Tokens per Sec:     3920, Lr: 0.000300
2024-05-27 17:13:42,586 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:13:42,586 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:14:40,098 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.31, acc:   0.58, generation: 57.5048[sec], evaluation: 0.0000[sec]
2024-05-27 17:14:40,100 - INFO - joeynmt.training - Example #0
2024-05-27 17:14:40,100 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:14:40,100 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:14:40,100 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'c@@', 'ot@@', 'ta', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', 'of', 'the', 'U@@', '.@@', 'S@@', '.', 'contin@@', 'ent@@', 'al', ',', 'it', 'was', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:14:40,100 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:14:40,100 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:14:40,100 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slidemonstrate that the cotta arctic glacial , which for almost three million years had the size of 48 percent of the U.S. continental , it was 40 percent .
2024-05-27 17:14:40,100 - INFO - joeynmt.training - Example #1
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'of', 'this', 'sub@@', 'ject', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'pen@@', 'si@@', 've', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'pen@@', 'si@@', 've', '.', '</s>']
2024-05-27 17:14:40,101 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:14:40,101 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:14:40,101 - INFO - joeynmt.training - 	Hypothesis: But this subject of this subject of the problem because it doesn &apos;t show the spexpensive because it doesn &apos;t show the spexpensive .
2024-05-27 17:14:40,101 - INFO - joeynmt.training - Example #2
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'way', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', ',', 'the', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:14:40,101 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:14:40,101 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:14:40,101 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a way , the pulsant , the heart of the global climate system .
2024-05-27 17:14:40,101 - INFO - joeynmt.training - Example #3
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:14:40,101 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'p@@', 'p@@', 'utt@@', 'ing', 'out', 'sum@@', 'm@@', 'er', ',', 'and', 'it', '&apos;s', 'ex@@', 'p@@', 'and@@', 'ing', '.', '</s>']
2024-05-27 17:14:40,102 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:14:40,102 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:14:40,102 - INFO - joeynmt.training - 	Hypothesis: It exppputting out summer , and it &apos;s expanding .
2024-05-27 17:14:40,102 - INFO - joeynmt.training - Example #4
2024-05-27 17:14:40,102 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:14:40,102 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:14:40,102 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 's@@', 'li@@', 'de', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:14:40,102 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:14:40,102 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:14:40,102 - INFO - joeynmt.training - 	Hypothesis: The next slide slide will be a rapid fast carried on the last 25 years .
2024-05-27 17:14:59,267 - INFO - joeynmt.training - Epoch  10, Step:    41600, Batch Loss:     1.252661, Batch Acc: 0.646608, Tokens per Sec:     3913, Lr: 0.000300
2024-05-27 17:15:18,392 - INFO - joeynmt.training - Epoch  10, Step:    41700, Batch Loss:     1.249327, Batch Acc: 0.645048, Tokens per Sec:     3722, Lr: 0.000300
2024-05-27 17:15:38,316 - INFO - joeynmt.training - Epoch  10, Step:    41800, Batch Loss:     1.344475, Batch Acc: 0.644143, Tokens per Sec:     3681, Lr: 0.000300
2024-05-27 17:15:57,244 - INFO - joeynmt.training - Epoch  10, Step:    41900, Batch Loss:     1.238981, Batch Acc: 0.639490, Tokens per Sec:     3796, Lr: 0.000300
2024-05-27 17:16:16,744 - INFO - joeynmt.training - Epoch  10, Step:    42000, Batch Loss:     1.249897, Batch Acc: 0.641825, Tokens per Sec:     3741, Lr: 0.000300
2024-05-27 17:16:16,744 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:16:16,744 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:17:17,064 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.31, acc:   0.59, generation: 60.3122[sec], evaluation: 0.0000[sec]
2024-05-27 17:17:17,066 - INFO - joeynmt.training - Example #0
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', '.', '</s>']
2024-05-27 17:17:17,067 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:17:17,067 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:17:17,067 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the calotta glacial glacial glacial , which for almost three million years , had the size of 48 United States .
2024-05-27 17:17:17,067 - INFO - joeynmt.training - Example #1
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'm@@', 'it', 'up', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ect', 'of', 'ice', '.', '</s>']
2024-05-27 17:17:17,067 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:17:17,067 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:17:17,067 - INFO - joeynmt.training - 	Hypothesis: But this submit up the gravity of the problem because it doesn &apos;t show the spexpect of ice .
2024-05-27 17:17:17,067 - INFO - joeynmt.training - Example #2
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:17:17,067 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 't@@', 'en', 'c@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ing', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Hypothesis: The arten clacial is , in a sense , the pulsing heart of the global climate system .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - Example #3
2024-05-27 17:17:17,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:17:17,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:17:17,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', '&apos;re', 'going', 'to', 'w@@', 'in@@', 'ter', 'and', 'it', 'was', 'ta@@', 'k@@', 'en', '.', '</s>']
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Hypothesis: You &apos;re going to winter and it was taken .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - Example #4
2024-05-27 17:17:17,068 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:17:17,068 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:17:17,068 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'is', 'a', 'rap@@', 'id', 'car@@', 'ri@@', 'ed', 'on', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:17:17,068 - INFO - joeynmt.training - 	Hypothesis: The next slide is a quick carried on is a rapid carried on the last 25 years .
2024-05-27 17:17:36,767 - INFO - joeynmt.training - Epoch  10, Step:    42100, Batch Loss:     1.203047, Batch Acc: 0.642294, Tokens per Sec:     3632, Lr: 0.000300
2024-05-27 17:17:56,636 - INFO - joeynmt.training - Epoch  10, Step:    42200, Batch Loss:     1.193064, Batch Acc: 0.645795, Tokens per Sec:     3620, Lr: 0.000300
2024-05-27 17:18:16,576 - INFO - joeynmt.training - Epoch  10, Step:    42300, Batch Loss:     1.395931, Batch Acc: 0.637507, Tokens per Sec:     3727, Lr: 0.000300
2024-05-27 17:18:36,246 - INFO - joeynmt.training - Epoch  10, Step:    42400, Batch Loss:     1.261437, Batch Acc: 0.645128, Tokens per Sec:     3741, Lr: 0.000300
2024-05-27 17:18:55,756 - INFO - joeynmt.training - Epoch  10, Step:    42500, Batch Loss:     1.201548, Batch Acc: 0.641042, Tokens per Sec:     3643, Lr: 0.000300
2024-05-27 17:18:55,757 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:18:55,757 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:19:51,424 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.31, acc:   0.59, generation: 55.6592[sec], evaluation: 0.0000[sec]
2024-05-27 17:19:51,426 - INFO - joeynmt.training - Example #0
2024-05-27 17:19:51,426 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:19:51,426 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:19:51,426 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'percent', 'of', 'the', 'Un@@', 'ited', 'St@@', 'ates', '.', 'B@@', 'y', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'ke', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:19:51,426 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:19:51,426 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:19:51,426 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slidemonstrate to demonstrate that the arctic glacial , which for almost three million years had the size of 48 percent of the United States . By , it &apos;s restrike 40 percent .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - Example #1
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['And', 'that', '&apos;s', 'that', 'that', 'under@@', 'ne@@', 'at@@', 'h', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'pen@@', 'ded', 'of', 'the', 'ice', 'of', 'ice', '.', '</s>']
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Hypothesis: And that &apos;s that that underneath the problem because it doesn &apos;t show the spexpended of the ice of ice .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - Example #2
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ta', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Hypothesis: The arctic calotta is , in a sense , the pulsant heart of the global climate system .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - Example #3
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:19:51,427 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'ver@@', 'ter', 'and', 'it', '&apos;s', 'ex@@', 'p@@', 'and@@', 'ing', '.', '</s>']
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - 	Hypothesis: You expanding inverter and it &apos;s expanding .
2024-05-27 17:19:51,427 - INFO - joeynmt.training - Example #4
2024-05-27 17:19:51,428 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:19:51,428 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:19:51,428 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'li@@', 'ving', 'b@@', 'un@@', 'ch', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:19:51,428 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:19:51,428 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:19:51,428 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrelated to the living bunch of the last 25 years .
2024-05-27 17:20:10,771 - INFO - joeynmt.training - Epoch  10, Step:    42600, Batch Loss:     1.286781, Batch Acc: 0.640176, Tokens per Sec:     3779, Lr: 0.000300
2024-05-27 17:20:30,399 - INFO - joeynmt.training - Epoch  10, Step:    42700, Batch Loss:     1.094621, Batch Acc: 0.638060, Tokens per Sec:     3653, Lr: 0.000300
2024-05-27 17:20:50,247 - INFO - joeynmt.training - Epoch  10, Step:    42800, Batch Loss:     1.129847, Batch Acc: 0.644203, Tokens per Sec:     3640, Lr: 0.000300
2024-05-27 17:21:10,322 - INFO - joeynmt.training - Epoch  10, Step:    42900, Batch Loss:     1.216182, Batch Acc: 0.637147, Tokens per Sec:     3723, Lr: 0.000300
2024-05-27 17:21:30,775 - INFO - joeynmt.training - Epoch  10, Step:    43000, Batch Loss:     1.192429, Batch Acc: 0.641353, Tokens per Sec:     3557, Lr: 0.000300
2024-05-27 17:21:30,776 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:21:30,776 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:22:24,463 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.46, ppl:   4.29, acc:   0.59, generation: 53.6795[sec], evaluation: 0.0000[sec]
2024-05-27 17:22:24,464 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:22:24,584 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/39500.ckpt
2024-05-27 17:22:24,590 - INFO - joeynmt.training - Example #0
2024-05-27 17:22:24,590 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:22:24,590 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:22:24,590 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'c@@', 'alc@@', 'ul@@', 'ate', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', ',', 'he', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', 'contin@@', 'ent@@', 'al', ',', 'it', 'was', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:22:24,590 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:22:24,590 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:22:24,590 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slide to show that the arctic calculate , which for almost three million years , he had the size of 48 continental United States continental continental , it was 40 percent .
2024-05-27 17:22:24,590 - INFO - joeynmt.training - Example #1
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['H@@', 'o@@', 'w@@', 'ever', ',', 'this', 'under@@', 'l@@', 'ying', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'ice', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Hypothesis: However , this underlying the gravity of the problem because it doesn &apos;t show the ice of the ice .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - Example #2
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'ti@@', 'c', 'cal@@', 'ot@@', 'ice', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'p@@', 'ul@@', 'l', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Hypothesis: The artic calotice is , in a certain sense , the pull of the global climate system .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - Example #3
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['It', 'ex@@', 'p@@', 'ands', 'out', 'sum@@', 'm@@', 'er', '.', '</s>']
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - 	Hypothesis: It expands out summer .
2024-05-27 17:22:24,591 - INFO - joeynmt.training - Example #4
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:22:24,591 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'rel@@', 'ated', 'to', 'the', 'ad@@', 'v@@', 'ance', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:22:24,592 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:22:24,592 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:22:24,592 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrelated to the advance of the last 25 years .
2024-05-27 17:22:43,532 - INFO - joeynmt.training - Epoch  10, Step:    43100, Batch Loss:     1.081882, Batch Acc: 0.639359, Tokens per Sec:     3910, Lr: 0.000300
2024-05-27 17:23:04,344 - INFO - joeynmt.training - Epoch  10, Step:    43200, Batch Loss:     1.058088, Batch Acc: 0.642562, Tokens per Sec:     3541, Lr: 0.000300
2024-05-27 17:23:24,448 - INFO - joeynmt.training - Epoch  10, Step:    43300, Batch Loss:     1.302198, Batch Acc: 0.636061, Tokens per Sec:     3481, Lr: 0.000300
2024-05-27 17:23:45,766 - INFO - joeynmt.training - Epoch  10, Step:    43400, Batch Loss:     1.266915, Batch Acc: 0.636800, Tokens per Sec:     3359, Lr: 0.000300
2024-05-27 17:24:04,148 - INFO - joeynmt.training - Epoch  10, Step:    43500, Batch Loss:     1.228761, Batch Acc: 0.636874, Tokens per Sec:     3968, Lr: 0.000300
2024-05-27 17:24:04,148 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:24:04,148 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:24:53,628 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.45, ppl:   4.27, acc:   0.59, generation: 49.4721[sec], evaluation: 0.0000[sec]
2024-05-27 17:24:53,630 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:24:53,760 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/41000.ckpt
2024-05-27 17:24:53,765 - INFO - joeynmt.training - Example #0
2024-05-27 17:24:53,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:24:53,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:24:53,765 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 'mon@@', 'str@@', 'ate', 'to', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'cal@@', 'ot@@', 'y', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'that', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'contin@@', 'ent@@', 'al', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p@@', 'ed', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:24:53,765 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:24:53,765 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:24:53,765 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slidemonstrate to demonstrate that the caloty glacial , that for almost three million years had the size of 48 continental United States continental , it &apos;s restriped 40 percent .
2024-05-27 17:24:53,765 - INFO - joeynmt.training - Example #1
2024-05-27 17:24:53,765 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:24:53,765 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'under@@', 'es@@', 'tim@@', 'ate', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 'ted', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Hypothesis: But this underestimate the gravity of the problem because it doesn &apos;t show the spexpected of the ice .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - Example #2
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'c@@', 'lim@@', 'ate', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', 'in', 'a', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'ant', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Hypothesis: The arctic climate glacial is in a sense , the pulsant heart of the global climate system .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - Example #3
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'and', 'in@@', 'ver@@', 't', 'of', 'sum@@', 'm@@', 'er', ',', 'and', 'it', '&apos;s', 'ex@@', 'p@@', 'and@@', 'ing', '.', '</s>']
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - 	Hypothesis: You expand invert of summer , and it &apos;s expanding .
2024-05-27 17:24:53,766 - INFO - joeynmt.training - Example #4
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:24:53,766 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'ri@@', 'ed', 'on', 'the', 'ad@@', 'ven@@', 'u@@', 'es', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:24:53,767 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:24:53,767 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:24:53,767 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carried on the advenues of the last 25 years .
2024-05-27 17:25:12,296 - INFO - joeynmt.training - Epoch  10, Step:    43600, Batch Loss:     1.259917, Batch Acc: 0.640252, Tokens per Sec:     3903, Lr: 0.000300
2024-05-27 17:25:30,733 - INFO - joeynmt.training - Epoch  10, Step:    43700, Batch Loss:     1.061099, Batch Acc: 0.640180, Tokens per Sec:     3859, Lr: 0.000300
2024-05-27 17:25:49,682 - INFO - joeynmt.training - Epoch  10, Step:    43800, Batch Loss:     1.258736, Batch Acc: 0.634746, Tokens per Sec:     3739, Lr: 0.000300
2024-05-27 17:26:07,188 - INFO - joeynmt.training - Epoch  10, Step:    43900, Batch Loss:     1.432323, Batch Acc: 0.637504, Tokens per Sec:     4050, Lr: 0.000300
2024-05-27 17:26:24,381 - INFO - joeynmt.training - Epoch  10, Step:    44000, Batch Loss:     1.239282, Batch Acc: 0.634819, Tokens per Sec:     4196, Lr: 0.000300
2024-05-27 17:26:24,382 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:26:24,382 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Greedy decoding with min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:27:17,256 - INFO - joeynmt.prediction - Evaluation result (greedy) loss:   1.44, ppl:   4.23, acc:   0.59, generation: 52.8677[sec], evaluation: 0.0000[sec]
2024-05-27 17:27:17,259 - INFO - joeynmt.training - Hooray! New best validation result [ppl]!
2024-05-27 17:27:17,375 - INFO - joeynmt.helpers - delete models/iten_transformer_bpe2000/38500.ckpt
2024-05-27 17:27:17,377 - INFO - joeynmt.training - Example #0
2024-05-27 17:27:17,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['L&apos;', 'anno', 'sc@@', 'or@@', 'so', 'ho', 'mostr@@', 'ato', 'queste', 'di@@', 'apos@@', 'iti@@', 've', 'per', 'di@@', 'mostr@@', 'are', 'che', 'la', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', ',', 'che', 'per', 'qu@@', 'asi', 'tre', 'milioni', 'di', 'anni', 'ha', 'avuto', 'le', 'dimen@@', 'sioni', 'dei', '4@@', '8', 'St@@', 'ati', 'Un@@', 'iti', 'contin@@', 'ent@@', 'ali', ',', 'si', 'è', 'ri@@', 'str@@', 'etta', 'del', '4@@', '0', '%', '.']
2024-05-27 17:27:17,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 'two', 's@@', 'li@@', 'de@@', 's', 'so', 'that', 'de@@', 'mon@@', 'str@@', 'ate', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', ',', 'which', 'for', 'most', 'of', 'the', 'last', 'three', 'million', 'years', 'has', 'been', 'the', 'si@@', 'ze', 'of', 'the', 'lo@@', 'wer', '4@@', '8', 'st@@', 'ates', ',', 'has', 'sh@@', 'r@@', 'un@@', 'k', 'by', '4@@', '0', 'percent', '.']
2024-05-27 17:27:17,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['L@@', 'ast', 'year', 'I', 'sho@@', 'w@@', 'ed', 'these', 's@@', 'li@@', 'de@@', 's', 'to', 'show', 'that', 'the', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', ',', 'which', 'for', 'al@@', 'most', 'three', 'million', 'years', 'had', 'the', 'si@@', 'ze', 'of', '4@@', '8', 'Un@@', 'ited', 'St@@', 'ates', 'contin@@', 'ent@@', 'al', ',', 'it', '&apos;s', 're@@', 'str@@', 'i@@', 'p@@', 'p@@', 'ed', 'up', 'of', '4@@', '0', 'percent', '.', '</s>']
2024-05-27 17:27:17,377 - INFO - joeynmt.training - 	Source:     L&apos; anno scorso ho mostrato queste diapositive per dimostrare che la calotta glaciale artica , che per quasi tre milioni di anni ha avuto le dimensioni dei 48 Stati Uniti continentali , si è ristretta del 40 % .
2024-05-27 17:27:17,377 - INFO - joeynmt.training - 	Reference:  Last year I showed these two slides so that demonstrate that the arctic ice cap , which for most of the last three million years has been the size of the lower 48 states , has shrunk by 40 percent .
2024-05-27 17:27:17,377 - INFO - joeynmt.training - 	Hypothesis: Last year I showed these slides to show that the arctic glacial glacial , which for almost three million years had the size of 48 United States continental , it &apos;s restripped up of 40 percent .
2024-05-27 17:27:17,377 - INFO - joeynmt.training - Example #1
2024-05-27 17:27:17,377 - DEBUG - joeynmt.training - 	Tokenized source:     ['T@@', 'utt@@', 'av@@', 'ia', 'questo', 's@@', 'ott@@', 'ov@@', 'al@@', 'uta', 'la', 'gr@@', 'av@@', 'ità', 'del', 'problema', 'perché', 'non', 'mostr@@', 'a', 'lo', 'sp@@', 'ess@@', 'ore', 'del', 'gh@@', 'i@@', 'ac@@', 'cio', '.']
2024-05-27 17:27:17,377 - DEBUG - joeynmt.training - 	Tokenized reference:  ['But', 'this', 'underst@@', 'ates', 'the', 'ser@@', 'i@@', 'ous@@', 'ness', 'of', 'this', 'partic@@', 'ular', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'th@@', 'ic@@', 'k@@', 'ness', 'of', 'the', 'ice', '.']
2024-05-27 17:27:17,377 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['But', 'this', 'sub@@', 'ject', 'is', 'the', 'gr@@', 'av@@', 'ity', 'of', 'the', 'problem', 'because', 'it', 'doesn', '&apos;t', 'show', 'the', 'sp@@', 'ex@@', 'p@@', 'ec@@', 't@@', 'ation', 'of', 'the', 'ice', '.', '</s>']
2024-05-27 17:27:17,377 - INFO - joeynmt.training - 	Source:     Tuttavia questo sottovaluta la gravità del problema perché non mostra lo spessore del ghiaccio .
2024-05-27 17:27:17,377 - INFO - joeynmt.training - 	Reference:  But this understates the seriousness of this particular problem because it doesn &apos;t show the thickness of the ice .
2024-05-27 17:27:17,377 - INFO - joeynmt.training - 	Hypothesis: But this subject is the gravity of the problem because it doesn &apos;t show the spexpectation of the ice .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - Example #2
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'cal@@', 'ot@@', 'ta', 'g@@', 'l@@', 'ac@@', 'i@@', 'ale', 'ar@@', 't@@', 'ica', 'è', ',', 'in', 'un', 'certo', 'senso', ',', 'il', 'cu@@', 'ore', 'p@@', 'ul@@', 's@@', 'ante', 'del', 'sistema', 'cli@@', 'mat@@', 'ico', 'glob@@', 'ale', '.']
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'ice', 'ca@@', 'p', 'is', ',', 'in', 'a', 'sense', ',', 'the', 'be@@', 'ating', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.']
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'ar@@', 'c@@', 'ti@@', 'c', 'g@@', 'l@@', 'ac@@', 'i@@', 'al', 'is', ',', 'in', 'a', 'cer@@', 'ta@@', 'in', 'sense', ',', 'the', 'p@@', 'ul@@', 's@@', 'er', 'hear@@', 't', 'of', 'the', 'glob@@', 'al', 'c@@', 'lim@@', 'ate', 'system', '.', '</s>']
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Source:     La calotta glaciale artica è , in un certo senso , il cuore pulsante del sistema climatico globale .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Reference:  The arctic ice cap is , in a sense , the beating heart of the global climate system .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Hypothesis: The arctic glacial is , in a certain sense , the pulser heart of the global climate system .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - Example #3
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['Si', 'es@@', 'pan@@', 'de', 'd&apos;', 'in@@', 'ver@@', 'no', 'e', 'si', 'r@@', 'iti@@', 'ra', 'd&apos;', 'est@@', 'ate', '.']
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['It', 'ex@@', 'p@@', 'ands', 'in', 'w@@', 'in@@', 'ter', 'and', 'contr@@', 'ac@@', 'ts', 'in', 'sum@@', 'm@@', 'er', '.']
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['You', 'ex@@', 'p@@', 'and@@', 'ing', 'in@@', 'ver@@', 'ter', 'and', 'it', 're@@', 'tre@@', 'at@@', 's', '.', '</s>']
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Source:     Si espande d&apos; inverno e si ritira d&apos; estate .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Reference:  It expands in winter and contracts in summer .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Hypothesis: You expanding inverter and it retreats .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - Example #4
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized source:     ['La', 'pros@@', 'si@@', 'ma', 'di@@', 'apos@@', 'iti@@', 'va', 'sarà', 'una', 'rap@@', 'i@@', 'da', 'car@@', 'rel@@', 'l@@', 'ata', 'su@@', 'gli', 'av@@', 'ven@@', 'im@@', 'enti', 'degli', 'ulti@@', 'mi', '2@@', '5', 'anni', '.']
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized reference:  ['The', 'next', 's@@', 'li@@', 'de', 'I', 'show', 'you', 'will', 'be', 'a', 'rap@@', 'id', 'f@@', 'ast@@', '-@@', 'for@@', 'w@@', 'ard', 'of', 'what', '&apos;s', 'happen@@', 'ed', 'over', 'the', 'last', '2@@', '5', 'years', '.']
2024-05-27 17:27:17,378 - DEBUG - joeynmt.training - 	Tokenized hypothesis: ['The', 'next', 's@@', 'li@@', 'de', 'is', 'going', 'to', 'be', 'a', 'qu@@', 'ick', 'car@@', 'r@@', 'ying', 'on', 'on', 'the', 'ad@@', 'ven@@', 'u@@', 'es', 'of', 'the', 'last', '2@@', '5', 'years', '.', '</s>']
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Source:     La prossima diapositiva sarà una rapida carrellata sugli avvenimenti degli ultimi 25 anni .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Reference:  The next slide I show you will be a rapid fast-forward of what &apos;s happened over the last 25 years .
2024-05-27 17:27:17,378 - INFO - joeynmt.training - 	Hypothesis: The next slide is going to be a quick carrying on on the advenues of the last 25 years .
2024-05-27 17:27:35,856 - INFO - joeynmt.training - Epoch  10, Step:    44100, Batch Loss:     1.127429, Batch Acc: 0.640362, Tokens per Sec:     3848, Lr: 0.000300
2024-05-27 17:27:54,648 - INFO - joeynmt.training - Epoch  10, Step:    44200, Batch Loss:     1.144321, Batch Acc: 0.634904, Tokens per Sec:     3812, Lr: 0.000300
2024-05-27 17:28:04,957 - INFO - joeynmt.training - Epoch  10: total training loss 5386.01
2024-05-27 17:28:04,958 - INFO - joeynmt.training - Training ended after  10 epochs.
2024-05-27 17:28:04,958 - INFO - joeynmt.training - Best validation result (greedy) at step    44000:   4.23 ppl.
2024-05-27 17:28:04,984 - INFO - joeynmt.model - Building an encoder-decoder model...
2024-05-27 17:28:05,025 - INFO - joeynmt.model - Enc-dec model built.
2024-05-27 17:28:05,046 - INFO - joeynmt.helpers - Load model from /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/44000.ckpt.
2024-05-27 17:28:05,055 - INFO - joeynmt.prediction - Model(
	encoder=TransformerEncoder(num_layers=4, num_heads=2, alpha=1.0, layer_norm="pre", activation=ReLU()),
	decoder=TransformerDecoder(num_layers=1, num_heads=2, alpha=1.0, layer_norm="post", activation=ReLU()),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1994),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1994),
	loss_function=None)
2024-05-27 17:28:05,061 - INFO - joeynmt.prediction - Decoding on dev set...
2024-05-27 17:28:05,061 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:28:05,061 - INFO - joeynmt.prediction - Predicting 929 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:29:05,936 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 60.8669[sec], evaluation: 0.0000[sec]
2024-05-27 17:29:05,940 - INFO - joeynmt.prediction - Translations saved to: /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/00044000.hyps.dev.
2024-05-27 17:29:05,940 - INFO - joeynmt.prediction - Decoding on test set...
2024-05-27 17:29:05,940 - WARNING - joeynmt.helpers - `alpha` option is obsolete. Please use `beam_alpha`, instead.
2024-05-27 17:29:05,940 - INFO - joeynmt.prediction - Predicting 1566 example(s)... (Beam search with beam_size=5, beam_alpha=1.0, n_best=1, min_output_length=1, max_output_length=-1, return_prob='none', generate_unk=True, repetition_penalty=-1, no_repeat_ngram_size=-1)
2024-05-27 17:30:31,149 - INFO - joeynmt.prediction - Evaluation result (beam search) , generation: 85.1946[sec], evaluation: 0.0000[sec]
2024-05-27 17:30:31,151 - INFO - joeynmt.prediction - Translations saved to: /Users/xiaojingzhang/Desktop/mt-exercise-5/models/iten_transformer_bpe2000/00044000.hyps.test.
